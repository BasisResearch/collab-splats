{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a mesh\n",
    "\n",
    "We can also use the Splatter wrapper class to take an existing nerfstudio model and create a mesh!\n",
    "1. **mesh:** creates a mesh via TSDF fusion\n",
    "\n",
    "2. **query_mesh:** uses the trained model to query the mesh and returns a similarity map\n",
    "\n",
    "3. **plot_mesh:** enables plotting of mesh features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/pyvista/plotting/utilities/xvfb.py:48: PyVistaDeprecationWarning: This function is deprecated and will be removed in future version of PyVista. Use vtk-osmesa instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "from ns_extension.wrapper import Splatter, SplatterConfig\n",
    "import pyvista as pv\n",
    "\n",
    "pv.start_xvfb()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths to the file for running splats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforms.json already exists at /workspace/fieldwork-data/rats/2024-07-11/environment/C0119/preproc/transforms.json\n",
      "To rerun preprocessing, set overwrite=True\n",
      "Output already exists for rade-features\n",
      "To rerun feature extraction, set overwrite=True\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path('/workspace/fieldwork-data/')\n",
    "session_dir = base_dir / \"rats/2024-07-11/SplatsSD\"\n",
    "\n",
    "# Make the configuration \n",
    "splatter_config = SplatterConfig(\n",
    "    file_path=session_dir / \"C0119.MP4\",\n",
    "    method='rade-features',\n",
    "    frame_proportion=0.25, # Use 25% of the frames within the video (or default to minimum 300 frames)\n",
    ")\n",
    "\n",
    "# Initialize the Splatter class\n",
    "splatter = Splatter(splatter_config)\n",
    "\n",
    "# Call these to populate the splatter with paths (probably a better way to do this --> maybe save out config)\n",
    "splatter.preprocess()\n",
    "splatter.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mesh\n",
    "\n",
    "We can create a mesh by calling the ```mesh()``` method. Under the hood, this runs TSDF fusion creating an integrated volume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available runs:\n",
      "[0] 2025-07-11_171420\n"
     ]
    }
   ],
   "source": [
    "splatter.mesh(\n",
    "    depth_name=\"median_depth\",\n",
    "    depth_trunc=1.0,\n",
    "    # overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mesh!\n",
    "\n",
    "We can use the splatter function ```plot_mesh``` to visualize given attributes of the mesh. The inherent attributes are RGB and Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 116178\n",
      "Number of cells: 215841\n",
      "Bounds: BoundsTuple(x_min=-0.5249999761581421, x_max=0.7450000047683716, y_min=-0.125, y_max=1.4850000143051147, z_min=-1.0149999856948853, z_max=1.0214753150939941)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84a2cfe326040b396a58d5bf18f78ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34453/index.html?ui=P_0x76d4a170e890_14&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splatter.plot_mesh(attribute=\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using semantic queries \n",
    "\n",
    "The mesh contains semantic features which we can query via positive and negative prompts. The goal of this is to find points that are more similar to the positive prompts compared to the negative prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-11_171420/config.yml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:52:28] </span>Auto image downscale factor of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                 <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nerfstudio_dataparser.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:52:28]\u001b[0m\u001b[2;36m \u001b[0mAuto image downscale factor of \u001b[1;36m2\u001b[0m                                                 \u001b]8;id=488478;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=105091;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\\u001b[2m484\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:52:55] </span>use color only optimization with sigmoid activation                                         <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">splatfacto.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#266\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:52:55]\u001b[0m\u001b[2;36m \u001b[0muse color only optimization with sigmoid activation                                         \u001b]8;id=87371;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\u001b\\\u001b[2msplatfacto.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=833039;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#266\u001b\\\u001b[2m266\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-11_171420/nerfstudio_models/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">step-00002</span>\n",
       "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">9999.ckpt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "\u001b[35m/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-11_171420/nerfstudio_models/\u001b[0m\u001b[95mstep-00002\u001b[0m\n",
       "\u001b[95m9999.ckpt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity = splatter.query_mesh(\n",
    "    positive_queries=[\"tree\"],\n",
    "    negative_queries=[\"ground\", \"leaves\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot similarity maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 116178\n",
      "Number of cells: 215841\n",
      "Bounds: BoundsTuple(x_min=-0.5249999761581421, x_max=0.7450000047683716, y_min=-0.125, y_max=1.4850000143051147, z_min=-1.0149999856948853, z_max=1.0214753150939941)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0186f6c4c3754c0e92a0ab4e8f26ee99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34453/index.html?ui=P_0x76d499a8f5e0_17&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splatter.plot_mesh(attribute=similarity, rgb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets clean up the mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix mesh multistep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PYMeshlab testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay, cKDTree\n",
    "from tqdm import tqdm\n",
    "from pymeshfix._meshfix import PyTMesh\n",
    "from pymeshfix import MeshFix\n",
    "import pymeshlab\n",
    "\n",
    "from ns_extension.utils.mesh import normals2vertex, features2vertex\n",
    "\n",
    "def clean_mesh(\n",
    "    mesh_path: str,\n",
    "    max_hole_size: int = 10000,\n",
    "    prevent_self_intersections: bool = True,\n",
    "    quality_threshold: float = 0.1,\n",
    "    edge_length_factor: float = 2.0,\n",
    "    verbose: bool = False\n",
    ") -> pv.PolyData:\n",
    "\n",
    "    mesh = pv.read(mesh_path)\n",
    "    \n",
    "    # Clean and prepare mesh\n",
    "    mesh = mesh.extract_largest().extract_surface().clean()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Input mesh: {mesh.n_points} points, {mesh.n_faces} faces\")\n",
    "    \n",
    "    # Calculate mesh statistics for adaptive parameters\n",
    "    edge_lengths = []\n",
    "    faces = mesh.faces.reshape(-1, 4)[:, 1:]\n",
    "    \n",
    "    for face in faces[:1000]:  # Sample first 1000 faces for efficiency\n",
    "        v0, v1, v2 = mesh.points[face]\n",
    "        edges = [\n",
    "            np.linalg.norm(v1 - v0),\n",
    "            np.linalg.norm(v2 - v1),\n",
    "            np.linalg.norm(v0 - v2)\n",
    "        ]\n",
    "        edge_lengths.extend(edges)\n",
    "    \n",
    "    median_edge_length = np.median(edge_lengths)\n",
    "    max_expected_edge = median_edge_length * edge_length_factor\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Median edge length: {median_edge_length:.4f}\")\n",
    "        print(f\"Max expected edge length: {max_expected_edge:.4f}\")\n",
    "    \n",
    "    # Convert to PyMeshLab\n",
    "    vertices = mesh.points.astype(np.float32)\n",
    "    faces_array = mesh.faces.reshape(-1, 4)[:, 1:]\n",
    "    \n",
    "    ms = pymeshlab.MeshSet()\n",
    "    meshlab_mesh = pymeshlab.Mesh(vertex_matrix=vertices, face_matrix=faces)\n",
    "    ms.add_mesh(meshlab_mesh, \"input_mesh\")\n",
    "    \n",
    "    print(f\"Original mesh: {ms.current_mesh().vertex_number()} vertices, {ms.current_mesh().face_number()} faces\")\n",
    "    \n",
    "    # Step 1: Clean the mesh thoroughly\n",
    "    ms.meshing_remove_duplicate_vertices()\n",
    "    ms.meshing_remove_duplicate_faces() \n",
    "    ms.meshing_remove_null_faces()\n",
    "    ms.meshing_remove_folded_faces()\n",
    "    \n",
    "    # Try to fix non-manifold edges\n",
    "    try:\n",
    "        ms.meshing_remove_non_manifold_edges()\n",
    "        print(\"Removed non-manifold edges\")\n",
    "    except:\n",
    "        print(\"Could not remove non-manifold edges directly\")\n",
    "    \n",
    "    # Alternative approach: split non-manifold vertices\n",
    "    try:\n",
    "        ms.meshing_repair_non_manifold_vertices()\n",
    "        print(\"Repaired non-manifold vertices\")\n",
    "    except:\n",
    "        print(\"Could not repair non-manifold vertices\")\n",
    "    \n",
    "    # Try snap and weld to fix small gaps\n",
    "    try:\n",
    "        ms.meshing_snap_mismatched_borders(edge_dist_thr=0.001)\n",
    "        ms.meshing_merge_close_vertices(threshold=0.0001)\n",
    "        print(\"Snapped borders and merged close vertices\")\n",
    "    except:\n",
    "        print(\"Could not snap borders\")\n",
    "    \n",
    "    # Step 2: Try to close holes with very large threshold\n",
    "    ms.meshing_close_holes(maxholesize=10000, selected=False, newfaceselected=False, selfintersection=True)\n",
    "    \n",
    "    # Step 3: Alternative hole closing if first attempt wasn't enough\n",
    "    ms.meshing_close_holes(maxholesize=20000, selected=False, newfaceselected=False, selfintersection=True)\n",
    "    \n",
    "    # Step 4: Final cleanup\n",
    "    ms.meshing_remove_duplicate_vertices()\n",
    "    ms.meshing_remove_duplicate_faces()\n",
    "    ms.meshing_remove_null_faces()\n",
    "\n",
    "    normals = normals2vertex(filled_mesh.points, mesh.points, mesh.point_data['Normals'])\n",
    "    rgb = features2vertex(filled_mesh.points, mesh.points, mesh.point_data['RGB'])\n",
    "\n",
    "    filled_mesh.point_data['Normals'] = normals\n",
    "    filled_mesh.point_data['RGB'] = np.asarray(rgb).astype(np.uint8)\n",
    "\n",
    "    # Final filtering of triangles with long edges (same as before)\n",
    "    triangles = filled_mesh.faces.reshape((-1, 4))[:, 1:4]\n",
    "    points = filled_mesh.points\n",
    "    tri_verts = points[triangles]\n",
    "    edge_vecs = np.roll(tri_verts, -1, axis=1) - tri_verts\n",
    "    edge_lengths = np.linalg.norm(edge_vecs, axis=2)\n",
    "    mask = np.all(edge_lengths <= edge_length_factor, axis=1)\n",
    "\n",
    "    filtered_triangles = triangles[mask]\n",
    "    flat_faces = np.hstack(np.column_stack((np.full(len(filtered_triangles), 3), filtered_triangles)))\n",
    "    final_mesh = pv.PolyData(points, flat_faces)\n",
    "\n",
    "    # Transfer attributes to filtered mesh\n",
    "    for name in filled_mesh.point_data:\n",
    "        final_mesh.point_data[name] = filled_mesh.point_data[name]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Final mesh: {final_mesh.n_points} points, {final_mesh.n_faces} faces\")\n",
    "\n",
    "    return final_mesh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pymeshfix testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay, cKDTree\n",
    "from tqdm import tqdm\n",
    "from pymeshfix._meshfix import PyTMesh\n",
    "from pymeshfix import MeshFix\n",
    "\n",
    "from ns_extension.utils.mesh import normals2vertex, features2vertex\n",
    "\n",
    "def clean_mesh(\n",
    "    mesh_path: str,\n",
    "    hole_perimeter_threshold: float = 1.0,\n",
    "    max_edge_length: float = 0.2,\n",
    "    properties: list = ['RGB', 'Normals'],\n",
    "    nbe: int = 10000,\n",
    "    verbose: bool = False\n",
    ") -> pv.PolyData:\n",
    "    \n",
    "    # Read in mesh\n",
    "    mesh = pv.read(mesh_path)\n",
    "\n",
    "    # Extract surface of the largest connected component \n",
    "    connectivity = mesh.connectivity()\n",
    "    region_ids = connectivity.cell_data['RegionId']\n",
    "    unique_ids, counts = np.unique(region_ids, return_counts=True)\n",
    "    largest_region_id = unique_ids[np.argmax(counts)]\n",
    "    lcc = connectivity.extract_cells(region_ids == largest_region_id)\n",
    "    mesh = lcc.extract_surface()\n",
    "\n",
    "    for key in mesh.point_data.keys():\n",
    "        if key not in properties:\n",
    "            mesh.point_data.remove(key)\n",
    "\n",
    "    # original_point_data = {name: mesh.point_data[name] for name in mesh.point_data}\n",
    "    # original_pts = mesh.points\n",
    "    # original_faces = mesh.faces.reshape((-1, 4))[:, 1:4]\n",
    "\n",
    "    # boundary_edges = mesh.extract_feature_edges(\n",
    "    #     boundary_edges=True,\n",
    "    #     feature_edges=False,\n",
    "    #     manifold_edges=False,\n",
    "    #     non_manifold_edges=False,\n",
    "    # )\n",
    "    # if boundary_edges.n_lines == 0:\n",
    "    #     if verbose:\n",
    "    #         print(\"[INFO] No holes found. Returning original mesh.\")\n",
    "    #     return mesh.copy()\n",
    "\n",
    "    # connectivity = boundary_edges.connectivity()\n",
    "    # region_ids = connectivity.point_data['RegionId']\n",
    "    # unique_region_ids = np.unique(region_ids)\n",
    "\n",
    "    # all_new_pts = []\n",
    "    # all_new_faces = []\n",
    "    # current_offset = len(original_pts)\n",
    "\n",
    "    # def order_loop_points_fast(pts):\n",
    "    #     pts = np.asarray(pts)\n",
    "    #     N = len(pts)\n",
    "    #     tree = cKDTree(pts)\n",
    "    #     ordered = [0]\n",
    "    #     used = set(ordered)\n",
    "    #     while len(ordered) < N:\n",
    "    #         last_idx = ordered[-1]\n",
    "    #         dists, idxs = tree.query(pts[last_idx], k=10)\n",
    "    #         for i in idxs:\n",
    "    #             if i not in used:\n",
    "    #                 ordered.append(i)\n",
    "    #                 used.add(i)\n",
    "    #                 break\n",
    "    #         else:\n",
    "    #             break\n",
    "    #     return pts[ordered]\n",
    "\n",
    "    # for region_id in tqdm(unique_region_ids, desc=\"Filling holes\"):\n",
    "    #     hole_loop = connectivity.extract_points(region_ids == region_id, adjacent_cells=True)\n",
    "    #     loop_pts = hole_loop.points\n",
    "    #     if len(loop_pts) < 3:\n",
    "    #         continue\n",
    "\n",
    "    #     ordered_pts = order_loop_points_fast(loop_pts)\n",
    "    #     perimeter = np.sum(np.linalg.norm(np.diff(np.vstack([ordered_pts, ordered_pts[0]]), axis=0), axis=1))\n",
    "\n",
    "    #     if perimeter < hole_perimeter_threshold:\n",
    "    #         centroid = ordered_pts.mean(axis=0)\n",
    "    #         pts_centered = ordered_pts - centroid\n",
    "    #         _, _, vh = np.linalg.svd(pts_centered)\n",
    "    #         proj_pts = pts_centered @ vh[:2].T\n",
    "\n",
    "    #         try:\n",
    "    #             tri = Delaunay(proj_pts)\n",
    "    #         except Exception as e:\n",
    "    #             if verbose:\n",
    "    #                 print(f\"Skipping hole due to triangulation error: {e}\")\n",
    "    #             continue\n",
    "\n",
    "    #         hole_faces = tri.simplices\n",
    "    #         all_new_pts.append(ordered_pts)\n",
    "    #         all_new_faces.append(hole_faces + current_offset)\n",
    "    #         current_offset += len(ordered_pts)\n",
    "    #     else:\n",
    "    #         if verbose:\n",
    "    #             print(f\"Skipping hole with perimeter {perimeter:.3f}\")\n",
    "\n",
    "    # # After loop: combine all new points and faces\n",
    "    # if all_new_pts:\n",
    "    #     new_pts = np.vstack(all_new_pts)\n",
    "    #     combined_pts = np.vstack([original_pts, new_pts])\n",
    "    #     new_faces = np.vstack(all_new_faces)\n",
    "    #     combined_faces = np.vstack([original_faces, new_faces])\n",
    "    # else:\n",
    "    #     combined_pts = original_pts\n",
    "    #     combined_faces = original_faces\n",
    "\n",
    "    # # Create the mesh with combined points and faces\n",
    "    # flat_faces = np.hstack(np.column_stack((np.full(len(combined_faces), 3, dtype=int), combined_faces)))\n",
    "    # filled_mesh = pv.PolyData(combined_pts, flat_faces)\n",
    "\n",
    "    meshfix = MeshFix(mesh)\n",
    "    meshfix.repair(verbose=True, joincomp=False, remove_smallest_components=False)\n",
    "    filled_mesh = meshfix.mesh\n",
    "\n",
    "    # # Use the passthrough interface to pymeshfix --> more sensitive but more control\n",
    "    # mfix = PyTMesh(False)\n",
    "    # mfix.load_array(mesh.points, mesh.regular_faces)\n",
    "    # # # mfix.join_closest_components()\n",
    "    \n",
    "    # # mfix.remove_smallest_components()\n",
    "    # holespatched = mfix.fill_small_boundaries(nbe=nbe, refine=True)\n",
    "    # if verbose:\n",
    "    #     print(f\"Patched {holespatched} holes\")\n",
    "    \n",
    "    # # # mfix.boundaries()\n",
    "    # # # mfix.clean(max_iters=8, inner_loops=3)\n",
    "    # v, f = mfix.return_arrays()\n",
    "    # v = np.asarray(v).astype(np.float32)\n",
    "    # f = np.asarray(f).astype(np.int32)\n",
    "\n",
    "    # # Add the face size (3) prefix for each triangle\n",
    "    # num_faces = f.shape[0]\n",
    "    # faces_flat = np.hstack([np.full((num_faces, 1), 3, dtype=np.int32), f])\n",
    "    # faces_flat = faces_flat.flatten()\n",
    "\n",
    "    # # Now create PyVista mesh\n",
    "    # filled_mesh = pv.PolyData(v, faces_flat)\n",
    "\n",
    "    # \"\"\"Convert PyVista PolyData to PyMeshLab Mesh.\"\"\"\n",
    "    # meshlab = pymeshlab.Mesh(\n",
    "    #     vertex_matrix=filled_mesh.points.astype(np.float32), \n",
    "    #     face_matrix=filled_mesh.faces.reshape(-1, 4)[:, 1:]  # remove leading '3's\n",
    "    # )\n",
    "\n",
    "    # ms = pymeshlab.MeshSet()\n",
    "    # ms.add_mesh(meshlab, \"input_mesh\")\n",
    "    # ms.meshing_close_holes(maxholesize=25000, selected=False, newfaceselected=False, selfintersection=True)\n",
    "\n",
    "    # mesh = ms.current_mesh()\n",
    "    # vertices = mesh.vertex_matrix()\n",
    "    # faces = mesh.face_matrix()\n",
    "    \n",
    "    # filled_mesh = pv.PolyData(\n",
    "    #     vertices, \n",
    "    #     np.hstack([np.full((faces.shape[0], 1), 3), faces]).astype(np.int32)\n",
    "    # )\n",
    "    \n",
    "    normals = normals2vertex(filled_mesh.points, mesh.points, mesh.point_data['Normals'])\n",
    "    rgb = features2vertex(filled_mesh.points, mesh.points, mesh.point_data['RGB'])\n",
    "\n",
    "    filled_mesh.point_data['Normals'] = normals\n",
    "    filled_mesh.point_data['RGB'] = np.asarray(rgb).astype(np.uint8)\n",
    "\n",
    "    # Final filtering of triangles with long edges (same as before)\n",
    "    triangles = filled_mesh.faces.reshape((-1, 4))[:, 1:4]\n",
    "    points = filled_mesh.points\n",
    "    tri_verts = points[triangles]\n",
    "    edge_vecs = np.roll(tri_verts, -1, axis=1) - tri_verts\n",
    "    edge_lengths = np.linalg.norm(edge_vecs, axis=2)\n",
    "    mask = np.all(edge_lengths <= max_edge_length, axis=1)\n",
    "\n",
    "    filtered_triangles = triangles[mask]\n",
    "    flat_faces = np.hstack(np.column_stack((np.full(len(filtered_triangles), 3), filtered_triangles)))\n",
    "    final_mesh = pv.PolyData(points, flat_faces)\n",
    "\n",
    "    # Transfer attributes to filtered mesh\n",
    "    for name in filled_mesh.point_data:\n",
    "        final_mesh.point_data[name] = filled_mesh.point_data[name]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Final mesh: {final_mesh.n_points} points, {final_mesh.n_faces} faces\")\n",
    "\n",
    "    return final_mesh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing meshlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating average edge length: 100%|██████████| 268439/268439 [00:04<00:00, 59913.95it/s]\n",
      "Filling holes (822):   2%|▏         | 13/822 [00:00<00:16, 49.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping hole Id_EdgeTag(27) of perimeter 45.35377921021609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling holes (822): 100%|██████████| 822/822 [00:11<00:00, 69.15it/s] \n"
     ]
    }
   ],
   "source": [
    "import meshlib.mrmeshpy as mm\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def collapse_spikes_on_boundary(mesh, threshold=2.0):\n",
    "    collapsed = 0\n",
    "\n",
    "    # Find boundary edge loops\n",
    "    boundary_loops = mm.findLeftBoundary(mesh.topology)\n",
    "\n",
    "    # Flatten list of edge loops\n",
    "    flat_edges = [e for loop in boundary_loops for e in loop]\n",
    "\n",
    "    # Define callback function required by collapseEdge\n",
    "    def on_edge_del(e1, e2):\n",
    "        # This function is called when edges are deleted after collapse\n",
    "        # You can add logging here if needed\n",
    "        pass\n",
    "\n",
    "    for edge in tqdm(flat_edges, desc=\"Collapsing long boundary edges\"):\n",
    "        edge = mm.EdgeId(edge)  # ensure type\n",
    "\n",
    "        org = mesh.topology.org(edge)\n",
    "        dest = mesh.topology.dest(edge)\n",
    "        p0 = mesh.points.vec[org.get()]\n",
    "        p1 = mesh.points.vec[dest.get()]\n",
    "        length = (p0 - p1).length()\n",
    "\n",
    "        if length > threshold:\n",
    "            result = mesh.topology.collapseEdge(edge, on_edge_del)\n",
    "            if result:\n",
    "                collapsed += 1\n",
    "            # Optionally print failures:\n",
    "            else:\n",
    "                print(f\"Collapse failed for edge {edge}, length={length:.4f}\")\n",
    "\n",
    "    print(f\"Collapsed {collapsed} long boundary edges\")\n",
    "\n",
    "def clean_repair_mesh(mesh_path: str, max_hole_size: float = 1.0, max_edge_splits: int = 1000):\n",
    "    \n",
    "    # Load mesh\n",
    "    mesh = mm.loadMesh(mesh_path)\n",
    "    \n",
    "    # Identify all connected components\n",
    "    components = mm.getAllComponents(mesh)\n",
    "\n",
    "    # Determine component sizes\n",
    "    sizes = [mask.count() for mask in components]  # count: faces or vertices\n",
    "    largest_idx = max(range(len(sizes)), key=lambda i: sizes[i])\n",
    "\n",
    "    # Create a new mesh for the largest component\n",
    "    largest_mask = components[largest_idx]\n",
    "    part = mm.Mesh()\n",
    "    part.addPartByMask(mesh, largest_mask)\n",
    "\n",
    "    # Set the mesh to the largest component\n",
    "    mesh = part\n",
    "\n",
    "    avg_edge_length = 0.0\n",
    "    num_edges = 0\n",
    "    for i in trange(mesh.topology.undirectedEdgeSize(), desc=\"Calculating average edge length\"):\n",
    "        dir_edge = mm.EdgeId(i*2)\n",
    "        org = mesh.topology.org(dir_edge)\n",
    "        dest = mesh.topology.dest(dir_edge)\n",
    "        avg_edge_length += (mesh.points.vec[dest.get()] - mesh.points.vec[org.get()]).length()\n",
    "        num_edges = num_edges + 1\n",
    "    avg_edge_length = avg_edge_length/num_edges\n",
    "\n",
    "    # Find all holes\n",
    "    hole_ids = mesh.topology.findHoleRepresentiveEdges()\n",
    "    fill_params = mm.FillHoleParams()\n",
    "    # fill_params.metric = mm.getUniversalMetric(mesh)\n",
    "\n",
    "    # Fill all holes\n",
    "    num_holes = len(hole_ids)\n",
    "    for he in tqdm(hole_ids, desc=f\"Filling holes ({num_holes})\", total=num_holes):\n",
    "        if mesh.holePerimiter( he ) < max_hole_size:\n",
    "            new_faces = mm.FaceBitSet()\n",
    "            fill_params.outNewFaces = new_faces\n",
    "            mm.fillHole( mesh, he, fill_params )\n",
    "\n",
    "            new_verts = mm.VertBitSet()\n",
    "            subdiv_settings = mm.SubdivideSettings()\n",
    "            subdiv_settings.maxEdgeLen = avg_edge_length\n",
    "            subdiv_settings.maxEdgeSplits = max_edge_splits\n",
    "            subdiv_settings.region = new_faces\n",
    "            subdiv_settings.newVerts = new_verts\n",
    "            mm.subdivideMesh(mesh,subdiv_settings)\n",
    "            mm.positionVertsSmoothly(mesh,new_verts)\n",
    "        else:\n",
    "            print(f\"Skipping hole {he} of perimeter {mesh.holePerimiter( he )}\")\n",
    "            \n",
    "    return mesh\n",
    "\n",
    "mesh = clean_repair_mesh(splatter.config['mesh_info']['mesh'], max_hole_size=3.0, max_edge_splits=10000)\n",
    "mm.saveMesh(mesh, \"test.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_mesh = pv.read(\"test.ply\")\n",
    "original_mesh = pv.read(splatter.config['mesh_info']['mesh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ns_extension.utils.mesh import normals2vertex, features2vertex\n",
    "\n",
    "normals = normals2vertex(cleaned_mesh.points, original_mesh.points, original_mesh.point_data['Normals'])\n",
    "rgb = features2vertex(cleaned_mesh.points, original_mesh.points, original_mesh.point_data['RGB'])\n",
    "tree_features = features2vertex(cleaned_mesh.points, original_mesh.points, similarity)\n",
    "\n",
    "cleaned_mesh.point_data['Normals'] = normals\n",
    "cleaned_mesh.point_data['RGB'] = np.asarray(rgb).astype(np.uint8)\n",
    "cleaned_mesh.point_data['tree'] = tree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding normals\n",
      "\u001b[1;33m[Open3D WARNING] Write geometry::TriangleMesh failed: unknown file extension.\u001b[0;m\n",
      "Saved: example_mesh\n",
      "Saved: example_mesh_tree.ply\n"
     ]
    }
   ],
   "source": [
    "save_pyvista_to_open3d_ply(cleaned_mesh, \"example_mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_pyvista_to_open3d_ply(pv_mesh, filename_base):\n",
    "    \"\"\"\n",
    "    Save a PyVista mesh to Open3D-compatible PLY format.\n",
    "    \n",
    "    Parameters:\n",
    "        pv_mesh (pyvista.PolyData): Input mesh with point data.\n",
    "        filename_base (str): Base filename without extension.\n",
    "    \"\"\"\n",
    "    # Extract basic geometry\n",
    "    points = np.asarray(pv_mesh.points)\n",
    "    faces = pv_mesh.faces.reshape((-1, 4))[:, 1:]  # triangle faces assumed\n",
    "\n",
    "    # Prepare base Open3D mesh\n",
    "    base_mesh = o3d.geometry.TriangleMesh()\n",
    "    base_mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "    base_mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "\n",
    "    # Handle RGB\n",
    "    if \"RGB\" in pv_mesh.point_data:\n",
    "        rgb = np.asarray(pv_mesh.point_data[\"RGB\"])\n",
    "        if rgb.max() > 1.0:\n",
    "            rgb = rgb / 255.0\n",
    "        base_mesh.vertex_colors = o3d.utility.Vector3dVector(rgb)\n",
    "    \n",
    "    # Handle normals\n",
    "    if \"Normals\" in pv_mesh.point_data:\n",
    "        print (f\"Adding normals\")\n",
    "        normals = np.asarray(pv_mesh.point_data[\"Normals\"])\n",
    "        base_mesh.vertex_normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "    # Save main mesh\n",
    "    main_path = f\"{filename_base}\"\n",
    "    o3d.io.write_triangle_mesh(main_path, base_mesh, write_ascii=True)\n",
    "    print(f\"Saved: {main_path}\")\n",
    "\n",
    "    # Save other point data fields in separate files\n",
    "    for key in pv_mesh.point_data.keys():\n",
    "        if key in [\"RGB\", \"Normals\"]:\n",
    "            continue\n",
    "        \n",
    "        attr = np.asarray(pv_mesh.point_data[key])\n",
    "        if attr.ndim == 1:\n",
    "            attr = attr[:, np.newaxis]\n",
    "        if attr.shape[1] > 3:\n",
    "            print(f\"Skipping {key}: more than 3 channels (shape={attr.shape})\")\n",
    "            continue\n",
    "\n",
    "        # Normalize and pad to RGB\n",
    "        color_data = np.zeros((len(attr), 3))\n",
    "        norm_attr = attr.astype(np.float64)\n",
    "        if np.max(norm_attr) > 0:\n",
    "            norm_attr /= np.max(norm_attr)\n",
    "        color_data[:, :attr.shape[1]] = norm_attr\n",
    "\n",
    "        # Build new mesh\n",
    "        custom_mesh = o3d.geometry.TriangleMesh()\n",
    "        custom_mesh.vertices = o3d.utility.Vector3dVector(points)\n",
    "        custom_mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "        custom_mesh.vertex_colors = o3d.utility.Vector3dVector(color_data)\n",
    "\n",
    "        # Save it\n",
    "        out_path = f\"{filename_base}_{key}.ply\"\n",
    "        o3d.io.write_triangle_mesh(out_path, custom_mesh, write_ascii=True)\n",
    "        print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(\"example_mesh.ply\")\n",
    "\n",
    "# o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.has_vertex_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee4342b52fa469eaf3bc230805ed06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:35473/index.html?ui=P_0x7c0d33d9c130_4&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "vis_mesh = pv.read(\"example_mesh_tree.ply\")\n",
    "\n",
    "vis_mesh.plot(scalars='RGB', rgb=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style='width: 100%;'><tr><th>Header</th><th>Data Arrays</th></tr><tr><td>\n",
       "<table style='width: 100%;'>\n",
       "<tr><th>PolyData</th><th>Information</th></tr>\n",
       "<tr><td>N Cells</td><td>200193</td></tr>\n",
       "<tr><td>N Points</td><td>102294</td></tr>\n",
       "<tr><td>N Strips</td><td>0</td></tr>\n",
       "<tr><td>X Bounds</td><td>-5.050e-01, 7.450e-01</td></tr>\n",
       "<tr><td>Y Bounds</td><td>-1.250e-01, 1.485e+00</td></tr>\n",
       "<tr><td>Z Bounds</td><td>-1.015e+00, 9.950e-01</td></tr>\n",
       "<tr><td>N Arrays</td><td>1</td></tr>\n",
       "</table>\n",
       "\n",
       "</td><td>\n",
       "<table style='width: 100%;'>\n",
       "<tr><th>Name</th><th>Field</th><th>Type</th><th>N Comp</th><th>Min</th><th>Max</th></tr>\n",
       "<tr><td><b>RGB</b></td><td>Points</td><td>uint8</td><td>3</td><td>0.000e+00</td><td>1.860e+02</td></tr>\n",
       "</table>\n",
       "\n",
       "</td></tr> </table>"
      ],
      "text/plain": [
       "PolyData (0x7ab6baa3a980)\n",
       "  N Cells:    200193\n",
       "  N Points:   102294\n",
       "  N Strips:   0\n",
       "  X Bounds:   -5.050e-01, 7.450e-01\n",
       "  Y Bounds:   -1.250e-01, 1.485e+00\n",
       "  Z Bounds:   -1.015e+00, 9.950e-01\n",
       "  N Arrays:   1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d90e513b7248609a8dd81d557c34bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:35387/index.html?ui=P_0x70945df9c040_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO- Loaded 93502 vertices and 174788 faces.\n",
      "Patching holes...\n",
      "\n",
      "0% done Patched 789 holes\n",
      "Fixing degeneracies and intersections\n",
      "100% done \n",
      "INFO- ********* ITERATION 0 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 18862 intersecting triangles have been selected.\n",
      "\n",
      "99 % done   \n",
      "INFO- 2122 intersecting triangles have been selected.\n",
      "\n",
      "99 % done   \n",
      "INFO- 1123 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 1 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "98 % done   \n",
      "INFO- 1548 intersecting triangles have been selected.\n",
      "\n",
      "96 % done   \n",
      "INFO- 463 intersecting triangles have been selected.\n",
      "\n",
      "97 % done   \n",
      "INFO- 526 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 2 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 144 intersecting triangles have been selected.\n",
      "\n",
      "95 % done   \n",
      "INFO- 540 intersecting triangles have been selected.\n",
      "\n",
      "99 % done   \n",
      "INFO- 1105 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 3 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "98 % done   \n",
      "INFO- 191 intersecting triangles have been selected.\n",
      "\n",
      "77 % done   \n",
      "INFO- 342 intersecting triangles have been selected.\n",
      "\n",
      "97 % done   \n",
      "INFO- 121 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 4 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "98 % done   \n",
      "INFO- 60 intersecting triangles have been selected.\n",
      "\n",
      "69 % done   \n",
      "INFO- 39 intersecting triangles have been selected.\n",
      "\n",
      "83 % done   \n",
      "INFO- 17 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 5 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 91 intersecting triangles have been selected.\n",
      "\n",
      "95 % done   \n",
      "INFO- 52 intersecting triangles have been selected.\n",
      "\n",
      "98 % done   \n",
      "INFO- 76 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 6 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 62 intersecting triangles have been selected.\n",
      "\n",
      "84 % done   \n",
      "INFO- 28 intersecting triangles have been selected.\n",
      "\n",
      "99 % done   \n",
      "INFO- 36 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 7 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 34 intersecting triangles have been selected.\n",
      "\n",
      "82 % done   \n",
      "INFO- 64 intersecting triangles have been selected.\n",
      "\n",
      "84 % done   \n",
      "INFO- 37 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 8 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 72 intersecting triangles have been selected.\n",
      "\n",
      "80 % done   \n",
      "INFO- 51 intersecting triangles have been selected.\n",
      "\n",
      "90 % done   \n",
      "INFO- 6 intersecting triangles have been selected.\n",
      "INFO- ********* ITERATION 9 *********\n",
      "INFO- Removing degeneracies...\n",
      "INFO- Removing self-intersections...\n",
      "\n",
      "99 % done   \n",
      "INFO- 28 intersecting triangles have been selected.\n",
      "\n",
      "0 % done   \n",
      "INFO- 21 intersecting triangles have been selected.\n",
      "\n",
      "93 % done   \n",
      "INFO- 20 intersecting triangles have been selected.\n",
      "Final mesh: 36257 points, 72709 faces\n"
     ]
    }
   ],
   "source": [
    "final_mesh = clean_mesh(\n",
    "    splatter.config['mesh_info']['mesh'], \n",
    "    # hole_perimeter_threshold=2.0,\n",
    "    # nbe=0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c5c29eb7be497999a69fe32fb2014c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34453/index.html?ui=P_0x76d499aaeb00_20&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_mesh.plot(scalars='RGB', rgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
