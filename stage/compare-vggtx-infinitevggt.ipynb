{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGT-X vs InfiniteVGGT Comparison on Bicycle Scene\n",
    "\n",
    "This notebook runs parallel pipelines to compare VGGT-X and InfiniteVGGT on the bicycle dataset.\n",
    "\n",
    "## Comparison Goals\n",
    "\n",
    "1. **Run both methods** on the same input images (images_4 - 4x downsampled)\n",
    "2. **Compare outputs**:\n",
    "   - Camera intrinsics\n",
    "   - Camera extrinsics (poses)\n",
    "   - 3D point clouds\n",
    "   - Reconstruction statistics\n",
    "3. **Save to separate directories** for downstream gaussian splatting comparison\n",
    "4. **Bundle adjustment testing** via matching procedure to get tracks across images\n",
    "\n",
    "## Directory Structure\n",
    "\n",
    "```\n",
    "/workspace/bicycle/\n",
    "├── images_4/                    # 4x downsampled images\n",
    "├── vggtx_output/                # VGGT-X results\n",
    "│   ├── preproc/\n",
    "│   │   ├── colmap/sparse/0/\n",
    "│   │   ├── transforms.json\n",
    "│   │   └── sparse_pc.ply\n",
    "│   └── matches/                 # Matching results for BA\n",
    "└── infinitevggt_output/         # InfiniteVGGT results\n",
    "    ├── preproc/\n",
    "    │   ├── colmap/sparse/0/\n",
    "    │   ├── transforms.json\n",
    "    │   └── sparse_pc.ply\n",
    "    └── matches/                 # Matching results for BA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pycolmap\n",
    "\n",
    "# Verify conda environment\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "if 'nerfstudio' not in sys.executable:\n",
    "    print(\"\\n⚠️  WARNING: Not running in nerfstudio conda environment!\")\n",
    "    print(\"Please activate with: conda activate nerfstudio\")\n",
    "else:\n",
    "    print(\"\\n✓ Running in nerfstudio environment\")\n",
    "\n",
    "# Add InfiniteVGGT to Python path\n",
    "infinitevggt_root = Path(\"/workspace/InfiniteVGGT\")\n",
    "if str(infinitevggt_root / \"src\") not in sys.path:\n",
    "    sys.path.append(str(infinitevggt_root / \"src\"))\n",
    "\n",
    "# Import InfiniteVGGT components\n",
    "from streamvggt.models.streamvggt import StreamVGGT\n",
    "from streamvggt.utils.load_fn import load_and_preprocess_images\n",
    "from streamvggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "\n",
    "# Import nerfstudio utilities\n",
    "from nerfstudio.process_data import vggt_utils, colmap_utils\n",
    "from nerfstudio.process_data.process_data_utils import CameraModel\n",
    "from nerfstudio.utils.rich_utils import CONSOLE\n",
    "\n",
    "from vggt.utils.load_fn import load_and_preprocess_images_ratio\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dataset Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Input: Downsampled bicycle images\n",
    "base_dir = Path(\"/workspace/bicycle\")\n",
    "image_dir = base_dir / \"images_4\"  # 4x downsampled images\n",
    "\n",
    "# Output directories\n",
    "vggtx_output_dir = base_dir / \"vggtx_output\"\n",
    "vggtx_preproc_dir = vggtx_output_dir / \"preproc\"\n",
    "vggtx_colmap_dir = vggtx_preproc_dir / \"colmap\"\n",
    "vggtx_matches_dir = vggtx_output_dir / \"matches\"\n",
    "\n",
    "infinitevggt_output_dir = base_dir / \"infinitevggt_output\"\n",
    "infinitevggt_preproc_dir = infinitevggt_output_dir / \"preproc\"\n",
    "infinitevggt_colmap_dir = infinitevggt_preproc_dir / \"colmap\"\n",
    "infinitevggt_matches_dir = infinitevggt_output_dir / \"matches\"\n",
    "\n",
    "# Create directories\n",
    "vggtx_colmap_dir.mkdir(parents=True, exist_ok=True)\n",
    "vggtx_matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "infinitevggt_colmap_dir.mkdir(parents=True, exist_ok=True)\n",
    "infinitevggt_matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check input images\n",
    "image_paths = sorted(list(image_dir.glob(\"*.JPG\")) + list(image_dir.glob(\"*.png\")))\n",
    "print(f\"Input images: {image_dir}\")\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "print(f\"\\nVGGT-X output: {vggtx_output_dir}\")\n",
    "print(f\"InfiniteVGGT output: {infinitevggt_output_dir}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Model Parameters\n",
    "# ============================================================================\n",
    "\n",
    "# VGGT-X parameters\n",
    "vggtx_camera_model = \"PINHOLE\"\n",
    "vggtx_scale_factor = 1.0\n",
    "vggtx_use_global_alignment = True\n",
    "vggtx_conf_threshold = 50.0\n",
    "\n",
    "# InfiniteVGGT parameters\n",
    "infinitevggt_checkpoint = Path(\"/workspace/InfiniteVGGT/checkpoints/streamvggt.pth\")\n",
    "infinitevggt_total_budget = 1200000\n",
    "infinitevggt_conf_threshold = 50.0\n",
    "infinitevggt_scale_factor = 1.0\n",
    "infinitevggt_shared_camera = True\n",
    "\n",
    "# Common parameters\n",
    "max_points_for_colmap = 500000\n",
    "\n",
    "print(f\"\\nVGGT-X Config:\")\n",
    "print(f\"  Camera model: {vggtx_camera_model}\")\n",
    "print(f\"  Scale factor: {vggtx_scale_factor}\")\n",
    "print(f\"  Global alignment: {vggtx_use_global_alignment}\")\n",
    "print(f\"\\nInfiniteVGGT Config:\")\n",
    "print(f\"  Total budget: {infinitevggt_total_budget:,}\")\n",
    "print(f\"  Checkpoint: {infinitevggt_checkpoint}\")\n",
    "print(f\"  Checkpoint exists: {infinitevggt_checkpoint.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1: VGGT-X\n",
    "\n",
    "Run VGGT-X (standard VGGT) on the bicycle images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RUNNING VGGT-X PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Track timing\n",
    "vggtx_start_time = time.time()\n",
    "\n",
    "# Run VGGT with global alignment\n",
    "vggt_utils.run_vggt(\n",
    "    image_dir=image_dir,\n",
    "    colmap_dir=vggtx_colmap_dir,\n",
    "    camera_model=vggtx_camera_model,\n",
    "    scale_factor=vggtx_scale_factor,\n",
    "    use_global_alignment=vggtx_use_global_alignment,\n",
    "    lambda_depth=0.25,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "vggtx_end_time = time.time()\n",
    "vggtx_inference_time = vggtx_end_time - vggtx_start_time\n",
    "\n",
    "print(f\"\\n✓ VGGT-X reconstruction complete!\")\n",
    "print(f\"  Time: {vggtx_inference_time:.2f}s\")\n",
    "print(f\"  Output: {vggtx_colmap_dir / 'sparse' / '0'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to nerfstudio format\n",
    "print(\"\\nConverting VGGT-X to nerfstudio format...\")\n",
    "\n",
    "colmap_utils.colmap_to_json(\n",
    "    recon_dir=vggtx_colmap_dir / \"sparse\" / \"0\",\n",
    "    output_dir=vggtx_preproc_dir,\n",
    ")\n",
    "\n",
    "# Load transforms to get applied_transform\n",
    "vggtx_transforms_path = vggtx_preproc_dir / \"transforms.json\"\n",
    "with open(vggtx_transforms_path) as f:\n",
    "    vggtx_transforms = json.load(f)\n",
    "\n",
    "vggtx_applied_transform = torch.tensor(vggtx_transforms[\"applied_transform\"])\n",
    "\n",
    "# Create point cloud PLY file\n",
    "vggtx_ply_filename = \"sparse_pc.ply\"\n",
    "colmap_utils.create_ply_from_colmap(\n",
    "    filename=vggtx_ply_filename,\n",
    "    recon_dir=vggtx_colmap_dir / \"sparse\" / \"0\",\n",
    "    output_dir=vggtx_preproc_dir,\n",
    "    applied_transform=vggtx_applied_transform,\n",
    ")\n",
    "\n",
    "# Update transforms.json with PLY path\n",
    "vggtx_transforms[\"ply_file_path\"] = vggtx_ply_filename\n",
    "with open(vggtx_transforms_path, 'w') as f:\n",
    "    json.dump(vggtx_transforms, f, indent=2)\n",
    "\n",
    "print(f\"✓ VGGT-X nerfstudio format complete\")\n",
    "print(f\"  transforms.json: {vggtx_transforms_path}\")\n",
    "print(f\"  Point cloud: {vggtx_preproc_dir / vggtx_ply_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2: InfiniteVGGT\n",
    "\n",
    "Run InfiniteVGGT on the same bicycle images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run VGGT with global alignment\n",
    "vggt_utils.run_infinite_vggt(\n",
    "    image_dir=image_dir,\n",
    "    colmap_dir=infinitevggt_colmap_dir,\n",
    "    camera_model=vggtx_camera_model,\n",
    "    scale_factor=vggtx_scale_factor,\n",
    "    use_global_alignment=True,\n",
    "    lambda_depth=0.25,\n",
    "    verbose=True,\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to nerfstudio format\n",
    "print(\"\\nConverting InfiniteVGGT to nerfstudio format...\")\n",
    "\n",
    "colmap_utils.colmap_to_json(\n",
    "    recon_dir=infinitevggt_colmap_dir / \"sparse\" / \"0\",\n",
    "    output_dir=infinitevggt_preproc_dir,\n",
    ")\n",
    "\n",
    "# Load transforms to get applied_transform\n",
    "infinitevggt_transforms_path = infinitevggt_preproc_dir / \"transforms.json\"\n",
    "with open(infinitevggt_transforms_path) as f:\n",
    "    infinitevggt_transforms = json.load(f)\n",
    "\n",
    "infinitevggt_applied_transform = torch.tensor(infinitevggt_transforms[\"applied_transform\"])\n",
    "\n",
    "# Create point cloud PLY file\n",
    "infinitevggt_ply_filename = \"sparse_pc.ply\"\n",
    "colmap_utils.create_ply_from_colmap(\n",
    "    filename=infinitevggt_ply_filename,\n",
    "    recon_dir=infinitevggt_colmap_dir / \"sparse\" / \"0\",\n",
    "    output_dir=infinitevggt_preproc_dir,\n",
    "    applied_transform=infinitevggt_applied_transform,\n",
    ")\n",
    "\n",
    "# Update transforms.json with PLY path\n",
    "infinitevggt_transforms[\"ply_file_path\"] = infinitevggt_ply_filename\n",
    "with open(infinitevggt_transforms_path, 'w') as f:\n",
    "    json.dump(infinitevggt_transforms, f, indent=2)\n",
    "\n",
    "print(f\"✓ InfiniteVGGT nerfstudio format complete\")\n",
    "print(f\"  transforms.json: {infinitevggt_transforms_path}\")\n",
    "print(f\"  Point cloud: {infinitevggt_preproc_dir / infinitevggt_ply_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Camera Intrinsics and Extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPARING CAMERA PARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load VGGT-X reconstruction\n",
    "vggtx_reconstruction = pycolmap.Reconstruction(str(vggtx_colmap_dir / \"sparse\" / \"0\"))\n",
    "\n",
    "# Load InfiniteVGGT reconstruction\n",
    "infinitevggt_reconstruction = pycolmap.Reconstruction(str(infinitevggt_colmap_dir / \"sparse\" / \"0\"))\n",
    "\n",
    "print(f\"\\nVGGT-X Reconstruction:\")\n",
    "print(f\"  Cameras: {len(vggtx_reconstruction.cameras)}\")\n",
    "print(f\"  Images: {len(vggtx_reconstruction.images)}\")\n",
    "print(f\"  Points3D: {len(vggtx_reconstruction.points3D):,}\")\n",
    "\n",
    "print(f\"\\nInfiniteVGGT Reconstruction:\")\n",
    "print(f\"  Cameras: {len(infinitevggt_reconstruction.cameras)}\")\n",
    "print(f\"  Images: {len(infinitevggt_reconstruction.images)}\")\n",
    "print(f\"  Points3D: {len(infinitevggt_reconstruction.points3D):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare camera intrinsics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CAMERA INTRINSICS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get first camera from each reconstruction\n",
    "vggtx_cam = list(vggtx_reconstruction.cameras.values())[0]\n",
    "infinitevggt_cam = list(infinitevggt_reconstruction.cameras.values())[0]\n",
    "\n",
    "print(f\"\\nVGGT-X Camera:\")\n",
    "print(f\"  Model: {vggtx_cam.model}\")\n",
    "print(f\"  Width: {vggtx_cam.width}\")\n",
    "print(f\"  Height: {vggtx_cam.height}\")\n",
    "print(f\"  Params: {vggtx_cam.params}\")\n",
    "\n",
    "print(f\"\\nInfiniteVGGT Camera:\")\n",
    "print(f\"  Model: {infinitevggt_cam.model}\")\n",
    "print(f\"  Width: {infinitevggt_cam.width}\")\n",
    "print(f\"  Height: {infinitevggt_cam.height}\")\n",
    "print(f\"  Params: {infinitevggt_cam.params}\")\n",
    "\n",
    "# Calculate differences in focal length and principal point\n",
    "# if vggtx_cam.model_name == \"PINHOLE\" and infinitevggt_cam.model_name in [\"PINHOLE\", \"SIMPLE_PINHOLE\"]:\n",
    "vggtx_fx = vggtx_cam.params[0]\n",
    "vggtx_fy = vggtx_cam.params[1]\n",
    "vggtx_cx = vggtx_cam.params[2]\n",
    "vggtx_cy = vggtx_cam.params[3]\n",
    "    \n",
    "    # if infinitevggt_cam.model_name == \"SIMPLE_PINHOLE\":\n",
    "    #     infinitevggt_fx = infinitevggt_cam.params[0]\n",
    "    #     infinitevggt_fy = infinitevggt_cam.params[0]\n",
    "    #     infinitevggt_cx = infinitevggt_cam.params[1]\n",
    "    #     infinitevggt_cy = infinitevggt_cam.params[2]\n",
    "    # else:\n",
    "infinitevggt_fx = infinitevggt_cam.params[0]\n",
    "infinitevggt_fy = infinitevggt_cam.params[1]\n",
    "infinitevggt_cx = infinitevggt_cam.params[2]\n",
    "infinitevggt_cy = infinitevggt_cam.params[3]\n",
    "\n",
    "print(f\"\\nFocal Length Comparison:\")\n",
    "print(f\"  VGGT-X fx: {vggtx_fx:.2f}, fy: {vggtx_fy:.2f}\")\n",
    "print(f\"  InfiniteVGGT fx: {infinitevggt_fx:.2f}, fy: {infinitevggt_fy:.2f}\")\n",
    "print(f\"  Difference fx: {abs(vggtx_fx - infinitevggt_fx):.2f} ({abs(vggtx_fx - infinitevggt_fx)/vggtx_fx*100:.2f}%)\")\n",
    "print(f\"  Difference fy: {abs(vggtx_fy - infinitevggt_fy):.2f} ({abs(vggtx_fy - infinitevggt_fy)/vggtx_fy*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nPrincipal Point Comparison:\")\n",
    "print(f\"  VGGT-X cx: {vggtx_cx:.2f}, cy: {vggtx_cy:.2f}\")\n",
    "print(f\"  InfiniteVGGT cx: {infinitevggt_cx:.2f}, cy: {infinitevggt_cy:.2f}\")\n",
    "print(f\"  Difference cx: {abs(vggtx_cx - infinitevggt_cx):.2f}\")\n",
    "print(f\"  Difference cy: {abs(vggtx_cy - infinitevggt_cy):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare camera extrinsics (poses)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CAMERA EXTRINSICS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate pose differences\n",
    "pose_differences = []\n",
    "\n",
    "for img_id, vggtx_img in vggtx_reconstruction.images.items():\n",
    "    if img_id in infinitevggt_reconstruction.images:\n",
    "        infinitevggt_img = infinitevggt_reconstruction.images[img_id]\n",
    "        \n",
    "        # Get rotation and translation\n",
    "        vggtx_R = vggtx_img.rotmat()\n",
    "        vggtx_t = vggtx_img.tvec\n",
    "        infinitevggt_R = infinitevggt_img.rotmat()\n",
    "        infinitevggt_t = infinitevggt_img.tvec\n",
    "        \n",
    "        # Calculate rotation difference (Frobenius norm)\n",
    "        R_diff = np.linalg.norm(vggtx_R - infinitevggt_R, 'fro')\n",
    "        \n",
    "        # Calculate translation difference (Euclidean distance)\n",
    "        t_diff = np.linalg.norm(vggtx_t - infinitevggt_t)\n",
    "        \n",
    "        pose_differences.append({\n",
    "            'image_id': img_id,\n",
    "            'image_name': vggtx_img.name,\n",
    "            'R_diff': R_diff,\n",
    "            't_diff': t_diff,\n",
    "        })\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "pose_df = pd.DataFrame(pose_differences)\n",
    "\n",
    "print(f\"\\nPose Differences (N={len(pose_df)}):\")\n",
    "print(f\"  Rotation (Frobenius norm):\")\n",
    "print(f\"    Mean: {pose_df['R_diff'].mean():.4f}\")\n",
    "print(f\"    Std: {pose_df['R_diff'].std():.4f}\")\n",
    "print(f\"    Min: {pose_df['R_diff'].min():.4f}\")\n",
    "print(f\"    Max: {pose_df['R_diff'].max():.4f}\")\n",
    "\n",
    "print(f\"\\n  Translation (Euclidean distance):\")\n",
    "print(f\"    Mean: {pose_df['t_diff'].mean():.4f}\")\n",
    "print(f\"    Std: {pose_df['t_diff'].std():.4f}\")\n",
    "print(f\"    Min: {pose_df['t_diff'].min():.4f}\")\n",
    "print(f\"    Max: {pose_df['t_diff'].max():.4f}\")\n",
    "\n",
    "# Show top 5 images with largest differences\n",
    "print(f\"\\nTop 5 images with largest pose differences:\")\n",
    "top5 = pose_df.nlargest(5, 't_diff')[['image_name', 'R_diff', 't_diff']]\n",
    "print(top5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"POINT CLOUD COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract 3D points\n",
    "vggtx_points = np.array([pt.xyz for pt in vggtx_reconstruction.points3D.values()])\n",
    "infinitevggt_points = np.array([pt.xyz for pt in infinitevggt_reconstruction.points3D.values()])\n",
    "\n",
    "print(f\"\\nVGGT-X Point Cloud:\")\n",
    "print(f\"  Number of points: {len(vggtx_points):,}\")\n",
    "print(f\"  Bounding box min: {vggtx_points.min(axis=0)}\")\n",
    "print(f\"  Bounding box max: {vggtx_points.max(axis=0)}\")\n",
    "print(f\"  Mean position: {vggtx_points.mean(axis=0)}\")\n",
    "\n",
    "print(f\"\\nInfiniteVGGT Point Cloud:\")\n",
    "print(f\"  Number of points: {len(infinitevggt_points):,}\")\n",
    "print(f\"  Bounding box min: {infinitevggt_points.min(axis=0)}\")\n",
    "print(f\"  Bounding box max: {infinitevggt_points.max(axis=0)}\")\n",
    "print(f\"  Mean position: {infinitevggt_points.mean(axis=0)}\")\n",
    "\n",
    "# Calculate point cloud statistics\n",
    "vggtx_bbox_size = vggtx_points.max(axis=0) - vggtx_points.min(axis=0)\n",
    "infinitevggt_bbox_size = infinitevggt_points.max(axis=0) - infinitevggt_points.min(axis=0)\n",
    "\n",
    "print(f\"\\nBounding Box Size Comparison:\")\n",
    "print(f\"  VGGT-X: {vggtx_bbox_size}\")\n",
    "print(f\"  InfiniteVGGT: {infinitevggt_bbox_size}\")\n",
    "print(f\"  Difference: {np.abs(vggtx_bbox_size - infinitevggt_bbox_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Side-by-Side Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "print(\"Loading point clouds for visualization...\")\n",
    "\n",
    "# Load PLY files\n",
    "vggtx_pcd = pv.PolyData(str(vggtx_preproc_dir / vggtx_ply_filename))\n",
    "infinitevggt_pcd = pv.PolyData(str(infinitevggt_preproc_dir / infinitevggt_ply_filename))\n",
    "\n",
    "print(f\"\\nVGGT-X point cloud: {vggtx_pcd.n_points:,} points\")\n",
    "print(f\"InfiniteVGGT point cloud: {infinitevggt_pcd.n_points:,} points\")\n",
    "\n",
    "# Create side-by-side visualization\n",
    "plotter = pv.Plotter(shape=(1, 2))\n",
    "\n",
    "# VGGT-X on the left\n",
    "plotter.subplot(0, 0)\n",
    "plotter.add_text(\"VGGT-X\", font_size=14)\n",
    "plotter.add_mesh(\n",
    "    vggtx_pcd,\n",
    "    point_size=2,\n",
    "    render_points_as_spheres=True,\n",
    ")\n",
    "plotter.add_axes()\n",
    "\n",
    "# InfiniteVGGT on the right\n",
    "plotter.subplot(0, 1)\n",
    "plotter.add_text(\"InfiniteVGGT\", font_size=14)\n",
    "plotter.add_mesh(\n",
    "    infinitevggt_pcd,\n",
    "    point_size=2,\n",
    "    render_points_as_spheres=True,\n",
    ")\n",
    "plotter.add_axes()\n",
    "\n",
    "# Link cameras for synchronized viewing\n",
    "plotter.link_views()\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Images: {len(image_paths)}\")\n",
    "print(f\"  Input directory: {image_dir}\")\n",
    "\n",
    "print(f\"\\nVGGT-X:\")\n",
    "print(f\"  Inference time: {vggtx_inference_time:.2f}s\")\n",
    "print(f\"  Time per frame: {vggtx_inference_time / len(image_paths):.3f}s\")\n",
    "print(f\"  Cameras: {len(vggtx_reconstruction.cameras)}\")\n",
    "print(f\"  Images registered: {len(vggtx_reconstruction.images)}\")\n",
    "print(f\"  3D points: {len(vggtx_reconstruction.points3D):,}\")\n",
    "print(f\"  Output: {vggtx_output_dir}\")\n",
    "\n",
    "print(f\"\\nInfiniteVGGT:\")\n",
    "print(f\"  Inference time: {infinitevggt_inference_time:.2f}s\")\n",
    "print(f\"  Time per frame: {infinitevggt_inference_time / len(image_paths):.3f}s\")\n",
    "print(f\"  Peak GPU memory: {infinitevggt_peak_memory_gb:.2f} GB\")\n",
    "print(f\"  Cameras: {len(infinitevggt_reconstruction.cameras)}\")\n",
    "print(f\"  Images registered: {len(infinitevggt_reconstruction.images)}\")\n",
    "print(f\"  3D points: {len(infinitevggt_reconstruction.points3D):,}\")\n",
    "print(f\"  Output: {infinitevggt_output_dir}\")\n",
    "\n",
    "print(f\"\\nSpeedup:\")\n",
    "speedup = vggtx_inference_time / infinitevggt_inference_time\n",
    "if speedup > 1:\n",
    "    print(f\"  InfiniteVGGT is {speedup:.2f}x faster than VGGT-X\")\n",
    "else:\n",
    "    print(f\"  VGGT-X is {1/speedup:.2f}x faster than InfiniteVGGT\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle Adjustment: Feature Matching\n",
    "\n",
    "To test how bundle adjustment affects each method, we need to run the matching procedure to get tracks across images. This uses feature matching to create correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FEATURE MATCHING FOR BUNDLE ADJUSTMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# This function runs feature matching and returns match outputs\n",
    "# The match outputs include:\n",
    "# - Feature keypoints for each image\n",
    "# - Feature descriptors\n",
    "# - Matches between image pairs\n",
    "# - Confidence scores\n",
    "\n",
    "from nerfstudio.process_data.vggt_utils import _run_global_alignment\n",
    "\n",
    "print(\"\\nNote: Feature matching was already performed during global alignment.\")\n",
    "print(\"Match outputs are stored in the following variables:\")\n",
    "print(\"  - match_outputs (from InfiniteVGGT global alignment)\")\n",
    "print(\"\\nTo use these matches for bundle adjustment, you can:\")\n",
    "print(\"  1. Extract tracks from match_outputs\")\n",
    "print(\"  2. Run pycolmap bundle adjustment with these tracks\")\n",
    "print(\"  3. Compare refined vs. original camera parameters\")\n",
    "\n",
    "# Save match information for both methods\n",
    "print(f\"\\nMatch statistics:\")\n",
    "if 'match_outputs' in locals() and match_outputs is not None:\n",
    "    # Count matches\n",
    "    total_matches = sum(len(m) for m in match_outputs['matches'])\n",
    "    print(f\"  Total feature matches: {total_matches:,}\")\n",
    "    print(f\"  Average matches per pair: {total_matches / len(match_outputs['matches']):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract tracks from matches for bundle adjustment\n",
    "# This creates a track graph that can be used with pycolmap BA\n",
    "\n",
    "def create_track_graph_from_matches(match_outputs, image_paths):\n",
    "    \"\"\"Create a simple track graph from match outputs.\n",
    "    \n",
    "    Returns a dictionary mapping track_id -> [(image_idx, keypoint_idx), ...]\n",
    "    \"\"\"\n",
    "    tracks = {}\n",
    "    track_id = 0\n",
    "    \n",
    "    # This is a simplified version - in practice, you'd want to use\n",
    "    # transitive closure to connect matches across multiple images\n",
    "    print(\"Track creation would go here...\")\n",
    "    print(\"In a full implementation, you would:\")\n",
    "    print(\"  1. Build a graph of feature correspondences\")\n",
    "    print(\"  2. Find connected components (tracks)\")\n",
    "    print(\"  3. Associate each track with a 3D point\")\n",
    "    print(\"  4. Use these tracks in pycolmap bundle adjustment\")\n",
    "    \n",
    "    return tracks\n",
    "\n",
    "# Note: For actual bundle adjustment, you can use pycolmap's BA functions\n",
    "# with the reconstruction objects we created:\n",
    "#   - vggtx_reconstruction\n",
    "#   - infinitevggt_reconstruction\n",
    "\n",
    "print(\"\\nTo run bundle adjustment on the reconstructions:\")\n",
    "print(\"\"\"\\n\n",
    "# Example code:\n",
    "from pycolmap import BundleAdjustmentOptions\n",
    "\n",
    "ba_options = BundleAdjustmentOptions()\n",
    "ba_options.refine_focal_length = True\n",
    "ba_options.refine_principal_point = False\n",
    "ba_options.refine_extra_params = False\n",
    "\n",
    "# Run BA on VGGT-X reconstruction\n",
    "vggtx_reconstruction_ba = vggtx_reconstruction\n",
    "vggtx_reconstruction_ba.bundle_adjustment(ba_options)\n",
    "\n",
    "# Run BA on InfiniteVGGT reconstruction  \n",
    "infinitevggt_reconstruction_ba = infinitevggt_reconstruction\n",
    "infinitevggt_reconstruction_ba.bundle_adjustment(ba_options)\n",
    "\n",
    "# Then compare the before/after camera parameters\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### 1. Train Gaussian Splatting Models\n",
    "\n",
    "You can now train gaussian splatting models on both outputs:\n",
    "\n",
    "```bash\n",
    "# Train on VGGT-X output\n",
    "ns-train splatfacto \\\n",
    "  --data /workspace/bicycle/vggtx_output/preproc \\\n",
    "  --output-dir /workspace/bicycle/vggtx_output/training\n",
    "\n",
    "# Train on InfiniteVGGT output\n",
    "ns-train splatfacto \\\n",
    "  --data /workspace/bicycle/infinitevggt_output/preproc \\\n",
    "  --output-dir /workspace/bicycle/infinitevggt_output/training\n",
    "```\n",
    "\n",
    "### 2. Compare Training Quality\n",
    "\n",
    "After training, compare:\n",
    "- PSNR, SSIM, LPIPS metrics\n",
    "- Visual quality of renderings\n",
    "- Training convergence speed\n",
    "- Number of gaussians\n",
    "\n",
    "### 3. Bundle Adjustment Testing\n",
    "\n",
    "Use the matching outputs to:\n",
    "- Extract feature tracks\n",
    "- Run bundle adjustment on both reconstructions\n",
    "- Compare refined vs. initial camera parameters\n",
    "- Evaluate impact on final rendering quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
