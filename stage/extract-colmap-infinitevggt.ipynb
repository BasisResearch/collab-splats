{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfiniteVGGT Preprocessing for Nerfstudio\n",
    "\n",
    "This notebook demonstrates how to use **InfiniteVGGT** (StreamVGGT) as an alternative to VGGT-X for structure-from-motion preprocessing, with conversion to COLMAP format for nerfstudio compatibility.\n",
    "\n",
    "## What is InfiniteVGGT?\n",
    "\n",
    "InfiniteVGGT (StreamVGGT) extends VGGT with:\n",
    "- Streaming inference for long video sequences\n",
    "- Memory-efficient processing via frame caching\n",
    "- Improved pose estimation for extended scenes\n",
    "\n",
    "Repository: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Run InfiniteVGGT Inference**: Get camera poses, depth maps, and confidence\n",
    "2. **Convert to COLMAP Format**: Transform outputs to match VGGT-X structure\n",
    "3. **Build Reconstruction**: Create COLMAP files (cameras.bin, images.bin, points3D.bin)\n",
    "4. **Generate transforms.json**: Convert to nerfstudio format\n",
    "5. **Compare Performance**: Benchmark against VGGT-X (optional)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "# InfiniteVGGT is already cloned in /workspace/InfiniteVGGT\n",
    "# Checkpoint available at: https://huggingface.co/lch01/StreamVGGT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/conda/envs/nerfstudio/bin/python\n",
      "Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n",
      "\n",
      "âœ“ Running in nerfstudio environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-17:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "*** Aborted at 1768860205 (unix time) try \"date -d @1768860205\" if you are using GNU date ***\n",
      "PC: @     0x73fc5204958b ossl_md5_block_asm_data_order\n",
      "*** SIGTERM (@0x9675) received by PID 47572 (TID 0x73fc52d80740) from PID 38517; stack trace: ***\n",
      "    @     0x73fc52e1cee8 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x99ee7)\n",
      "    @     0x73fac77a00ed (/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/pycolmap.cpython-310-x86_64-linux-gnu.so+0x5830ec)\n",
      "    @     0x73fc52dc5520 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x4251f)\n",
      "    @     0x73fc5204958b ossl_md5_block_asm_data_order\n",
      "    @     0x73fc5204975a MD5_Update\n",
      "    @     0x73fc517fc3c6 py_evp_fromname\n",
      "    @     0x73fc517fbfe0 _hashlib_openssl_md5\n",
      "    @     0x5ce9d4a527c3 cfunction_vectorcall_FASTCALL_KEYWORDS\n",
      "    @     0x5ce9d4a4fa65 _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "    @     0x5ce9d4b2c98f bounded_lru_cache_wrapper\n",
      "    @     0x5ce9d4a54023 _PyObject_MakeTpCall.localalias\n",
      "    @     0x5ce9d4a4fcc6 _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "    @     0x5ce9d4a4b7b0 _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "    @     0x5ce9d4a53567 _PyObject_FastCallDictTstate.localalias\n",
      "    @     0x5ce9d4a63fe9 slot_tp_init\n",
      "    @     0x5ce9d4a5403b _PyObject_MakeTpCall.localalias\n",
      "    @     0x5ce9d4a5071d _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "    @     0x5ce9d4a4b3bc _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "    @     0x5ce9d4a4b3bc _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4aeb3bc _PyEval_Vector\n",
      "    @     0x5ce9d4aeb307 PyEval_EvalCode\n",
      "    @     0x5ce9d4af255b builtin_exec\n",
      "    @     0x5ce9d4a5b2b3 cfunction_vectorcall_FASTCALL\n",
      "    @     0x5ce9d4a5098d _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "    @     0x5ce9d4a4fa65 _PyEval_EvalFrameDefault\n",
      "    @     0x5ce9d4a5b0ec _PyFunction_Vectorcall\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-10:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstreamvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrameDiskCache\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Import nerfstudio utilities\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnerfstudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocess_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vggt_utils, colmap_utils\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnerfstudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocess_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocess_data_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CameraModel\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnerfstudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrich_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONSOLE\n",
      "File \u001b[0;32m/workspace/nerfstudio/nerfstudio/process_data/vggt_utils.py:85\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# StreamVGGT = None  # type: ignore\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# load_and_preprocess_images = None  # type: ignore\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# pose_encoding_to_extri_intri = None  # type: ignore\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# FrameDiskCache = None  # type: ignore\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Try to import vggt - it's an optional dependency\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VGGT\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_fn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_and_preprocess_images_ratio\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_enc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pose_encoding_to_extri_intri\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/vggt/models/vggt.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyTorchModelHubMixin  \u001b[38;5;66;03m# used for model hub\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Aggregator\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcamera_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CameraHead\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdpt_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DPTHead\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/vggt/models/aggregator.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m checkpoint\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple, Union, List, Dict, Any\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PatchEmbed\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Block\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvggt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrope\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RotaryPositionEmbedding2D, PositionGetter\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/vggt/layers/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mlp, MlpFP32\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatch_embed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PatchEmbed\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mswiglu_ffn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SwiGLUFFN, SwiGLUFFNFused\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/vggt/layers/mlp.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m         y \u001b[38;5;241m=\u001b[39m gelu_fused(x)\n\u001b[1;32m     31\u001b[0m     _gelu_fused_warmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mwarmup_gelu_fused\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMlp\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     39\u001b[0m         in_features: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m         bias: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/vggt/layers/mlp.py:29\u001b[0m, in \u001b[0;36mwarmup_gelu_fused\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mfloat32, torch\u001b[38;5;241m.\u001b[39mfloat16, torch\u001b[38;5;241m.\u001b[39mbfloat16]:\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m16\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 29\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mgelu_fused\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     y \u001b[38;5;241m=\u001b[39m gelu_fused(x)\n\u001b[1;32m     31\u001b[0m _gelu_fused_warmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:490\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_entry, frame_state)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_entry, hooks, frame_state)\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:641\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks, frame_state)\u001b[0m\n\u001b[1;32m    639\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 641\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:133\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m cleanup \u001b[38;5;241m=\u001b[39m setup_compile_debug()\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:389\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_entry, hooks, frame_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m compile_id \u001b[38;5;241m=\u001b[39m CompileId(frame_id, frame_compile_id)\n\u001b[1;32m    378\u001b[0m signpost_event(\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_frame_assert._compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m     },\n\u001b[1;32m    387\u001b[0m )\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:569\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_size, frame, frame_state, compile_id)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 569\u001b[0m         guarded_code \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    572\u001b[0m         Unsupported,\n\u001b[1;32m    573\u001b[0m         TorchRuntimeError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m         ValidationException,\n\u001b[1;32m    579\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/utils.py:189\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    188\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 189\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    191\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:491\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m         out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m         orig_code_map[out_code] \u001b[38;5;241m=\u001b[39m code\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1028\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m   1025\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m   1026\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m-> 1028\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:458\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context):\n\u001b[0;32m--> 458\u001b[0m         \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (exc\u001b[38;5;241m.\u001b[39mRestartAnalysis, exc\u001b[38;5;241m.\u001b[39mSkipFrame):\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2069\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2069\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:719\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 719\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m     ):\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:683\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m         unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    680\u001b[0m     TracingContext\u001b[38;5;241m.\u001b[39mset_current_loc(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_filename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[1;32m    682\u001b[0m     )\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2157\u001b[0m, in \u001b[0;36mInstructionTranslator.RETURN_VALUE\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   2152\u001b[0m _step_logger()(\n\u001b[1;32m   2153\u001b[0m     logging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[1;32m   2154\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (RETURN_VALUE)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2155\u001b[0m )\n\u001b[1;32m   2156\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE triggered compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2157\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   2161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39madd_output_instructions([create_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:833\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    830\u001b[0m     append_prefix_insts()\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;66;03m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_output_instructions(\n\u001b[0;32m--> 833\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;241m+\u001b[39m [create_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNPACK_SEQUENCE\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(stack_values))]\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    837\u001b[0m     graph_output_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_var(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph_out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:957\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m    952\u001b[0m graph_tabular_log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, lazy_format_graph_tabular(name, gm))\n\u001b[1;32m    953\u001b[0m graph_sizes_log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, LazyString(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_graph_sizes_log_str(name))\n\u001b[1;32m    955\u001b[0m )\n\u001b[0;32m--> 957\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m disable(compiled_fn)\n\u001b[1;32m    960\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/utils.py:189\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    188\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 189\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    191\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:1009\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mverify_correctness:\n\u001b[1;32m   1008\u001b[0m     compiler_fn \u001b[38;5;241m=\u001b[39m WrapperBackend(compiler_fn)\n\u001b[0;32m-> 1009\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_fn did not return callable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py:117\u001b[0m, in \u001b[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     compiled_gm \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/__init__.py:1568\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[0;32m-> 1568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:1150\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[0m\n\u001b[1;32m   1143\u001b[0m tracing_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1144\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mTracingContext\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mTracingContext(fake_mode)\n\u001b[1;32m   1145\u001b[0m )\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_fake_mode(fake_mode), torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mtracing(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m     tracing_context\n\u001b[1;32m   1149\u001b[0m ), compiled_autograd\u001b[38;5;241m.\u001b[39mdisable():\n\u001b[0;32m-> 1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/backends/common.py:55\u001b[0m, in \u001b[0;36maot_autograd.<locals>.compiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[0;32m---> 55\u001b[0m         cg \u001b[38;5;241m=\u001b[39m \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m         counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:3891\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler)\u001b[0m\n\u001b[1;32m   3875\u001b[0m aot_config \u001b[38;5;241m=\u001b[39m AOTConfig(\n\u001b[1;32m   3876\u001b[0m     fw_compiler\u001b[38;5;241m=\u001b[39mfw_compiler,\n\u001b[1;32m   3877\u001b[0m     bw_compiler\u001b[38;5;241m=\u001b[39mbw_compiler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3887\u001b[0m     no_tangents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3888\u001b[0m )\n\u001b[1;32m   3890\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd\u001b[38;5;241m.\u001b[39mdisable():\n\u001b[0;32m-> 3891\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;66;03m# TODO: There is something deeply wrong here; compiled_fn running with\u001b[39;00m\n\u001b[1;32m   3898\u001b[0m \u001b[38;5;66;03m# the boxed calling convention, but aot_module_simplified somehow\u001b[39;00m\n\u001b[1;32m   3899\u001b[0m \u001b[38;5;66;03m# historically returned a function that was not the boxed calling\u001b[39;00m\n\u001b[1;32m   3900\u001b[0m \u001b[38;5;66;03m# convention.  This should get fixed...\u001b[39;00m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39mruntime_args):\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/utils.py:189\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    188\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 189\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    191\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:3429\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   3426\u001b[0m compiler_fn \u001b[38;5;241m=\u001b[39m partial(aot_wrapper_dedupe, compiler_fn\u001b[38;5;241m=\u001b[39mcompiler_fn)\n\u001b[1;32m   3427\u001b[0m \u001b[38;5;66;03m# You can put more passes here\u001b[39;00m\n\u001b[0;32m-> 3429\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aot_config\u001b[38;5;241m.\u001b[39mis_export:\n\u001b[1;32m   3432\u001b[0m     mutated_user_inp_locs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3433\u001b[0m         idx \u001b[38;5;241m-\u001b[39m aot_config\u001b[38;5;241m.\u001b[39mnum_params_buffers\n\u001b[1;32m   3434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m fw_metadata\u001b[38;5;241m.\u001b[39mmutated_inp_indices\n\u001b[1;32m   3435\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m aot_config\u001b[38;5;241m.\u001b[39mnum_params_buffers\n\u001b[1;32m   3436\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2212\u001b[0m, in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn, fw_metadata)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[0;32m-> 2212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;66;03m# export path: ban duplicate inputs for now, add later if requested.\u001b[39;00m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aot_config\u001b[38;5;241m.\u001b[39mis_export:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2392\u001b[0m, in \u001b[0;36maot_wrapper_synthetic_base\u001b[0;34m(flat_fn, flat_args, aot_config, fw_metadata, needs_autograd, compiler_fn)\u001b[0m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;66;03m# Happy path: we don't need synthetic bases\u001b[39;00m\n\u001b[1;32m   2391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synthetic_base_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[38;5;66;03m# export path: ban synthetic bases for now, add later if requested.\u001b[39;00m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aot_config\u001b[38;5;241m.\u001b[39mis_export:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1573\u001b[0m, in \u001b[0;36maot_dispatch_base\u001b[0;34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mTracingContext\u001b[38;5;241m.\u001b[39mget():\n\u001b[1;32m   1572\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mTracingContext\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mfw_metadata \u001b[38;5;241m=\u001b[39m fw_metadata\n\u001b[0;32m-> 1573\u001b[0m     compiled_fw \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# This boxed_call handling happens inside create_runtime_wrapper as well.\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;66;03m# However, create_runtime_wrapper does not expect the rng offsets in the\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# output. So, we have to create another wrapper and take out the offset. As\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;66;03m# a result, we have to account for not boxed_call compilers as well.\u001b[39;00m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/utils.py:189\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    188\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 189\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    191\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:1092\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler_base\u001b[0;34m(model, example_inputs, is_inference)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;66;03m# We makes the following assumption\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m     \u001b[38;5;66;03m# For inference\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;66;03m#   len(orig_model_outputs) == len(model_outputs)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;66;03m# To make things safe, we'll use original_output_start_index field\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;66;03m# set by AOTAutograd to decide where the original module outputs start.\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     user_visible_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1084\u001b[0m         n\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1085\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m model_outputs[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mNode)\n\u001b[1;32m   1090\u001b[0m     }\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_fixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py:80\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     inner_compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/debug.py:228\u001b[0m, in \u001b[0;36mDebugContext.wrap.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DebugContext():\n\u001b[0;32m--> 228\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:54\u001b[0m, in \u001b[0;36mtime_and_log.<locals>.wrap.<locals>.newFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(old_func)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnewFunction\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:341\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt)\u001b[0m\n\u001b[1;32m    328\u001b[0m graph_args \u001b[38;5;241m=\u001b[39m [gm, example_inputs]\n\u001b[1;32m    329\u001b[0m graph_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcudagraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m: cudagraphs,\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_fixed\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_fixed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout_opt\u001b[39m\u001b[38;5;124m\"\u001b[39m: layout_opt,\n\u001b[1;32m    339\u001b[0m }\n\u001b[0;32m--> 341\u001b[0m compiled_graph: CompiledFxGraph \u001b[38;5;241m=\u001b[39m \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgraph_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    343\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aot_mode:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled_graph\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:565\u001b[0m, in \u001b[0;36mfx_codegen_and_compile\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, user_visible_outputs, layout_opt)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m             context\u001b[38;5;241m.\u001b[39moutput_strides\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 565\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mdisable_cudagraphs:\n\u001b[1;32m    568\u001b[0m     BoxedBool\u001b[38;5;241m.\u001b[39mdisable(cudagraphs)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/graph.py:970\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AotCodeCache\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;28mself\u001b[39m, code, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcall\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_dynamo/utils.py:189\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    188\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 189\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    191\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/graph.py:941\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m linemap \u001b[38;5;241m=\u001b[39m [(line_no, node\u001b[38;5;241m.\u001b[39mstack_trace) \u001b[38;5;28;01mfor\u001b[39;00m line_no, node \u001b[38;5;129;01min\u001b[39;00m linemap]\n\u001b[1;32m    940\u001b[0m key, path \u001b[38;5;241m=\u001b[39m PyCodeCache\u001b[38;5;241m.\u001b[39mwrite(code)\n\u001b[0;32m--> 941\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mPyCodeCache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_by_key_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinemap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinemap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_key \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_path \u001b[38;5;241m=\u001b[39m path\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/codecache.py:1139\u001b[0m, in \u001b[0;36mPyCodeCache.load_by_key_path\u001b[0;34m(cls, key, path, linemap)\u001b[0m\n\u001b[1;32m   1137\u001b[0m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m   1138\u001b[0m mod\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m-> 1139\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m mod\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# another thread might set this first\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/torchinductor_root/nb/cnb4dn6ie32q2fwdppf5mza4k7txteg3dxlekf6oi4gtwyqgmhsi.py:64\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton_heuristics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m grid, start_graph, end_graph\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _cuda_getCurrentRawStream \u001b[38;5;28;01mas\u001b[39;00m get_cuda_stream\n\u001b[0;32m---> 64\u001b[0m \u001b[43masync_compile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m async_compile\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(args):\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/codecache.py:1418\u001b[0m, in \u001b[0;36mAsyncCompile.wait\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(key)\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, (Future, TritonFuture)):\n\u001b[0;32m-> 1418\u001b[0m             scope[key] \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1419\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1421\u001b[0m _compile_end()\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/_inductor/codecache.py:1277\u001b[0m, in \u001b[0;36mTritonFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;66;03m# If the worker failed this will throw an exception.\u001b[39;00m\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m _load_kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_code)\n\u001b[1;32m   1279\u001b[0m latency \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Verify conda environment\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "if 'nerfstudio' not in sys.executable:\n",
    "    print(\"\\nâš ï¸  WARNING: Not running in nerfstudio conda environment!\")\n",
    "    print(\"Please activate with: conda activate nerfstudio\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Running in nerfstudio environment\")\n",
    "\n",
    "# Add InfiniteVGGT to Python path (append to end so environment VGGT takes precedence)\n",
    "infinitevggt_root = Path(\"/workspace/InfiniteVGGT\")\n",
    "if str(infinitevggt_root / \"src\") not in sys.path:\n",
    "    sys.path.append(str(infinitevggt_root / \"src\"))  # âœ… This puts it last\n",
    "\n",
    "# Import InfiniteVGGT components\n",
    "from streamvggt.models.streamvggt import StreamVGGT\n",
    "from streamvggt.utils.load_fn import load_and_preprocess_images\n",
    "from streamvggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "from streamvggt.utils.geometry import FrameDiskCache\n",
    "\n",
    "# Import nerfstudio utilities\n",
    "from nerfstudio.process_data import vggt_utils, colmap_utils\n",
    "from nerfstudio.process_data.process_data_utils import CameraModel\n",
    "from nerfstudio.utils.rich_utils import CONSOLE\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up paths for input images, output directory, and model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dataset Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Input: Bicycle dataset (194 images)\n",
    "image_dir = Path(\"/workspace/bicycle/images_4\")\n",
    "\n",
    "# Output: Will create structure similar to VGGT-X\n",
    "output_base = Path(\"/workspace/bicycle/environment/bicycle\")\n",
    "preproc_dir = output_base / \"preproc\"\n",
    "colmap_dir = preproc_dir / \"colmap\"\n",
    "colmap_output_dir = colmap_dir / \"sparse\" / \"0\"\n",
    "\n",
    "# Create directories\n",
    "colmap_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# InfiniteVGGT Model Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Checkpoint path - download from https://huggingface.co/lch01/StreamVGGT\n",
    "checkpoint_path = Path(\"/workspace/InfiniteVGGT/checkpoints/streamvggt.pth\")\n",
    "\n",
    "# Model parameters\n",
    "total_budget = 1200000  # Total point budget for reconstruction\n",
    "cache_results = True    # Cache results in memory (set False for very long sequences)\n",
    "frame_cache_dir = None  # Set to a directory path to cache per-frame outputs to disk\n",
    "\n",
    "# COLMAP conversion parameters (matching VGGT-X defaults)\n",
    "conf_threshold = 50.0         # Confidence threshold percentile (0-100)\n",
    "scale_factor = 2.5            # Scale points for better reconstruction\n",
    "shared_camera = True          # Use single camera model for all frames\n",
    "max_points_for_colmap = 500000  # Maximum points for COLMAP reconstruction\n",
    "\n",
    "print(f\"Input images: {image_dir}\")\n",
    "print(f\"Output directory: {output_base}\")\n",
    "print(f\"COLMAP output: {colmap_output_dir}\")\n",
    "print(f\"Checkpoint: {checkpoint_path}\")\n",
    "print(f\"  Exists: {checkpoint_path.exists()}\")\n",
    "\n",
    "# Check input images\n",
    "image_paths = sorted(list(image_dir.glob(\"*.JPG\")) + list(image_dir.glob(\"*.png\")))\n",
    "print(f\"\\nFound {len(image_paths)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run InfiniteVGGT Inference\n",
    "\n",
    "Load the StreamVGGT model and run inference on the image sequence. This produces:\n",
    "- Camera pose encodings\n",
    "- Depth maps with confidence\n",
    "- 3D point predictions in camera coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_infinite_vggt(model_name=\"lch01/StreamVGGT\", total_budget=1200000):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if not torch.cuda.is_available():\n",
    "            raise RuntimeError(\"CUDA is required for InfiniteVGGT inference\")\n",
    "\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING MODEL\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Initialize model\n",
    "    model = StreamVGGT.from_pretrained(model_name, total_budget=total_budget)\n",
    "    print(f\"âœ“ Model initialized with budget: {total_budget:,} points\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def _run_infinite_vggt_inference(model, image_paths):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if not torch.cuda.is_available():\n",
    "            raise RuntimeError(\"CUDA is required for InfiniteVGGT inference\")\n",
    "\n",
    "    #############################################\n",
    "    ###### Load and preprocess images ###########\n",
    "    #############################################\n",
    "    \n",
    "    print(f\"Loading {len(image_paths)} images...\")\n",
    "    images = load_and_preprocess_images([str(p) for p in image_paths]).to(device)\n",
    "    print(f\"âœ“ Images preprocessed: {images.shape}\")\n",
    "    print(f\"  Shape: (N={images.shape[0]}, C={images.shape[1]}, H={images.shape[2]}, W={images.shape[3]})\")\n",
    "\n",
    "    # Prepare frames for inference\n",
    "    frames = [{\"img\": images[i].unsqueeze(0)} for i in range(images.shape[0])]\n",
    "\n",
    "    # Determine optimal dtype based on GPU capability\n",
    "    dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n",
    "    print(f\"Using dtype: {dtype}\")\n",
    "\n",
    "    # Run inference with timing and memory tracking\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(dtype=dtype):\n",
    "            output = model.inference(\n",
    "                frames,\n",
    "                frame_writer=None,\n",
    "                cache_results=cache_results\n",
    "            )\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    inference_time = end_time - start_time\n",
    "    peak_memory_gb = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INFERENCE COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  Total time: {inference_time:.2f}s\")\n",
    "    print(f\"  Time per frame: {inference_time / len(image_paths):.3f}s\")\n",
    "    print(f\"  Peak GPU memory: {peak_memory_gb:.2f} GB\")\n",
    "    print(f\"  Frames processed: {len(image_paths)}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return output\n",
    "\n",
    "def _outputs_to_array(output):\n",
    "\n",
    "    keys = output.ress[0].keys()\n",
    "    arrs = {k: [] for k in keys}\n",
    "\n",
    "    for res in output.ress:\n",
    "        for k in keys:\n",
    "            arrs[k].append(res[k].squeeze(0))\n",
    "\n",
    "    # return arrs\n",
    "    print(f\"âœ“ Extracted predictions:\")\n",
    "\n",
    "    for k in keys:\n",
    "        arrs[k] = torch.stack(arrs[k], dim=0)\n",
    "        print (f\"  {k}: {arrs[k].shape}\")\n",
    "\n",
    "    return arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _load_infinite_vggt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = _run_infinite_vggt_inference(model, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = _outputs_to_array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract and Convert Predictions\n",
    "\n",
    "Extract predictions from InfiniteVGGT output and convert to VGGT-X compatible format.\n",
    "\n",
    "### InfiniteVGGT Output Structure\n",
    "- `pts3d_in_other_view`: 3D points in world coordinates (N, H, W, 3)\n",
    "- `conf`: Point confidence scores (N, H, W)\n",
    "- `depth`: Depth maps (N, H, W)\n",
    "- `depth_conf`: Depth confidence (N, H, W)\n",
    "- `camera_pose`: Pose encoding (N, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTRACTING PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not cache_results or output.ress is None or len(output.ress) == 0:\n",
    "    raise RuntimeError(\n",
    "        \"No cached results available. Set cache_results=True or use frame_cache_dir \"\n",
    "        \"to save per-frame outputs.\"\n",
    "    )\n",
    "\n",
    "# Extract results (following InfiniteVGGT/run_inference.py pattern)\n",
    "all_pts3d = [res['pts3d_in_other_view'].squeeze(0) for res in output.ress]\n",
    "all_conf = [res['conf'].squeeze(0) for res in output.ress]\n",
    "all_depth = [res['depth'].squeeze(0) for res in output.ress]\n",
    "all_depth_conf = [res['depth_conf'].squeeze(0) for res in output.ress]\n",
    "all_camera_pose = [res['camera_pose'].squeeze(0) for res in output.ress]\n",
    "\n",
    "# Stack into tensors\n",
    "world_points = torch.stack(all_pts3d, dim=0)      # (N, H, W, 3)\n",
    "world_points_conf = torch.stack(all_conf, dim=0)  # (N, H, W)\n",
    "depth = torch.stack(all_depth, dim=0)             # (N, H, W)\n",
    "depth_conf = torch.stack(all_depth_conf, dim=0)   # (N, H, W)\n",
    "pose_enc = torch.stack(all_camera_pose, dim=0)    # (N, 16)\n",
    "\n",
    "print(f\"âœ“ Extracted predictions:\")\n",
    "print(f\"  World points: {world_points.shape}\")\n",
    "print(f\"  Confidence: {world_points_conf.shape}\")\n",
    "print(f\"  Depth: {depth.shape}\")\n",
    "print(f\"  Depth confidence: {depth_conf.shape}\")\n",
    "print(f\"  Pose encoding: {pose_enc.shape}\")\n",
    "\n",
    "# Convert pose encoding to extrinsic and intrinsic matrices\n",
    "# Following VGGT pattern: pose_encoding_to_extri_intri expects (B, N, 16)\n",
    "extrinsic, intrinsic = pose_encoding_to_extri_intri(\n",
    "    pose_enc.unsqueeze(0),  # Add batch dimension\n",
    "    images.shape[-2:]       # (H, W)\n",
    ")\n",
    "\n",
    "# Remove batch dimension\n",
    "extrinsic = extrinsic.squeeze(0)  # (N, 4, 4) or (N, 3, 4)\n",
    "intrinsic = intrinsic.squeeze(0) if intrinsic is not None else None  # (N, 3, 3)\n",
    "\n",
    "print(f\"\\nâœ“ Converted to camera matrices:\")\n",
    "print(f\"  Extrinsic: {extrinsic.shape}\")\n",
    "print(f\"  Intrinsic: {intrinsic.shape if intrinsic is not None else 'None'}\")\n",
    "\n",
    "# Move to CPU for further processing\n",
    "images_cpu = images.detach().cpu()\n",
    "world_points_cpu = world_points.detach().cpu()\n",
    "world_points_conf_cpu = world_points_conf.detach().cpu()\n",
    "depth_cpu = depth.detach().cpu()\n",
    "depth_conf_cpu = depth_conf.detach().cpu()\n",
    "extrinsic_cpu = extrinsic.detach().cpu()\n",
    "intrinsic_cpu = intrinsic.detach().cpu() if intrinsic is not None else None\n",
    "\n",
    "# Clean up GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nâœ“ Moved predictions to CPU and cleared GPU cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert to COLMAP Format\n",
    "\n",
    "Convert InfiniteVGGT predictions to COLMAP format following the VGGT-X pattern:\n",
    "1. Scale poses and depth\n",
    "2. Convert world points to the format expected by COLMAP\n",
    "3. Filter points by confidence\n",
    "4. Build pycolmap reconstruction\n",
    "5. Write COLMAP binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONVERTING TO COLMAP FORMAT\")\n",
    "print(\"=\"*70)\n",
    "scale_factor=1\n",
    "\n",
    "conf_threshold = 50.0\n",
    "\n",
    "# Convert tensors to numpy for COLMAP processing\n",
    "images_np = images_cpu.numpy()  # (N, C, H, W)\n",
    "world_points_np = world_points_cpu.numpy()  # (N, H, W, 3)\n",
    "world_points_conf_np = world_points_conf_cpu.numpy()  # (N, H, W)\n",
    "depth_np = depth_cpu.numpy()  # (N, H, W)\n",
    "depth_conf_np = depth_conf_cpu.numpy()  # (N, H, W)\n",
    "extrinsic_np = extrinsic_cpu.numpy()  # (N, 4, 4) or (N, 3, 4)\n",
    "intrinsic_np = intrinsic_cpu.numpy() if intrinsic_cpu is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerfstudio.process_data.vggt_utils import _run_global_alignment\n",
    "\n",
    "# Optimized camera poses using feature matching\n",
    "extrinsic, intrinsic, match_outputs = _run_global_alignment(\n",
    "    images=images,\n",
    "    image_paths=image_paths,\n",
    "    extrinsic=extrinsic_np,\n",
    "    intrinsic=intrinsic_np,\n",
    "    depth_map=depth_np,\n",
    "    depth_conf=depth_conf_np,\n",
    "    lambda_depth=0.0,\n",
    "    colmap_dir=colmap_dir,\n",
    "    shared_camera=shared_camera,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "from nerfstudio.process_data.vggt_utils import _filter_and_prepare_points_for_pycolmap\n",
    "\n",
    "# # Unproject depth map to point map\n",
    "# points3d = unproject_depth_map_to_point_map(\n",
    "#     depth_cpu, \n",
    "#     extrinsic, \n",
    "#     intrinsic\n",
    "# )\n",
    "points3d = world_points_np\n",
    "\n",
    "# Convert confidence threshold from percentile to value\n",
    "if conf_threshold > 1.0:\n",
    "    conf_threshold_value = np.percentile(depth_conf_np, conf_threshold)\n",
    "else:\n",
    "    conf_threshold_value = conf_threshold\n",
    "\n",
    "\n",
    "print(f\"Original shapes:\")\n",
    "print(f\"  World points: {points3d.shape}\")\n",
    "print(f\"  Extrinsic: {extrinsic_np.shape}\")\n",
    "print(f\"  Depth: {depth_np.shape}\")\n",
    "\n",
    "# Filter points for pycolmap reconstruction using VGGTX logic\n",
    "points3d, points_xyf, points_rgb = _filter_and_prepare_points_for_pycolmap(\n",
    "    points3d=points3d,\n",
    "    depth_map=depth_np,\n",
    "    depth_conf=depth_conf_np,\n",
    "    images=images,\n",
    "    image_paths=image_paths,\n",
    "    conf_thres_value=conf_threshold_value,\n",
    "    use_global_alignment=True,\n",
    "    max_points_for_colmap=max_points_for_colmap,\n",
    "    match_outputs=match_outputs\n",
    ")\n",
    "\n",
    "print(f\"\\nConfidence filtering:\")\n",
    "print(f\"  Threshold percentile: {conf_threshold}\")\n",
    "print(f\"  Threshold value: {conf_threshold_value:.4f}\")\n",
    "print(f\"  Depth conf range: [{depth_conf_np.min():.4f}, {depth_conf_np.max():.4f}]\")\n",
    "\n",
    "# Filter points by confidence\n",
    "conf_mask = depth_conf_np >= conf_threshold_value\n",
    "num_valid_points = conf_mask.sum()\n",
    "print(f\"  Valid points: {num_valid_points:,} / {conf_mask.size:,} ({100*num_valid_points/conf_mask.size:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postproc via StreamVGGT method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Convert tensors to numpy for COLMAP processing\n",
    "# images_np = images_cpu.numpy()  # (N, C, H, W)\n",
    "# world_points_np = world_points_cpu.numpy()  # (N, H, W, 3)\n",
    "# world_points_conf_np = world_points_conf_cpu.numpy()  # (N, H, W)\n",
    "# depth_np = depth_cpu.numpy()  # (N, H, W)\n",
    "# depth_conf_np = depth_conf_cpu.numpy()  # (N, H, W)\n",
    "# extrinsic_np = extrinsic_cpu.numpy()  # (N, 4, 4) or (N, 3, 4)\n",
    "# intrinsic_np = intrinsic_cpu.numpy() if intrinsic_cpu is not None else None\n",
    "\n",
    "# print(f\"Original shapes:\")\n",
    "# print(f\"  World points: {world_points_np.shape}\")\n",
    "# print(f\"  Extrinsic: {extrinsic_np.shape}\")\n",
    "# print(f\"  Depth: {depth_np.shape}\")\n",
    "\n",
    "# # Apply scale factor (following VGGT-X pattern)\n",
    "# print(f\"\\nApplying scale factor: {scale_factor}\")\n",
    "# if extrinsic_np.shape[-1] == 4 and extrinsic_np.shape[-2] == 4:\n",
    "#     # (N, 4, 4) format\n",
    "#     extrinsic_np[:, :3, 3] *= scale_factor\n",
    "# elif extrinsic_np.shape[-1] == 4 and extrinsic_np.shape[-2] == 3:\n",
    "#     # (N, 3, 4) format\n",
    "#     extrinsic_np[:, :, 3] *= scale_factor\n",
    "# depth_np *= scale_factor\n",
    "# world_points_np *= scale_factor\n",
    "\n",
    "\n",
    "# print(f\"\\nConfidence filtering:\")\n",
    "# print(f\"  Threshold percentile: {conf_threshold}\")\n",
    "# print(f\"  Threshold value: {conf_threshold_value:.4f}\")\n",
    "# print(f\"  Depth conf range: [{depth_conf_np.min():.4f}, {depth_conf_np.max():.4f}]\")\n",
    "\n",
    "# # Filter points by confidence\n",
    "# conf_mask = depth_conf_np >= conf_threshold_value\n",
    "# num_valid_points = conf_mask.sum()\n",
    "# print(f\"  Valid points: {num_valid_points:,} / {conf_mask.size:,} ({100*num_valid_points/conf_mask.size:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from vggt.utils.helper import create_pixel_coordinate_grid, randomly_limit_trues\n",
    "# # Filter points for pycolmap reconstruction using VGGTX logic\n",
    "# points3d, points_xyf, points_rgb = _filter_and_prepare_points_for_pycolmap(\n",
    "#     points3d=world_points_np,\n",
    "#     depth_map=depth_np,\n",
    "#     depth_conf=depth_conf_np,\n",
    "#     images=images,\n",
    "#     image_paths=image_paths,\n",
    "#     conf_thres_value=conf_threshold_value,\n",
    "#     use_global_alignment=False,\n",
    "#     max_points_for_colmap=max_points_for_colmap,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move into colmap format (Stream VGGT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build pycolmap Reconstruction\n",
    "\n",
    "Use VGGT's utility function to build a pycolmap Reconstruction from the filtered points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerfstudio.process_data.vggt_utils import _build_pycolmap_reconstruction_without_tracks\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUILDING PYCOLMAP RECONSTRUCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Image size [W, H]\n",
    "N, H, W, _= depth_np.shape\n",
    "image_size = np.array([W, H])\n",
    "\n",
    "# Camera type\n",
    "camera_type = \"SIMPLE_PINHOLE\" if shared_camera else \"PINHOLE\"\n",
    "\n",
    "print(f\"Building reconstruction:\")\n",
    "print(f\"  Camera type: {camera_type}\")\n",
    "print(f\"  Image size: {image_size[0]}x{image_size[1]}\")\n",
    "print(f\"  Number of cameras: {1 if shared_camera else N}\")\n",
    "print(f\"  Number of images: {N}\")\n",
    "print(f\"  Number of 3D points: {len(points3d)}\")\n",
    "\n",
    "# Build reconstruction\n",
    "reconstruction = _build_pycolmap_reconstruction_without_tracks(\n",
    "    points3d=points3d,\n",
    "    points_xyf=points_xyf,\n",
    "    points_rgb=points_rgb,\n",
    "    extrinsic=extrinsic,\n",
    "    intrinsic=intrinsic,\n",
    "    image_paths=image_paths,\n",
    "    image_size=image_size,\n",
    "    camera_type=camera_type,\n",
    "    shared_camera=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "if reconstruction is None:\n",
    "    raise RuntimeError(\"Failed to build pycolmap reconstruction\")\n",
    "\n",
    "print(f\"\\nâœ“ Reconstruction built successfully:\")\n",
    "print(f\"  Cameras: {len(reconstruction.cameras)}\")\n",
    "print(f\"  Images: {len(reconstruction.images)}\")\n",
    "print(f\"  Points3D: {len(reconstruction.points3D)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand image to original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from nerfstudio.process_data.vggt_utils import _rescale_reconstruction_to_original_dimensions\n",
    "\n",
    "img = Image.open(image_paths[0])\n",
    "\n",
    "# # Step 2: Rescale reconstruction to original dimensions\n",
    "reconstruction_resolution = (img.width, img.height) # Reverse as it expects width and height\n",
    "\n",
    "original_coords = [[0, 0, W, H, img.width, img.height]] * len(image_paths)\n",
    "original_coords = np.array(original_coords)\n",
    "\n",
    "reconstruction = _rescale_reconstruction_to_original_dimensions(\n",
    "    reconstruction=reconstruction,\n",
    "    image_paths=image_paths,\n",
    "    original_image_sizes=original_coords,\n",
    "    image_size=reconstruction_resolution,\n",
    "    shift_point2d_to_original_res=True,\n",
    "    shared_camera=shared_camera,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Write COLMAP files\n",
    "print(f\"\\nWriting COLMAP files to: {colmap_output_dir}\")\n",
    "reconstruction.write_binary(str(colmap_output_dir))\n",
    "print(f\"âœ“ Wrote:\")\n",
    "print(f\"  - {colmap_output_dir / 'cameras.bin'}\")\n",
    "print(f\"  - {colmap_output_dir / 'images.bin'}\")\n",
    "print(f\"  - {colmap_output_dir / 'points3D.bin'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Convert to Nerfstudio Format\n",
    "\n",
    "Convert the COLMAP reconstruction to nerfstudio's `transforms.json` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONVERTING TO NERFSTUDIO FORMAT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert COLMAP to transforms.json\n",
    "print(f\"Converting COLMAP reconstruction to transforms.json...\")\n",
    "colmap_utils.colmap_to_json(\n",
    "    recon_dir=colmap_output_dir,\n",
    "    output_dir=preproc_dir,\n",
    ")\n",
    "\n",
    "transforms_path = preproc_dir / \"transforms.json\"\n",
    "print(f\"âœ“ Created: {transforms_path}\")\n",
    "\n",
    "# Load transforms to get applied_transform\n",
    "with open(transforms_path) as f:\n",
    "    transforms = json.load(f)\n",
    "\n",
    "applied_transform = torch.tensor(transforms[\"applied_transform\"])\n",
    "\n",
    "# Create point cloud PLY file\n",
    "ply_filename = \"sparse_pc.ply\"\n",
    "print(f\"\\nCreating point cloud PLY file...\")\n",
    "colmap_utils.create_ply_from_colmap(\n",
    "    filename=ply_filename,\n",
    "    recon_dir=colmap_output_dir,\n",
    "    output_dir=preproc_dir,\n",
    "    applied_transform=applied_transform,\n",
    ")\n",
    "\n",
    "ply_path = preproc_dir / ply_filename\n",
    "print(f\"âœ“ Created: {ply_path}\")\n",
    "\n",
    "# Update transforms.json with PLY path\n",
    "transforms[\"ply_file_path\"] = ply_filename\n",
    "with open(transforms_path, 'w') as f:\n",
    "    json.dump(transforms, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONVERSION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  ðŸ“ {preproc_dir}/\")\n",
    "print(f\"    ðŸ“„ transforms.json\")\n",
    "print(f\"    ðŸ“„ {ply_filename}\")\n",
    "print(f\"    ðŸ“ colmap/sparse/0/\")\n",
    "print(f\"      ðŸ“„ cameras.bin\")\n",
    "print(f\"      ðŸ“„ images.bin\")\n",
    "print(f\"      ðŸ“„ points3D.bin\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Sparse Point Cloud\n",
    "\n",
    "Visualize the reconstructed point cloud using PyVista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "# Optional: Import visualization utilities if available\n",
    "try:\n",
    "    from collab_splats.utils.visualization import (\n",
    "        CAMERA_KWARGS,\n",
    "        MESH_KWARGS,\n",
    "        VIZ_KWARGS,\n",
    "        visualize_splat,\n",
    "    )\n",
    "    has_viz_utils = True\n",
    "except ImportError:\n",
    "    has_viz_utils = False\n",
    "    print(\"collab_splats visualization utilities not available, using basic PyVista\")\n",
    "\n",
    "print(f\"\\nLoading point cloud from: {ply_path}\")\n",
    "point_cloud = pv.PolyData(str(ply_path))\n",
    "print(f\"  Points: {point_cloud.n_points:,}\")\n",
    "\n",
    "if has_viz_utils:\n",
    "    # Use collab_splats visualization\n",
    "    pcd_kwargs = MESH_KWARGS.copy()\n",
    "    pcd_kwargs.update({\n",
    "        \"point_size\": 2,\n",
    "        \"render_points_as_spheres\": True,\n",
    "        \"ambient\": 0.3,\n",
    "        \"diffuse\": 0.8,\n",
    "        \"specular\": 0.1,\n",
    "    })\n",
    "    \n",
    "    plotter = visualize_splat(\n",
    "        mesh=point_cloud,\n",
    "        mesh_kwargs=pcd_kwargs,\n",
    "        viz_kwargs=VIZ_KWARGS,\n",
    "    )\n",
    "else:\n",
    "    # Basic PyVista visualization\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_mesh(\n",
    "        point_cloud,\n",
    "        point_size=2,\n",
    "        render_points_as_spheres=True,\n",
    "    )\n",
    "    plotter.add_axes()\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Performance Summary\n",
    "\n",
    "Display comprehensive performance metrics for InfiniteVGGT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFINITEVGGT PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset: {image_dir.name}\")\n",
    "print(f\"  Images: {len(image_paths)}\")\n",
    "print(f\"  Resolution: {W}x{H}\")\n",
    "\n",
    "print(f\"\\nInference Performance:\")\n",
    "print(f\"  Total time: {inference_time:.2f}s\")\n",
    "print(f\"  Per frame: {inference_time / len(image_paths):.3f}s\")\n",
    "print(f\"  FPS: {len(image_paths) / inference_time:.2f}\")\n",
    "print(f\"  Peak GPU memory: {peak_memory_gb:.2f} GB\")\n",
    "\n",
    "print(f\"\\nReconstruction Quality:\")\n",
    "print(f\"  Cameras: {len(reconstruction.cameras)}\")\n",
    "print(f\"  Images registered: {len(reconstruction.images)} / {len(image_paths)}\")\n",
    "print(f\"  3D points: {len(reconstruction.points3D):,}\")\n",
    "print(f\"  Confidence threshold: {conf_threshold_value:.4f} (p{conf_threshold})\")\n",
    "\n",
    "# Calculate average track length\n",
    "if len(reconstruction.points3D) > 0:\n",
    "    track_lengths = [len(pt.track.elements) for pt in reconstruction.points3D.values()]\n",
    "    avg_track_length = np.mean(track_lengths)\n",
    "    print(f\"  Avg track length: {avg_track_length:.2f}\")\n",
    "\n",
    "print(f\"\\nOutput Directory: {preproc_dir}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use Splatter wrapper for training\n",
    "from collab_splats.wrapper import Splatter, SplatterConfig\n",
    "\n",
    "# Configuration\n",
    "config_dir = Path(\"/workspace/collab-splats/docs/splats/configs/\")\n",
    "dataset_name = \"bicycle\"\n",
    "# dataset_name = \"birds_date-02062024_video-C0043\"\n",
    "\n",
    "# Create splatter from config\n",
    "splatter = Splatter.from_config_file(\n",
    "    dataset=dataset_name,\n",
    "    config_dir=config_dir,\n",
    "    # overrides={\n",
    "    #     \"frame_proportion\": 0.1,\n",
    "    # }\n",
    ")\n",
    "\n",
    "splatter.preprocess()\n",
    "\n",
    "# splatter.preprocess(\n",
    "#     sfm_tool='vggt',\n",
    "#     overwrite=False, \n",
    "#     kwargs={\n",
    "#         \"refine-vggt\": \"\",\n",
    "#         \"camera-type\": \"pinhole\",\n",
    "#         \"verbose\": \"\",\n",
    "#         \"num_downscales\": 0,\n",
    "#         \"vggt_conf_threshold\": 35.0,\n",
    "#         # \"skip_image_processing\": \"\",\n",
    "#     }  # Enable bundle adjustment\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_kwargs = {\n",
    "    # \"pipeline.model.strategy\": \"mcmc\",\n",
    "    \"pipeline.model.output-depth-during-training\": True,\n",
    "    \"pipeline.model.rasterize-mode\": \"antialiased\",\n",
    "    \"pipeline.model.use-scale-regularization\": True,\n",
    "    \"pipeline.model.random-scale\": 1.0,\n",
    "    \"pipeline.model.num-downscales\": 1,\n",
    "    # \"pipeline.datamanager.dataparser.downscale-factor\": 1,\n",
    "    # \"pipeline.model.collider-params\": \"near_plane 0.1 far_plane 3.0\",\n",
    "}\n",
    "\n",
    "splatter.extract_features(\n",
    "    kwargs=feature_kwargs, \n",
    "    overwrite=True\n",
    ")\n",
    "print(\"\\nâœ“ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Training with Nerfstudio\n",
    "\n",
    "Now that preprocessing is complete, you can train a model using the generated data:\n",
    "\n",
    "### Option 1: Using Splatter Wrapper\n",
    "\n",
    "```python\n",
    "from collab_splats.wrapper import Splatter\n",
    "\n",
    "# Create config pointing to InfiniteVGGT preprocessing output\n",
    "splatter = Splatter(\n",
    "    dataset=\"bicycle\",\n",
    "    method=\"rade-features\",\n",
    "    file_path=image_dir,\n",
    "    input_type=\"images\",\n",
    "    output_path=output_base,\n",
    ")\n",
    "\n",
    "# Training will use the existing preproc directory\n",
    "splatter.extract_features(\n",
    "    kwargs={\n",
    "        \"pipeline.model.output-depth-during-training\": True,\n",
    "        \"pipeline.model.rasterize-mode\": \"antialiased\",\n",
    "    },\n",
    "    overwrite=True\n",
    ")\n",
    "```\n",
    "\n",
    "### Option 2: Direct ns-train\n",
    "\n",
    "```bash\n",
    "ns-train splatfacto \\\n",
    "  --data /workspace/bicycle/environment/bicycle_infinitevggt/preproc \\\n",
    "  --output-dir /workspace/bicycle/environment/bicycle_infinitevggt/outputs\n",
    "```\n",
    "\n",
    "## Key Differences: InfiniteVGGT vs VGGT-X\n",
    "\n",
    "| Feature | InfiniteVGGT | VGGT-X |\n",
    "|---------|--------------|--------|\n",
    "| **Architecture** | StreamVGGT with frame caching | Memory-optimized VGGT |\n",
    "| **Memory** | Uses frame budget system | Chunked processing |\n",
    "| **Best for** | Long sequences, streaming | General scenes |\n",
    "| **Output** | World points directly | Depth + camera poses |\n",
    "| **Speed** | Comparable to VGGT-X | 30-40% faster than original VGGT |\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory\n",
    "- Reduce `total_budget` (e.g., 800000)\n",
    "- Set `cache_results=False` and use `frame_cache_dir` for disk caching\n",
    "- Process fewer images at once\n",
    "\n",
    "### Poor Reconstruction Quality\n",
    "- Adjust `conf_threshold` (try 40.0 - 60.0)\n",
    "- Modify `scale_factor` (try 1.0 - 5.0)\n",
    "- Increase `max_points_for_colmap`\n",
    "\n",
    "### Missing Checkpoint\n",
    "```bash\n",
    "cd /workspace/InfiniteVGGT\n",
    "mkdir -p checkpoints\n",
    "cd checkpoints\n",
    "# Download from HuggingFace: https://huggingface.co/lch01/StreamVGGT\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
