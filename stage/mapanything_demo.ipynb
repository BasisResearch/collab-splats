{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapAnything Demo: Config-Driven Pipeline\n",
    "\n",
    "This notebook demonstrates the MapAnything pipeline using configuration from Splatter's YAML configs.\n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "1. **Load Config**: Load paths and settings from Splatter config file\n",
    "2. **Run MapAnything**: Execute the complete MapAnything pipeline\n",
    "3. **Visualize**: Visualize the reconstructed point cloud and cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Python executable: /opt/conda/envs/nerfstudio/bin/python\n",
      "Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n",
      "GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyvista as pv\n",
    "import pycolmap\n",
    "\n",
    "# Import Splatter for config loading\n",
    "from collab_splats.wrapper import Splatter\n",
    "\n",
    "# Import our modular utilities\n",
    "from mapanything_utils import (\n",
    "    load_mapanything_model,\n",
    "    load_and_preprocess_images,\n",
    "    run_mapanything_inference,\n",
    "    export_to_colmap,\n",
    "    rescale_to_original_dimensions,\n",
    "    convert_to_nerfstudio_format,\n",
    "    cleanup_gpu_memory,\n",
    ")\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration from Splatter\n",
    "\n",
    "Load dataset configuration using Splatter's config system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration: birds_date-02062024_video-C0043\n",
      "Config directory: /workspace/collab-splats/docs/splats/configs\n",
      "✓ Valid video file with 2388 frames\n",
      "\n",
      "======================================================================\n",
      "Configuration Loaded\n",
      "======================================================================\n",
      "Dataset: /workspace/fieldwork-data/birds/2024-02-06/SplatsSD/C0043.MP4\n",
      "Method: rade-features\n",
      "Input type: video\n",
      "Output: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configuration paths\n",
    "config_dir = Path(\"/workspace/collab-splats/docs/splats/configs\")\n",
    "dataset_name = \"birds_date-02062024_video-C0043\" #\"bicycle_mapanything\"\n",
    "\n",
    "print(f\"Loading configuration: {dataset_name}\")\n",
    "print(f\"Config directory: {config_dir}\")\n",
    "\n",
    "# Load the splatter configuration\n",
    "splatter = Splatter.from_config_file(\n",
    "    dataset=dataset_name,\n",
    "    config_dir=config_dir,\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"Configuration Loaded\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: {splatter.config['file_path']}\")\n",
    "print(f\"Method: {splatter.config['method']}\")\n",
    "print(f\"Input type: {splatter.config['input_type']}\")\n",
    "print(f\"Output: {splatter.config['output_path']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Paths and Parameters\n",
    "\n",
    "Extract the paths and parameters we need for MapAnything from the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths extracted from config:\n",
      "  Image directory: /workspace/fieldwork-data/birds/2024-02-06/SplatsSD/C0043.MP4\n",
      "  Output base: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043\n",
      "  Preprocessing dir: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc\n",
      "\n",
      "✓ Image directory verified\n"
     ]
    }
   ],
   "source": [
    "# Extract paths from config\n",
    "image_dir = Path(splatter.config['file_path'])\n",
    "output_base = Path(splatter.config['output_path'])\n",
    "preproc_dir = output_base / \"preproc\"\n",
    "colmap_dir = preproc_dir / \"colmap\"\n",
    "\n",
    "print(f\"Paths extracted from config:\")\n",
    "print(f\"  Image directory: {image_dir}\")\n",
    "print(f\"  Output base: {output_base}\")\n",
    "print(f\"  Preprocessing dir: {preproc_dir}\")\n",
    "\n",
    "# Verify image directory exists\n",
    "if not image_dir.exists():\n",
    "    raise ValueError(f\"Image directory does not exist: {image_dir}\")\n",
    "\n",
    "print(f\"\\n✓ Image directory verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure MapAnything Parameters\n",
    "\n",
    "Set up MapAnything model and inference parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapAnything Configuration:\n",
      "  Model: facebook/map-anything\n",
      "  Memory efficient: True\n",
      "  Voxel fraction: 0.02\n",
      "  Shared camera: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Model Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Model selection\n",
    "model_name = \"facebook/map-anything\"  # CC-BY-NC 4.0 license\n",
    "# model_name = \"facebook/map-anything-apache\"  # Apache 2.0 license\n",
    "\n",
    "# ============================================================================\n",
    "# Inference Parameters\n",
    "# ============================================================================\n",
    "\n",
    "inference_params = {\n",
    "    'memory_efficient_inference': True,\n",
    "    'minibatch_size': 1,\n",
    "    'use_amp': True,\n",
    "    'amp_dtype': 'bf16',  # Use 'fp16' for older GPUs\n",
    "    'apply_mask': True,\n",
    "    'mask_edges': True,\n",
    "    'apply_confidence_mask': True,\n",
    "    'use_multiview_confidence': True,\n",
    "    'confidence_percentile': 35.0,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# COLMAP Export Parameters\n",
    "# ============================================================================\n",
    "\n",
    "export_params = {\n",
    "    'voxel_fraction': 0.02,  # Voxel size as fraction of scene extent\n",
    "    'save_ply': True,\n",
    "    'save_images': True,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# Rescaling Parameters\n",
    "# ============================================================================\n",
    "\n",
    "rescale_params = {\n",
    "    'shared_camera': True,  # MapAnything typically uses shared camera\n",
    "    'shift_point2d_to_original_res': True,\n",
    "}\n",
    "\n",
    "print(f\"MapAnything Configuration:\")\n",
    "print(f\"  Model: {model_name}\")\n",
    "print(f\"  Memory efficient: {inference_params['memory_efficient_inference']}\")\n",
    "print(f\"  Voxel fraction: {export_params['voxel_fraction']}\")\n",
    "print(f\"  Shared camera: {rescale_params['shared_camera']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MapAnything Pipeline\n",
    "\n",
    "Execute the complete MapAnything pipeline using the paths from the config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load MapAnything Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Loading MapAnything model: facebook/map-anything</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mLoading MapAnything model: facebook/map-anything\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  GPU: NVIDIA A40\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  GPU: NVIDIA A40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained dinov2_vitg14 from torch hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /workspace/models/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Model loaded successfully</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Model loaded successfully\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model from HuggingFace\n",
    "model = load_mapanything_model(\n",
    "    model_name=model_name,\n",
    "    enable_optimizations=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Loading images from: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mLoading images from: \u001b[0m\u001b[1;36m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/\u001b[0m\u001b[1;36mimages\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> images\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Found \u001b[1;36m200\u001b[0m images\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Images loaded and preprocessed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Images loaded and preprocessed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Image shape: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">294</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Image shape: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m518\u001b[0m, \u001b[1;36m294\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model processes images at: 294x518\n",
      "Number of images: 200\n"
     ]
    }
   ],
   "source": [
    "if dataset_name != 'bicycle_mapanything':\n",
    "    image_dir = preproc_dir / 'images'\n",
    "\n",
    "# Load images from directory specified in config\n",
    "views, image_paths = load_and_preprocess_images(\n",
    "    image_dir=image_dir,\n",
    "    max_images=200,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Get model dimensions from preprocessed images\n",
    "model_width = views[0]['img'].shape[-1]\n",
    "model_height = views[0]['img'].shape[-2]\n",
    "\n",
    "print(f\"\\nModel processes images at: {model_width}x{model_height}\")\n",
    "print(f\"Number of images: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run MapAnything Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Running MapAnything inference</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRunning MapAnything inference\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Frames: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Frames: \u001b[1;36m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Memory efficient: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Memory efficient: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Minibatch size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Minibatch size: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Mixed precision: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>bf16<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Mixed precision: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mbf16\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking frustum containment: 100%|██████████| 4/4 [00:00<00:00, 298.51it/s]\n",
      "Checking triangle intersections: 100%|██████████| 4/4 [00:00<00:00, 76.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Inference complete</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Inference complete\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.</span>32s\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Total time: \u001b[1;36m76.\u001b[0m32s\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Time per frame: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>382s\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Time per frame: \u001b[1;36m0.\u001b[0m382s\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  FPS: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.62</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  FPS: \u001b[1;36m2.62\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Peak GPU memory: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.14</span> GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Peak GPU memory: \u001b[1;36m22.14\u001b[0m GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output keys:\n",
      "  pts3d: torch.Size([1, 518, 294, 3]) (torch.float32)\n",
      "  pts3d_cam: torch.Size([1, 518, 294, 3]) (torch.float32)\n",
      "  ray_directions: torch.Size([1, 518, 294, 3]) (torch.float32)\n",
      "  depth_along_ray: torch.Size([1, 518, 294, 1]) (torch.float32)\n",
      "  cam_trans: torch.Size([1, 3]) (torch.float32)\n",
      "  cam_quats: torch.Size([1, 4]) (torch.float32)\n",
      "  metric_scaling_factor: torch.Size([1, 1]) (torch.float32)\n",
      "  conf: torch.Size([1, 518, 294]) (torch.float32)\n",
      "  non_ambiguous_mask: torch.Size([1, 518, 294]) (torch.bool)\n",
      "  non_ambiguous_mask_logits: torch.Size([1, 518, 294]) (torch.float32)\n",
      "  img_no_norm: torch.Size([1, 518, 294, 3]) (torch.float32)\n",
      "  depth_z: torch.Size([1, 518, 294, 1]) (torch.float32)\n",
      "  intrinsics: torch.Size([1, 3, 3]) (torch.float32)\n",
      "  camera_poses: torch.Size([1, 4, 4]) (torch.float32)\n",
      "  mask: torch.Size([1, 518, 294, 1]) (torch.bool)\n"
     ]
    }
   ],
   "source": [
    "# Run inference to get poses, depth, and 3D points\n",
    "outputs = run_mapanything_inference(\n",
    "    model=model,\n",
    "    views=views,\n",
    "    verbose=True,\n",
    "    **inference_params\n",
    ")\n",
    "\n",
    "# Inspect outputs\n",
    "print(\"\\nOutput keys:\")\n",
    "for key in outputs[0].keys():\n",
    "    value = outputs[0][key]\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: {value.shape} ({value.dtype})\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  {key}: list of {len(value)} items\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Export to COLMAP Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Exporting to COLMAP format</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mExporting to COLMAP format\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Output directory: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">colmap</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Output directory: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/\u001b[0m\u001b[95mcolmap\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Voxel downsampling: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>% of scene extent\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Voxel downsampling: \u001b[1;36m0.5\u001b[0m% of scene extent\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Collecting 3D points from </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> frames...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mCollecting 3D points from \u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;36m frames\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total points before filtering: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17485076</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Total points before filtering: \u001b[1;36m17485076\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Spatial filtering (</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1.0</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">-</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">99.0</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> percentile):</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mSpatial filtering \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m1.0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m99.0\u001b[0m\u001b[1;33m percentile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Bounding box extent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30.</span>000m\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Bounding box extent: \u001b[1;36m30.\u001b[0m000m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Filtered from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17485076</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5248932</span> points\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Filtered from \u001b[1;36m17485076\u001b[0m to \u001b[1;36m5248932\u001b[0m points\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Removed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12236144</span> outliers <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70.0</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Removed \u001b[1;36m12236144\u001b[0m outliers \u001b[1m(\u001b[0m\u001b[1;36m70.0\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Voxel downsampling point cloud...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mVoxel downsampling point cloud\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Scene extent <span style=\"font-weight: bold\">(</span>IQR-based<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.</span>025m, full extent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30.</span>000m\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Scene extent \u001b[1m(\u001b[0mIQR-based\u001b[1m)\u001b[0m: \u001b[1;36m13.\u001b[0m025m, full extent: \u001b[1;36m30.\u001b[0m000m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Adaptive voxel size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>0651m\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Adaptive voxel size: \u001b[1;36m0.\u001b[0m0651m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downsampled from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5248932</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675426</span> points\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Downsampled from \u001b[1;36m5248932\u001b[0m to \u001b[1;36m675426\u001b[0m points\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Building COLMAP reconstruction...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mBuilding COLMAP reconstruction\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Backprojecting points to frames<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Backprojecting points to frames\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Built COLMAP reconstruction:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Built COLMAP reconstruction:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> images\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1;36m200\u001b[0m images\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675426</span> 3D points\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1;36m675426\u001b[0m 3D points\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59038594</span> Point2D observations\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1;36m59038594\u001b[0m Point2D observations\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Saved COLMAP reconstruction to: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Saved COLMAP reconstruction to: \u001b[0m\u001b[1;32m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/\u001b[0m\u001b[1;32msparse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Saved point cloud PLY to: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">points.ply</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Saved point cloud PLY to: \n",
       "\u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/\u001b[0m\u001b[95mpoints.ply\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Saved <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> processed images to: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Saved \u001b[1;36m200\u001b[0m processed images to: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/\u001b[0m\u001b[95mimages\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Exported to COLMAP format</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Exported to COLMAP format\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Output: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Output: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/\u001b[0m\u001b[95m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - cameras.bin\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - cameras.bin\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - images.bin\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - images.bin\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - points3D.bin\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - points3D.bin\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - points.ply\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - points.ply\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COLMAP reconstruction: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/0\n"
     ]
    }
   ],
   "source": [
    "# Get image names for COLMAP\n",
    "image_names = [p.name for p in image_paths]\n",
    "\n",
    "# # Export to COLMAP format\n",
    "# colmap_sparse_dir = export_to_colmap(\n",
    "#     outputs=outputs,\n",
    "#     views=views,\n",
    "#     image_names=image_names,\n",
    "#     output_dir=colmap_dir,\n",
    "#     model=model,\n",
    "#     verbose=True,\n",
    "#     **export_params\n",
    "# )\n",
    "\n",
    "export_params_updated = export_params.copy()\n",
    "# export_params_updated['spatial_filter_percentile'] = (1.0, 99.0)\n",
    "# export_params_updated['spatial_filter_max_extent'] = 25.0\n",
    "export_params_updated['voxel_fraction'] = 0.005\n",
    "\n",
    "# Remove outliers + clip to 50m max extent\n",
    "colmap_sparse_dir = export_to_colmap(\n",
    "    outputs=outputs,\n",
    "    views=views, \n",
    "    image_names=image_names, \n",
    "    output_dir=colmap_dir, \n",
    "    model=model,\n",
    "    spatial_filter_percentile=(1.0, 99.0),\n",
    "    spatial_filter_max_extent=30.0,\n",
    "    verbose=True,\n",
    "    **export_params_updated\n",
    ")\n",
    "\n",
    "print(f\"\\nCOLMAP reconstruction: {colmap_sparse_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Rescale to Original Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rescaled reconstruction: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/0\n"
     ]
    }
   ],
   "source": [
    "# Rescale reconstruction to original image sizes\n",
    "rescaled_dir = rescale_to_original_dimensions(\n",
    "    colmap_sparse_dir=colmap_sparse_dir,\n",
    "    image_paths=image_paths,\n",
    "    model_width=model_width,\n",
    "    model_height=model_height,\n",
    "    output_dir=preproc_dir,\n",
    "    verbose=True,\n",
    "    **rescale_params\n",
    ")\n",
    "\n",
    "# rescaled_sparse_dir = rescaled_dir / \"colmap\" / \"sparse\" / \"0\"\n",
    "print(f\"\\nRescaled reconstruction: {rescaled_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Convert to Nerfstudio Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Converting to nerfstudio format</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mConverting to nerfstudio format\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  COLMAP dir: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  COLMAP dir: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/\u001b[0m\u001b[95m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Output dir: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">preproc</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Output dir: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/\u001b[0m\u001b[95mpreproc\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Warning: More than one camera is found in </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mWarning: More than one camera is found in \u001b[0m\n",
       "\u001b[1;33m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/colmap/sparse/\u001b[0m\u001b[1;33m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{200: Camera(id=200, model='PINHOLE', width=294, height=518, params=array([454.71694946, 455.62411499, 146.52827454, 258.74172974])), 199: Camera(id=199, model='PINHOLE', width=294, height=518, params=array([461.49856567, 462.29397583, 146.4912262 , 258.68356323])), 198: Camera(id=198, model='PINHOLE', width=294, height=518, params=array([454.97314453, 455.83453369, 146.44416809, 258.67327881])), 197: Camera(id=197, model='PINHOLE', width=294, height=518, params=array([457.05584717, 458.70318604, 146.29042053, 258.70367432])), 196: Camera(id=196, model='PINHOLE', width=294, height=518, params=array([457.24343872, 458.87097168, 146.34733582, 258.69766235])), 195: Camera(id=195, model='PINHOLE', width=294, height=518, params=array([462.97399902, 464.62695312, 146.31620789, 258.17672729])), 194: Camera(id=194, model='PINHOLE', width=294, height=518, params=array([469.77023315, 470.95596313, 146.61053467, 258.19003296])), 193: Camera(id=193, model='PINHOLE', width=294, height=518, params=array([467.26708984, 468.87634277, 146.58558655, 257.95019531])), 192: Camera(id=192, model='PINHOLE', width=294, height=518, params=array([468.62207031, 469.02713013, 146.51167297, 258.14730835])), 191: Camera(id=191, model='PINHOLE', width=294, height=518, params=array([460.26031494, 462.49356079, 146.4979248 , 258.17129517])), 190: Camera(id=190, model='PINHOLE', width=294, height=518, params=array([463.9597168 , 464.9704895 , 146.64743042, 258.21923828])), 189: Camera(id=189, model='PINHOLE', width=294, height=518, params=array([473.98770142, 473.97653198, 146.52793884, 258.40045166])), 188: Camera(id=188, model='PINHOLE', width=294, height=518, params=array([462.44415283, 462.60696411, 146.46473694, 258.57928467])), 187: Camera(id=187, model='PINHOLE', width=294, height=518, params=array([457.68615723, 457.03137207, 146.50662231, 258.16088867])), 186: Camera(id=186, model='PINHOLE', width=294, height=518, params=array([471.82946777, 472.24530029, 146.41572571, 258.1567688 ])), 185: Camera(id=185, model='PINHOLE', width=294, height=518, params=array([444.12341309, 444.4815979 , 146.4460144 , 258.03070068])), 184: Camera(id=184, model='PINHOLE', width=294, height=518, params=array([436.57745361, 437.14779663, 146.50325012, 258.08123779])), 183: Camera(id=183, model='PINHOLE', width=294, height=518, params=array([418.36740112, 419.90924072, 146.56462097, 258.36907959])), 182: Camera(id=182, model='PINHOLE', width=294, height=518, params=array([430.40008545, 432.96316528, 146.65161133, 257.98010254])), 181: Camera(id=181, model='PINHOLE', width=294, height=518, params=array([469.93789673, 471.48895264, 147.03215027, 258.39215088])), 180: Camera(id=180, model='PINHOLE', width=294, height=518, params=array([471.65539551, 472.13189697, 147.09820557, 258.78533936])), 179: Camera(id=179, model='PINHOLE', width=294, height=518, params=array([449.40145874, 449.6567688 , 146.60749817, 258.20724487])), 178: Camera(id=178, model='PINHOLE', width=294, height=518, params=array([438.480896  , 437.85638428, 146.52403259, 258.30667114])), 177: Camera(id=177, model='PINHOLE', width=294, height=518, params=array([475.96511841, 473.56707764, 146.34194946, 259.22036743])), 176: Camera(id=176, model='PINHOLE', width=294, height=518, params=array([472.57369995, 470.25192261, 146.17379761, 259.19015503])), 175: Camera(id=175, model='PINHOLE', width=294, height=518, params=array([476.934021  , 475.80575562, 146.16186523, 258.77612305])), 174: Camera(id=174, model='PINHOLE', width=294, height=518, params=array([467.60375977, 467.07806396, 146.35415649, 258.56829834])), 173: Camera(id=173, model='PINHOLE', width=294, height=518, params=array([472.81799316, 473.52047729, 146.42111206, 258.15270996])), 172: Camera(id=172, model='PINHOLE', width=294, height=518, params=array([459.5451355 , 459.77770996, 146.34690857, 258.49667358])), 171: Camera(id=171, model='PINHOLE', width=294, height=518, params=array([454.01913452, 453.19442749, 146.48907471, 258.63122559])), 170: Camera(id=170, model='PINHOLE', width=294, height=518, params=array([476.41748047, 474.87194824, 146.54374695, 258.45019531])), 169: Camera(id=169, model='PINHOLE', width=294, height=518, params=array([476.62069702, 474.82659912, 146.33045959, 258.45059204])), 168: Camera(id=168, model='PINHOLE', width=294, height=518, params=array([435.64279175, 436.22494507, 146.27580261, 258.45401001])), 167: Camera(id=167, model='PINHOLE', width=294, height=518, params=array([468.01245117, 468.37057495, 146.39208984, 258.21325684])), 166: Camera(id=166, model='PINHOLE', width=294, height=518, params=array([453.98693848, 453.2119751 , 146.52819824, 258.08078003])), 165: Camera(id=165, model='PINHOLE', width=294, height=518, params=array([476.96118164, 476.0953064 , 146.39570618, 258.67224121])), 164: Camera(id=164, model='PINHOLE', width=294, height=518, params=array([456.35089111, 455.25750732, 146.3236084 , 258.80560303])), 163: Camera(id=163, model='PINHOLE', width=294, height=518, params=array([456.41107178, 457.35552979, 146.27580261, 258.81390381])), 162: Camera(id=162, model='PINHOLE', width=294, height=518, params=array([444.84988403, 445.39028931, 146.65927124, 258.08279419])), 161: Camera(id=161, model='PINHOLE', width=294, height=518, params=array([467.78668213, 467.92733765, 146.4627533 , 258.38964844])), 160: Camera(id=160, model='PINHOLE', width=294, height=518, params=array([472.05026245, 471.36120605, 146.49710083, 258.4750061 ])), 159: Camera(id=159, model='PINHOLE', width=294, height=518, params=array([431.29440308, 430.28579712, 146.67932129, 257.97131348])), 158: Camera(id=158, model='PINHOLE', width=294, height=518, params=array([468.96054077, 470.77020264, 146.40663147, 258.80450439])), 157: Camera(id=157, model='PINHOLE', width=294, height=518, params=array([466.93515015, 468.4105835 , 146.30711365, 258.97616577])), 156: Camera(id=156, model='PINHOLE', width=294, height=518, params=array([470.42382812, 471.39004517, 146.40415955, 259.09628296])), 155: Camera(id=155, model='PINHOLE', width=294, height=518, params=array([474.53952026, 474.3901062 , 146.42947388, 259.18148804])), 154: Camera(id=154, model='PINHOLE', width=294, height=518, params=array([466.96746826, 466.59521484, 146.23168945, 259.32803345])), 153: Camera(id=153, model='PINHOLE', width=294, height=518, params=array([469.46298218, 470.40130615, 146.3039856 , 258.92666626])), 152: Camera(id=152, model='PINHOLE', width=294, height=518, params=array([460.42059326, 460.13201904, 146.12818909, 259.47360229])), 151: Camera(id=151, model='PINHOLE', width=294, height=518, params=array([450.02740479, 451.12271118, 146.25782776, 259.57159424])), 150: Camera(id=150, model='PINHOLE', width=294, height=518, params=array([470.53707886, 470.83847046, 146.61920166, 259.08520508])), 149: Camera(id=149, model='PINHOLE', width=294, height=518, params=array([460.68789673, 462.32601929, 146.34259033, 259.21896362])), 148: Camera(id=148, model='PINHOLE', width=294, height=518, params=array([454.19320679, 455.75918579, 146.41969299, 258.94897461])), 147: Camera(id=147, model='PINHOLE', width=294, height=518, params=array([461.73202515, 460.73977661, 146.64442444, 259.29360962])), 146: Camera(id=146, model='PINHOLE', width=294, height=518, params=array([460.24752808, 459.84832764, 146.60975647, 259.24685669])), 145: Camera(id=145, model='PINHOLE', width=294, height=518, params=array([456.49462891, 455.70697021, 146.36585999, 259.15139771])), 144: Camera(id=144, model='PINHOLE', width=294, height=518, params=array([459.92645264, 460.03964233, 146.54829407, 259.49798584])), 143: Camera(id=143, model='PINHOLE', width=294, height=518, params=array([451.4624939 , 450.78631592, 146.58607483, 258.82839966])), 142: Camera(id=142, model='PINHOLE', width=294, height=518, params=array([442.83413696, 442.14761353, 146.58813477, 258.7930603 ])), 141: Camera(id=141, model='PINHOLE', width=294, height=518, params=array([447.92315674, 448.55728149, 146.69065857, 258.7802124 ])), 140: Camera(id=140, model='PINHOLE', width=294, height=518, params=array([446.52163696, 448.30181885, 146.62117004, 258.41299438])), 139: Camera(id=139, model='PINHOLE', width=294, height=518, params=array([447.12820435, 448.18548584, 146.80137634, 258.83132935])), 138: Camera(id=138, model='PINHOLE', width=294, height=518, params=array([471.24081421, 470.24703979, 146.97981262, 259.35437012])), 137: Camera(id=137, model='PINHOLE', width=294, height=518, params=array([463.69747925, 463.66030884, 146.8494873 , 258.23562622])), 136: Camera(id=136, model='PINHOLE', width=294, height=518, params=array([473.46057129, 473.39318848, 146.72929382, 258.40478516])), 135: Camera(id=135, model='PINHOLE', width=294, height=518, params=array([471.26821899, 469.42105103, 146.57597351, 258.45578003])), 134: Camera(id=134, model='PINHOLE', width=294, height=518, params=array([476.69412231, 474.70565796, 146.80844116, 258.68936157])), 133: Camera(id=133, model='PINHOLE', width=294, height=518, params=array([472.25790405, 471.55044556, 146.7243042 , 258.80618286])), 132: Camera(id=132, model='PINHOLE', width=294, height=518, params=array([471.45217896, 469.69546509, 146.5629425 , 258.93814087])), 131: Camera(id=131, model='PINHOLE', width=294, height=518, params=array([466.81750488, 465.04821777, 146.53981018, 258.57354736])), 130: Camera(id=130, model='PINHOLE', width=294, height=518, params=array([429.8175354 , 429.62588501, 146.64781189, 257.67388916])), 129: Camera(id=129, model='PINHOLE', width=294, height=518, params=array([430.46887207, 429.83737183, 146.2093811 , 257.69625854])), 128: Camera(id=128, model='PINHOLE', width=294, height=518, params=array([421.67080688, 420.42617798, 146.27914429, 258.93362427])), 59: Camera(id=59, model='PINHOLE', width=294, height=518, params=array([475.44042969, 473.80633545, 146.545578  , 259.52114868])), 58: Camera(id=58, model='PINHOLE', width=294, height=518, params=array([471.34835815, 469.57650757, 146.30368042, 259.28881836])), 57: Camera(id=57, model='PINHOLE', width=294, height=518, params=array([458.9005127 , 457.19003296, 146.34915161, 258.57067871])), 56: Camera(id=56, model='PINHOLE', width=294, height=518, params=array([469.5133667 , 468.09747314, 146.20040894, 258.92785645])), 55: Camera(id=55, model='PINHOLE', width=294, height=518, params=array([466.92962646, 466.92105103, 146.22311401, 259.05340576])), 54: Camera(id=54, model='PINHOLE', width=294, height=518, params=array([466.97998047, 466.96261597, 146.25628662, 258.53640747])), 53: Camera(id=53, model='PINHOLE', width=294, height=518, params=array([468.80706787, 469.23278809, 146.29019165, 258.63867188])), 52: Camera(id=52, model='PINHOLE', width=294, height=518, params=array([461.5848999 , 462.51446533, 146.37989807, 258.83343506])), 51: Camera(id=51, model='PINHOLE', width=294, height=518, params=array([469.53363037, 470.65603638, 146.31439209, 258.64526367])), 50: Camera(id=50, model='PINHOLE', width=294, height=518, params=array([459.98098755, 460.25344849, 146.45341492, 258.60232544])), 49: Camera(id=49, model='PINHOLE', width=294, height=518, params=array([453.49819946, 454.70825195, 146.52426147, 258.51730347])), 48: Camera(id=48, model='PINHOLE', width=294, height=518, params=array([464.09466553, 463.85186768, 146.49330139, 258.59609985])), 47: Camera(id=47, model='PINHOLE', width=294, height=518, params=array([464.05117798, 463.50723267, 146.60977173, 258.29660034])), 46: Camera(id=46, model='PINHOLE', width=294, height=518, params=array([465.69467163, 464.65692139, 146.42698669, 258.55441284])), 45: Camera(id=45, model='PINHOLE', width=294, height=518, params=array([464.76437378, 464.75323486, 146.34181213, 258.82550049])), 44: Camera(id=44, model='PINHOLE', width=294, height=518, params=array([473.39926147, 472.82565308, 146.39059448, 258.60830688])), 43: Camera(id=43, model='PINHOLE', width=294, height=518, params=array([471.22918701, 471.38284302, 146.40058899, 258.54620361])), 42: Camera(id=42, model='PINHOLE', width=294, height=518, params=array([475.02236938, 474.75924683, 146.38891602, 258.67932129])), 41: Camera(id=41, model='PINHOLE', width=294, height=518, params=array([474.97399902, 475.41235352, 146.33163452, 258.73965454])), 40: Camera(id=40, model='PINHOLE', width=294, height=518, params=array([480.28744507, 479.90441895, 146.50033569, 258.46490479])), 39: Camera(id=39, model='PINHOLE', width=294, height=518, params=array([473.4883728 , 474.0300293 , 146.6481781 , 258.52905273])), 38: Camera(id=38, model='PINHOLE', width=294, height=518, params=array([478.14923096, 479.09243774, 146.57881165, 258.99035645])), 37: Camera(id=37, model='PINHOLE', width=294, height=518, params=array([480.65618896, 480.51629639, 146.56208801, 258.6812439 ])), 36: Camera(id=36, model='PINHOLE', width=294, height=518, params=array([467.51074219, 467.61938477, 146.46232605, 258.82415771])), 35: Camera(id=35, model='PINHOLE', width=294, height=518, params=array([469.24090576, 468.66662598, 146.49513245, 259.00665283])), 34: Camera(id=34, model='PINHOLE', width=294, height=518, params=array([474.04412842, 473.5105896 , 146.50605774, 258.82394409])), 33: Camera(id=33, model='PINHOLE', width=294, height=518, params=array([465.72317505, 464.57608032, 146.46995544, 258.5484314 ])), 32: Camera(id=32, model='PINHOLE', width=294, height=518, params=array([477.38485718, 477.0329895 , 146.34082031, 258.70684814])), 31: Camera(id=31, model='PINHOLE', width=294, height=518, params=array([473.1635437 , 472.42608643, 146.46443176, 258.5847168 ])), 30: Camera(id=30, model='PINHOLE', width=294, height=518, params=array([473.66210938, 473.72143555, 146.44316101, 258.72988892])), 13: Camera(id=13, model='PINHOLE', width=294, height=518, params=array([483.39187622, 483.22171021, 146.82575989, 258.00985718])), 12: Camera(id=12, model='PINHOLE', width=294, height=518, params=array([480.71139526, 481.05349731, 146.59779358, 258.16226196])), 11: Camera(id=11, model='PINHOLE', width=294, height=518, params=array([477.69262695, 477.21817017, 146.85961914, 257.6104126 ])), 10: Camera(id=10, model='PINHOLE', width=294, height=518, params=array([476.10147095, 476.39398193, 146.87928772, 257.96392822])), 9: Camera(id=9, model='PINHOLE', width=294, height=518, params=array([475.84371948, 476.57440186, 146.71324158, 257.8727417 ])), 8: Camera(id=8, model='PINHOLE', width=294, height=518, params=array([478.28720093, 479.92663574, 146.6746521 , 257.77026367])), 7: Camera(id=7, model='PINHOLE', width=294, height=518, params=array([479.04232788, 480.4367981 , 146.81108093, 257.65884399])), 6: Camera(id=6, model='PINHOLE', width=294, height=518, params=array([471.2331543 , 473.88400269, 146.86802673, 257.88412476])), 5: Camera(id=5, model='PINHOLE', width=294, height=518, params=array([469.98129272, 472.1734314 , 146.47268677, 257.98513794])), 4: Camera(id=4, model='PINHOLE', width=294, height=518, params=array([464.93331909, 467.12030029, 146.51759338, 257.88134766])), 3: Camera(id=3, model='PINHOLE', width=294, height=518, params=array([466.51953125, 468.77667236, 146.47108459, 258.3742981 ])), 2: Camera(id=2, model='PINHOLE', width=294, height=518, params=array([470.53036499, 472.16143799, 146.60293579, 258.41748047])), 1: Camera(id=1, model='PINHOLE', width=294, height=518, params=array([472.52597046, 474.41934204, 146.66429138, 257.95962524])), 14: Camera(id=14, model='PINHOLE', width=294, height=518, params=array([479.87142944, 480.36074829, 146.62200928, 258.31167603])), 15: Camera(id=15, model='PINHOLE', width=294, height=518, params=array([479.39016724, 480.66317749, 146.64746094, 258.37475586])), 16: Camera(id=16, model='PINHOLE', width=294, height=518, params=array([476.88925171, 476.76339722, 146.63569641, 257.93832397])), 17: Camera(id=17, model='PINHOLE', width=294, height=518, params=array([481.19897461, 481.02850342, 146.55838013, 258.01550293])), 18: Camera(id=18, model='PINHOLE', width=294, height=518, params=array([476.70379639, 476.35464478, 146.61291504, 258.31900024])), 19: Camera(id=19, model='PINHOLE', width=294, height=518, params=array([479.27685547, 478.16693115, 146.5035553 , 258.05703735])), 20: Camera(id=20, model='PINHOLE', width=294, height=518, params=array([484.63122559, 482.48355103, 146.45037842, 258.20458984])), 21: Camera(id=21, model='PINHOLE', width=294, height=518, params=array([489.43011475, 488.44564819, 146.72798157, 257.55255127])), 22: Camera(id=22, model='PINHOLE', width=294, height=518, params=array([488.68887329, 488.15579224, 146.82206726, 257.62948608])), 23: Camera(id=23, model='PINHOLE', width=294, height=518, params=array([479.86953735, 480.81472778, 146.73117065, 258.040802  ])), 24: Camera(id=24, model='PINHOLE', width=294, height=518, params=array([478.70401001, 479.80899048, 146.54768372, 258.25405884])), 25: Camera(id=25, model='PINHOLE', width=294, height=518, params=array([478.58706665, 479.37426758, 146.3989563 , 258.22253418])), 26: Camera(id=26, model='PINHOLE', width=294, height=518, params=array([481.04458618, 478.15365601, 146.58903503, 257.93222046])), 27: Camera(id=27, model='PINHOLE', width=294, height=518, params=array([486.91238403, 484.5838623 , 146.65733337, 258.31878662])), 28: Camera(id=28, model='PINHOLE', width=294, height=518, params=array([473.70043945, 473.87081909, 146.86763   , 259.21102905])), 29: Camera(id=29, model='PINHOLE', width=294, height=518, params=array([475.77285767, 475.66323853, 146.62062073, 258.95556641])), 60: Camera(id=60, model='PINHOLE', width=294, height=518, params=array([470.12072754, 469.11950684, 146.28910828, 259.50091553])), 61: Camera(id=61, model='PINHOLE', width=294, height=518, params=array([473.75588989, 471.38204956, 146.30229187, 259.37203979])), 62: Camera(id=62, model='PINHOLE', width=294, height=518, params=array([456.66775513, 455.23861694, 146.09683228, 259.17980957])), 63: Camera(id=63, model='PINHOLE', width=294, height=518, params=array([462.13867188, 462.29336548, 146.50135803, 258.96014404])), 64: Camera(id=64, model='PINHOLE', width=294, height=518, params=array([462.18334961, 460.50588989, 146.32929993, 258.58071899])), 65: Camera(id=65, model='PINHOLE', width=294, height=518, params=array([467.17056274, 466.65124512, 146.40371704, 258.72396851])), 66: Camera(id=66, model='PINHOLE', width=294, height=518, params=array([459.65353394, 459.71011353, 146.66069031, 258.99484253])), 67: Camera(id=67, model='PINHOLE', width=294, height=518, params=array([455.99017334, 455.15081787, 146.78755188, 258.99987793])), 68: Camera(id=68, model='PINHOLE', width=294, height=518, params=array([470.43353271, 471.26251221, 146.9908905 , 259.00143433])), 69: Camera(id=69, model='PINHOLE', width=294, height=518, params=array([463.57885742, 465.20098877, 146.79597473, 258.62991333])), 70: Camera(id=70, model='PINHOLE', width=294, height=518, params=array([471.52148438, 472.51483154, 146.79426575, 258.80422974])), 71: Camera(id=71, model='PINHOLE', width=294, height=518, params=array([459.89810181, 460.9647522 , 146.86161804, 259.2852478 ])), 72: Camera(id=72, model='PINHOLE', width=294, height=518, params=array([458.50991821, 458.38220215, 146.65621948, 259.35324097])), 73: Camera(id=73, model='PINHOLE', width=294, height=518, params=array([471.27191162, 469.43206787, 146.64831543, 259.55178833])), 74: Camera(id=74, model='PINHOLE', width=294, height=518, params=array([470.32202148, 469.21795654, 146.81053162, 258.89556885])), 75: Camera(id=75, model='PINHOLE', width=294, height=518, params=array([471.14596558, 470.23199463, 146.85934448, 259.43963623])), 76: Camera(id=76, model='PINHOLE', width=294, height=518, params=array([481.57614136, 478.55603027, 146.74046326, 259.01513672])), 77: Camera(id=77, model='PINHOLE', width=294, height=518, params=array([475.2230835 , 474.0765686 , 146.87408447, 258.7322998 ])), 78: Camera(id=78, model='PINHOLE', width=294, height=518, params=array([466.27575684, 465.1071167 , 146.89620972, 259.2388916 ])), 79: Camera(id=79, model='PINHOLE', width=294, height=518, params=array([441.76193237, 441.84906006, 146.95854187, 259.55200195])), 80: Camera(id=80, model='PINHOLE', width=294, height=518, params=array([449.01821899, 448.34246826, 147.06399536, 259.22167969])), 81: Camera(id=81, model='PINHOLE', width=294, height=518, params=array([455.03604126, 453.22677612, 147.12591553, 259.46014404])), 82: Camera(id=82, model='PINHOLE', width=294, height=518, params=array([467.92626953, 465.18597412, 146.65750122, 258.69482422])), 83: Camera(id=83, model='PINHOLE', width=294, height=518, params=array([457.26177979, 455.31124878, 147.00791931, 258.77774048])), 84: Camera(id=84, model='PINHOLE', width=294, height=518, params=array([476.92739868, 475.48376465, 146.67541504, 259.01202393])), 85: Camera(id=85, model='PINHOLE', width=294, height=518, params=array([463.47747803, 462.61834717, 146.82698059, 259.18051147])), 86: Camera(id=86, model='PINHOLE', width=294, height=518, params=array([475.21923828, 472.644104  , 146.6343689 , 259.29425049])), 87: Camera(id=87, model='PINHOLE', width=294, height=518, params=array([473.39263916, 471.06665039, 146.36419678, 259.66275024])), 88: Camera(id=88, model='PINHOLE', width=294, height=518, params=array([455.0423584 , 453.84902954, 146.46105957, 259.56097412])), 89: Camera(id=89, model='PINHOLE', width=294, height=518, params=array([459.64279175, 459.30755615, 146.59448242, 259.44107056])), 90: Camera(id=90, model='PINHOLE', width=294, height=518, params=array([461.93322754, 460.37127686, 146.29698181, 259.63696289])), 91: Camera(id=91, model='PINHOLE', width=294, height=518, params=array([473.00357056, 471.61956787, 146.35176086, 259.42254639])), 92: Camera(id=92, model='PINHOLE', width=294, height=518, params=array([466.86730957, 465.93127441, 146.46694946, 259.38101196])), 93: Camera(id=93, model='PINHOLE', width=294, height=518, params=array([471.57165527, 471.30728149, 146.62042236, 258.92340088])), 94: Camera(id=94, model='PINHOLE', width=294, height=518, params=array([472.99194336, 471.4932251 , 146.57839966, 258.92825317])), 95: Camera(id=95, model='PINHOLE', width=294, height=518, params=array([472.94235229, 470.8203125 , 146.57641602, 259.01425171])), 96: Camera(id=96, model='PINHOLE', width=294, height=518, params=array([475.15493774, 472.88430786, 146.54612732, 258.72637939])), 97: Camera(id=97, model='PINHOLE', width=294, height=518, params=array([471.49523926, 468.17971802, 146.6479187 , 259.07409668])), 98: Camera(id=98, model='PINHOLE', width=294, height=518, params=array([473.99481201, 470.69961548, 146.62237549, 259.15322876])), 99: Camera(id=99, model='PINHOLE', width=294, height=518, params=array([475.21173096, 473.23931885, 146.60545349, 259.00769043])), 100: Camera(id=100, model='PINHOLE', width=294, height=518, params=array([440.9956665 , 440.37686157, 146.64187622, 259.05545044])), 101: Camera(id=101, model='PINHOLE', width=294, height=518, params=array([476.84194946, 472.82485962, 146.85406494, 259.42095947])), 102: Camera(id=102, model='PINHOLE', width=294, height=518, params=array([481.16815186, 478.65298462, 146.80854797, 258.96017456])), 103: Camera(id=103, model='PINHOLE', width=294, height=518, params=array([467.17648315, 464.92370605, 146.89044189, 259.07855225])), 104: Camera(id=104, model='PINHOLE', width=294, height=518, params=array([473.28417969, 469.75378418, 146.97254944, 259.13153076])), 105: Camera(id=105, model='PINHOLE', width=294, height=518, params=array([479.19204712, 475.66448975, 147.02075195, 258.65435791])), 106: Camera(id=106, model='PINHOLE', width=294, height=518, params=array([464.50665283, 461.40881348, 147.00663757, 258.84854126])), 107: Camera(id=107, model='PINHOLE', width=294, height=518, params=array([464.93133545, 462.43710327, 146.82281494, 259.12850952])), 108: Camera(id=108, model='PINHOLE', width=294, height=518, params=array([464.26107788, 463.05752563, 146.7959137 , 259.27880859])), 109: Camera(id=109, model='PINHOLE', width=294, height=518, params=array([473.11730957, 470.64758301, 146.84487915, 259.10043335])), 110: Camera(id=110, model='PINHOLE', width=294, height=518, params=array([460.27914429, 457.93386841, 146.71784973, 259.1477356 ])), 111: Camera(id=111, model='PINHOLE', width=294, height=518, params=array([471.97290039, 469.52514648, 146.70541382, 258.89361572])), 112: Camera(id=112, model='PINHOLE', width=294, height=518, params=array([470.7543335 , 467.48583984, 146.63009644, 258.85693359])), 113: Camera(id=113, model='PINHOLE', width=294, height=518, params=array([473.0269165 , 469.58010864, 146.51313782, 258.68411255])), 114: Camera(id=114, model='PINHOLE', width=294, height=518, params=array([472.86779785, 469.44232178, 146.39416504, 259.34643555])), 115: Camera(id=115, model='PINHOLE', width=294, height=518, params=array([476.28161621, 475.74291992, 146.42269897, 258.85150146])), 116: Camera(id=116, model='PINHOLE', width=294, height=518, params=array([476.7220459 , 475.16323853, 146.55747986, 258.57058716])), 117: Camera(id=117, model='PINHOLE', width=294, height=518, params=array([473.6920166 , 472.24923706, 146.57911682, 258.97171021])), 118: Camera(id=118, model='PINHOLE', width=294, height=518, params=array([464.590271  , 464.65811157, 146.43832397, 258.89440918])), 119: Camera(id=119, model='PINHOLE', width=294, height=518, params=array([466.09069824, 465.5010376 , 146.59565735, 258.83914185])), 120: Camera(id=120, model='PINHOLE', width=294, height=518, params=array([470.77987671, 469.13290405, 146.72027588, 258.44976807])), 121: Camera(id=121, model='PINHOLE', width=294, height=518, params=array([436.98007202, 436.79333496, 146.66184998, 258.01873779])), 122: Camera(id=122, model='PINHOLE', width=294, height=518, params=array([449.47756958, 449.08282471, 146.63755798, 258.13726807])), 123: Camera(id=123, model='PINHOLE', width=294, height=518, params=array([461.24850464, 462.58267212, 147.05570984, 258.97280884])), 124: Camera(id=124, model='PINHOLE', width=294, height=518, params=array([423.83737183, 426.42001343, 146.98080444, 257.9967041 ])), 125: Camera(id=125, model='PINHOLE', width=294, height=518, params=array([425.16812134, 423.25134277, 147.00942993, 258.45404053])), 126: Camera(id=126, model='PINHOLE', width=294, height=518, params=array([423.25796509, 423.05728149, 146.96679688, 258.88995361])), 127: Camera(id=127, model='PINHOLE', width=294, height=518, params=array([415.20263672, 415.03421021, 146.27404785, 259.03668213]))}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Copying point cloud from COLMAP\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Copying point cloud from COLMAP\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Nerfstudio format conversion complete</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Nerfstudio format conversion complete\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  transforms.json: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">transforms.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  transforms.json: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/\u001b[0m\u001b[95mtransforms.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Point cloud: <span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">sparse_pc.ply</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Point cloud: \u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/\u001b[0m\u001b[95msparse_pc.ply\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nerfstudio transforms: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/transforms.json\n"
     ]
    }
   ],
   "source": [
    "# Convert to transforms.json\n",
    "transforms_path = convert_to_nerfstudio_format(\n",
    "    colmap_sparse_dir=rescaled_sparse_dir,\n",
    "    output_dir=preproc_dir,\n",
    "    ply_filename=\"sparse_pc.ply\",\n",
    "    copy_ply_from_colmap=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nNerfstudio transforms: {transforms_path}\")\n",
    "ply_path = preproc_dir / \"sparse_pc.ply\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Clean Up GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Cleaning up GPU memory</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mCleaning up GPU memory\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ GPU memory cleaned</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ GPU memory cleaned\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Allocated: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.98</span> GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Allocated: \u001b[1;36m6.98\u001b[0m GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Reserved: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.06</span> GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Reserved: \u001b[1;36m11.06\u001b[0m GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Free up GPU memory\n",
    "cleanup_gpu_memory(\n",
    "    model=model,\n",
    "    outputs=outputs,\n",
    "    views=views,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Splatter Config with Preprocessing Path\n",
    "\n",
    "Update the Splatter config to point to our MapAnything outputs for future training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Splatter config:\n",
      "  Preprocessing path: /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc\n",
      "\n",
      "This path can now be used for training with:\n",
      "  splatter.extract_features(overwrite=True)\n"
     ]
    }
   ],
   "source": [
    "# Set the preprocessing data path in splatter config\n",
    "splatter.config[\"preproc_data_path\"] = preproc_dir\n",
    "\n",
    "print(f\"Updated Splatter config:\")\n",
    "print(f\"  Preprocessing path: {splatter.config['preproc_data_path']}\")\n",
    "print(f\"\\nThis path can now be used for training with:\")\n",
    "print(f\"  splatter.extract_features(overwrite=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Point Cloud\n",
    "\n",
    "Visualize the reconstructed sparse point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud loaded: 675,426 points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2492682d4444659806036f67811bb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:38257/index.html?ui=P_0x7fa103584f40_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load point cloud\n",
    "point_cloud = pv.PolyData(str(ply_path))\n",
    "\n",
    "# Handle RGBA colors\n",
    "if 'RGBA' in point_cloud.point_data:\n",
    "    point_cloud.point_data['RGB'] = point_cloud.point_data['RGBA'][:, :3]\n",
    "\n",
    "print(f\"Point cloud loaded: {point_cloud.n_points:,} points\")\n",
    "\n",
    "# Create plotter\n",
    "plotter = pv.Plotter(window_size=[1200, 800])\n",
    "\n",
    "# Add point cloud\n",
    "plotter.add_mesh(\n",
    "    point_cloud,\n",
    "    scalars='RGB',\n",
    "    rgb=True,\n",
    "    point_size=1,\n",
    "    render_points_as_spheres=False,\n",
    ")\n",
    "\n",
    "# Add coordinate axes\n",
    "plotter.add_axes(\n",
    "    xlabel='X',\n",
    "    ylabel='Y',\n",
    "    zlabel='Z',\n",
    "    line_width=5,\n",
    ")\n",
    "\n",
    "# Set camera view\n",
    "plotter.camera_position = 'iso'\n",
    "plotter.enable_eye_dome_lighting()  # Better depth perception\n",
    "\n",
    "# Add title\n",
    "plotter.add_text(\n",
    "    f\"MapAnything Reconstruction\\n{point_cloud.n_points:,} points\",\n",
    "    position='upper_left',\n",
    "    font_size=12,\n",
    "    color='white',\n",
    ")\n",
    "\n",
    "# Show\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Camera Poses\n",
    "\n",
    "Visualize camera poses from the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reconstruction\n",
    "reconstruction = pycolmap.Reconstruction(str(rescaled_sparse_dir))\n",
    "\n",
    "print(f\"Reconstruction loaded:\")\n",
    "print(f\"  Cameras: {len(reconstruction.cameras)}\")\n",
    "print(f\"  Images: {len(reconstruction.images)}\")\n",
    "print(f\"  Points3D: {len(reconstruction.points3D)}\")\n",
    "\n",
    "# Extract camera positions and orientations\n",
    "camera_positions = []\n",
    "camera_directions = []\n",
    "\n",
    "for img_id, image in reconstruction.images.items():\n",
    "    # Get camera center in world coordinates\n",
    "    camera_center = image.projection_center()\n",
    "    camera_positions.append(camera_center)\n",
    "    \n",
    "    # Get camera viewing direction (negative Z axis in camera space)\n",
    "    R = image.cam_from_world.rotation.matrix()\n",
    "    view_direction = R[2, :]  # Negative Z axis\n",
    "    camera_directions.append(view_direction)\n",
    "\n",
    "camera_positions = np.array(camera_positions)\n",
    "camera_directions = np.array(camera_directions)\n",
    "\n",
    "print(f\"\\nCamera trajectory:\")\n",
    "print(f\"  Start: {camera_positions[0]}\")\n",
    "print(f\"  End: {camera_positions[-1]}\")\n",
    "print(f\"  Total distance: {np.linalg.norm(camera_positions[-1] - camera_positions[0]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cameras and point cloud together\n",
    "plotter = pv.Plotter(window_size=[1200, 800])\n",
    "\n",
    "# Add point cloud (smaller points)\n",
    "plotter.add_mesh(\n",
    "    point_cloud,\n",
    "    scalars='RGB',\n",
    "    rgb=True,\n",
    "    point_size=1,\n",
    "    opacity=0.5,\n",
    ")\n",
    "\n",
    "# Add camera centers\n",
    "camera_cloud = pv.PolyData(camera_positions)\n",
    "plotter.add_mesh(\n",
    "    camera_cloud,\n",
    "    color='red',\n",
    "    point_size=10,\n",
    "    render_points_as_spheres=True,\n",
    "    label='Camera Centers',\n",
    ")\n",
    "\n",
    "# Add camera trajectory\n",
    "if len(camera_positions) > 1:\n",
    "    trajectory = pv.PolyData(camera_positions)\n",
    "    trajectory.lines = np.hstack([[2, i, i+1] for i in range(len(camera_positions)-1)])\n",
    "    plotter.add_mesh(\n",
    "        trajectory,\n",
    "        color='yellow',\n",
    "        line_width=3,\n",
    "        label='Camera Trajectory',\n",
    "    )\n",
    "\n",
    "# Add camera viewing directions (arrows)\n",
    "arrow_scale = 0.5\n",
    "for pos, direction in zip(camera_positions[::5], camera_directions[::5]):  # Show every 5th camera\n",
    "    arrow = pv.Arrow(\n",
    "        start=pos,\n",
    "        direction=direction,\n",
    "        scale=arrow_scale,\n",
    "    )\n",
    "    plotter.add_mesh(\n",
    "        arrow,\n",
    "        color='cyan',\n",
    "        opacity=0.7,\n",
    "    )\n",
    "\n",
    "# Add axes\n",
    "plotter.add_axes(\n",
    "    xlabel='X',\n",
    "    ylabel='Y',\n",
    "    zlabel='Z',\n",
    "    line_width=5,\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "plotter.add_legend()\n",
    "\n",
    "# Set view\n",
    "plotter.camera_position = 'iso'\n",
    "plotter.enable_eye_dome_lighting()\n",
    "\n",
    "# Add title\n",
    "plotter.add_text(\n",
    "    f\"Camera Poses & Reconstruction\\n{len(camera_positions)} cameras, {point_cloud.n_points:,} points\",\n",
    "    position='upper_left',\n",
    "    font_size=12,\n",
    "    color='white',\n",
    ")\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection: Reconstruction Quality\n",
    "\n",
    "Analyze the quality of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transforms.json\n",
    "with open(transforms_path) as f:\n",
    "    transforms = json.load(f)\n",
    "\n",
    "print(\"Reconstruction Statistics:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: {image_dir.name}\")\n",
    "print(f\"\\nImages:\")\n",
    "print(f\"  Total: {len(reconstruction.images)}\")\n",
    "print(f\"  Registered: {len([img for img in reconstruction.images.values() if img.registered])}\")\n",
    "\n",
    "print(f\"\\nCameras:\")\n",
    "print(f\"  Total: {len(reconstruction.cameras)}\")\n",
    "for cam_id, camera in list(reconstruction.cameras.items())[:3]:  # Show first 3 cameras\n",
    "    print(f\"  Camera {cam_id}: {camera.model.name} - {camera.width}x{camera.height}\")\n",
    "    print(f\"    Focal: fx={camera.params[0]:.2f}, fy={camera.params[1]:.2f}\")\n",
    "    print(f\"    Principal: cx={camera.params[2]:.2f}, cy={camera.params[3]:.2f}\")\n",
    "\n",
    "print(f\"\\nPoint Cloud:\")\n",
    "print(f\"  3D Points: {len(reconstruction.points3D):,}\")\n",
    "print(f\"  PLY Points: {point_cloud.n_points:,}\")\n",
    "\n",
    "# Compute point cloud statistics\n",
    "points = np.array([pt.xyz for pt in reconstruction.points3D.values()])\n",
    "if len(points) > 0:\n",
    "    print(f\"\\nPoint Cloud Extent:\")\n",
    "    print(f\"  X: [{points[:, 0].min():.2f}, {points[:, 0].max():.2f}]\")\n",
    "    print(f\"  Y: [{points[:, 1].min():.2f}, {points[:, 1].max():.2f}]\")\n",
    "    print(f\"  Z: [{points[:, 2].min():.2f}, {points[:, 2].max():.2f}]\")\n",
    "    \n",
    "    # Compute scene scale\n",
    "    scene_extent = points.max(axis=0) - points.min(axis=0)\n",
    "    scene_diagonal = np.linalg.norm(scene_extent)\n",
    "    print(f\"\\n  Scene diagonal: {scene_diagonal:.2f}\")\n",
    "\n",
    "# Camera trajectory statistics\n",
    "trajectory_length = np.sum(np.linalg.norm(np.diff(camera_positions, axis=0), axis=1))\n",
    "print(f\"\\nCamera Trajectory:\")\n",
    "print(f\"  Total length: {trajectory_length:.2f}\")\n",
    "print(f\"  Average step: {trajectory_length / (len(camera_positions) - 1):.2f}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "MapAnything preprocessing complete and ready for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MAPANYTHING PIPELINE COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n📁 Configuration:\")\n",
    "print(f\"  Dataset: {dataset_name}\")\n",
    "print(f\"  Config dir: {config_dir}\")\n",
    "\n",
    "print(f\"\\n📸 Input:\")\n",
    "print(f\"  Images: {image_dir}\")\n",
    "print(f\"  Count: {len(image_paths)} images\")\n",
    "\n",
    "print(f\"\\n📊 MapAnything Outputs:\")\n",
    "print(f\"  Preprocessing: {preproc_dir}\")\n",
    "print(f\"  transforms.json: {transforms_path}\")\n",
    "print(f\"  Point cloud: {ply_path} ({point_cloud.n_points:,} points)\")\n",
    "print(f\"  COLMAP: {rescaled_sparse_dir}\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps:\")\n",
    "print(f\"  Train model: splatter.extract_features(overwrite=True)\")\n",
    "print(f\"  Or use nerfstudio directly: ns-train {splatter.config['method']} --data {preproc_dir}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
