{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4164e70",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b080a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/conda/envs/nerfstudio/bin/python\n",
      "Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n",
      "\n",
      "✓ Running in nerfstudio environment\n",
      "✓ Imports complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-1:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-32:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkProcess-10:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-11:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Verify conda environment\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're in the nerfstudio environment\n",
    "if 'nerfstudio' not in sys.executable:\n",
    "    print(\"\\n⚠️  WARNING: Not running in nerfstudio conda environment!\")\n",
    "    print(\"Please activate with: conda activate nerfstudio\")\n",
    "else:\n",
    "    print(\"\\n✓ Running in nerfstudio environment\")\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "# Import internal nerfstudio utilities\n",
    "from nerfstudio.process_data import vggt_utils\n",
    "from nerfstudio.process_data import colmap_utils\n",
    "from nerfstudio.process_data.process_data_utils import (\n",
    "    convert_video_to_images,\n",
    "    CameraModel,\n",
    ")\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7f58f",
   "metadata": {},
   "source": [
    "## Run preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecf48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "✓ Valid video file with 2388 frames\n",
      "transforms.json already exists at /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/transforms.json\n",
      "To rerun preprocessing, set overwrite=True\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Use Splatter wrapper for training\n",
    "from collab_splats.wrapper import Splatter, SplatterConfig\n",
    "\n",
    "# Configuration\n",
    "config_dir = Path(\"/workspace/collab-splats/docs/splats/configs/\")\n",
    "# dataset_name = \"bicycle\"\n",
    "dataset_name = \"birds_date-02062024_video-C0043\"\n",
    "\n",
    "# Create splatter from config\n",
    "splatter = Splatter.from_config_file(\n",
    "    dataset=dataset_name,\n",
    "    config_dir=config_dir,\n",
    "    # overrides={\n",
    "    #     \"frame_proportion\": 0.1,\n",
    "    # }\n",
    ")\n",
    "\n",
    "splatter.preprocess()\n",
    "\n",
    "# splatter.preprocess(\n",
    "#     sfm_tool='vggt',\n",
    "#     overwrite=False, \n",
    "#     kwargs={\n",
    "#         \"refine-vggt\": \"\",\n",
    "#         \"camera-type\": \"pinhole\",\n",
    "#         \"verbose\": \"\",\n",
    "#         \"num_downscales\": 0,\n",
    "#         \"vggt_conf_threshold\": 35.0,\n",
    "#         \"save_vggt_checkpoint\": \"\",\n",
    "#         # \"skip_image_processing\": \"\",\n",
    "#     }  # Enable bundle adjustment\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the aligned poses in case we want them for visualization --> by default they are aligned to the splat\n",
    "aligned_cameras = splatter.load_aligned_cameras(align_mesh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca83020",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Visualize the Sparse Point Cloud\n",
    "import pyvista as pv\n",
    "from collab_splats.utils.visualization import (\n",
    "    CAMERA_KWARGS,\n",
    "    MESH_KWARGS,\n",
    "    VIZ_KWARGS,\n",
    "    visualize_splat,\n",
    ")\n",
    "\n",
    "# Load the sparse point cloud\n",
    "pcd_fn = splatter.config[\"preproc_data_path\"] / \"sparse_pc.ply\"\n",
    "splat = pv.PolyData(str(pcd_fn))\n",
    "\n",
    "pcd_kwargs = MESH_KWARGS.copy()\n",
    "pcd_kwargs.update(\n",
    "    {\n",
    "        \"point_size\": 2,\n",
    "        \"render_points_as_spheres\": True,\n",
    "        \"ambient\": 0.3,\n",
    "        \"diffuse\": 0.8,\n",
    "        \"specular\": 0.1,\n",
    "    }\n",
    ")\n",
    "\n",
    "camera_kwargs = CAMERA_KWARGS.copy()\n",
    "camera_kwargs.update(\n",
    "    {\n",
    "        \"n_poses\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "plotter = visualize_splat(\n",
    "    mesh=splat,\n",
    "    mesh_kwargs=pcd_kwargs,\n",
    "    camera_kwargs=camera_kwargs,\n",
    "    viz_kwargs=VIZ_KWARGS,\n",
    "    aligned_cameras=aligned_cameras,\n",
    ")\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0977c",
   "metadata": {},
   "source": [
    "## Run VGGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61e9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nerfstudio.process_data import vggt_utils\n",
    "\n",
    "image_dir = splatter.config[\"preproc_data_path\"] / \"images\"\n",
    "\n",
    "vggt_output_dir = splatter.config[\"preproc_data_path\"] / \"vggt\"\n",
    "\n",
    "colmap_dir = splatter.config[\"preproc_data_path\"] / \"colmap\"\n",
    "vggt_ckpt_path = colmap_dir / \"vggt_checkpoint.pt\"\n",
    "\n",
    "vggt_data_loaded =  torch.load(vggt_ckpt_path)\n",
    "\n",
    "# Extract data from inference results\n",
    "images = vggt_data_loaded[\"images\"]\n",
    "extrinsic = vggt_data_loaded[\"extrinsic\"]\n",
    "intrinsic = vggt_data_loaded[\"instrinsics\"] # Upsampled to native resolution\n",
    "intrinsic_downsampled = vggt_data_loaded[\"instrinsics_downsampled\"] # Downsampled to VGGT resolution\n",
    "depth_map = vggt_data_loaded[\"depth\"]\n",
    "depth_conf = vggt_data_loaded[\"depth_conf\"]\n",
    "image_paths = vggt_data_loaded[\"image_paths\"]\n",
    "\n",
    "image_basenames = [image_path.name for image_path in image_paths]\n",
    "\n",
    "matches_fn = splatter.config[\"preproc_data_path\"] / \"colmap\" / \"matches.pt\"\n",
    "matches = torch.load(matches_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe42c99a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "corrcoef() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: corrcoef() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "torch.corrcoef(depth_map[0], depth_map[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f7570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pose Optimization...: 100%|██████████| 300/300 [06:58<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "extrinsic_refined, intrinsic_refined = vggt_utils.pose_optimization(\n",
    "    match_outputs=matches,\n",
    "    extrinsic=extrinsic,\n",
    "    intrinsic=intrinsic_downsampled,\n",
    "    images=images,\n",
    "    depth_conf=depth_conf,\n",
    "    depth_maps=depth_map,\n",
    "    base_image_path_list=image_basenames,\n",
    "    target_scene_dir=colmap_dir,\n",
    "    shared_intrinsics=True,\n",
    "    lambda_depth=0.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3882006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and prepare 3D points in Facebook's format (points3d, points_xyf, points_rgb)\n",
    "# Note: Facebook uses conf_threshold as a value (e.g., 5.0), not percentile\n",
    "# For compatibility, we convert percentile to value if > 1\n",
    "# Interpret as value directly\n",
    "conf_threshold_value = 1.0\n",
    "\n",
    "# Unproject depth map to point map\n",
    "points3d = vggt_utils.unproject_depth_map_to_point_map(\n",
    "    depth_map, \n",
    "    extrinsic_refined, \n",
    "    intrinsic_refined\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abf6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points for pycolmap reconstruction using VGGTX logic\n",
    "points3d, points_xyf, points_rgb = vggt_utils._filter_and_prepare_points_for_pycolmap(\n",
    "    points3d=points3d,\n",
    "    depth_map=depth_map,\n",
    "    depth_conf=depth_conf,\n",
    "    images=images,\n",
    "    image_paths=image_paths,\n",
    "    conf_thres_value=conf_threshold_value,\n",
    "    use_global_alignment=True,\n",
    "    match_outputs=matches,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a39c515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Calling batch_np_matrix_to_pycolmap_wo_track with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500000</span> 3D points\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Calling batch_np_matrix_to_pycolmap_wo_track with \u001b[1;36m500000\u001b[0m 3D points\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - points_xyf shape: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - points_xyf shape: \u001b[1m(\u001b[0m\u001b[1;36m500000\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Camera type: PINHOLE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Camera type: PINHOLE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Created reconstruction:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Created reconstruction:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Cameras: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Cameras: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Images: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">597</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Images: \u001b[1;36m597\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Points3D: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Points3D: \u001b[1;36m500000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Grab image size from depth map (N, H, W) --> make as width and height\n",
    "image_size = np.array([depth_map.shape[2], depth_map.shape[1]])\n",
    "\n",
    "reconstruction = vggt_utils._build_pycolmap_reconstruction_without_tracks(\n",
    "    points3d=points3d,\n",
    "    points_xyf=points_xyf,\n",
    "    points_rgb=points_rgb,\n",
    "    extrinsic=extrinsic_refined,\n",
    "    intrinsic=intrinsic_refined,\n",
    "    image_size=image_size,\n",
    "    image_paths=image_paths,\n",
    "    shared_camera=True,\n",
    "    camera_type=\"PINHOLE\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e99973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 518)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8528f9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Rescaling reconstruction from WxH (294x518) to original dimensions</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mRescaling reconstruction from WxH \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m294x518\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m to original dimensions\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Original image sizes <span style=\"font-weight: bold\">(</span>WxH<span style=\"font-weight: bold\">)</span>: 108<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1920</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Original image sizes \u001b[1m(\u001b[0mWxH\u001b[1m)\u001b[0m: 108\u001b[1;36m0x1920\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Rescaled reconstruction to original dimensions</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Rescaled reconstruction to original dimensions\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Step 2: Rescale reconstruction to original dimensions\n",
    "reconstruction_resolution = (image_size[0], image_size[1]) # Reverse as it expects width and height\n",
    "\n",
    "original_image_sizes = np.repeat([[0, 0, 294, 518, 1080, 1920]], len(image_paths), axis=0)\n",
    "\n",
    "reconstruction = vggt_utils._rescale_reconstruction_to_original_dimensions(\n",
    "    reconstruction=reconstruction,\n",
    "    image_paths=image_paths,\n",
    "    original_image_sizes=original_image_sizes,\n",
    "    image_size=reconstruction_resolution,\n",
    "    shift_point2d_to_original_res=True,\n",
    "    shared_camera=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89c591a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[yellow]Image 233: pose jump 0.188 > 0.170\n",
      "[yellow]Image 370: pose jump 0.195 > 0.170\n",
      "[yellow]Image 371: pose jump 0.201 > 0.170\n",
      "[yellow]Image 374: pose jump 0.244 > 0.170\n",
      "[yellow]Image 375: pose jump 0.296 > 0.170\n",
      "[yellow]Image 376: pose jump 0.334 > 0.170\n",
      "[yellow]Image 377: pose jump 0.259 > 0.170\n",
      "[yellow]Image 417: pose jump 0.186 > 0.170\n",
      "[yellow]Image 418: pose jump 0.188 > 0.170\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "filtered_reconstruction = copy.deepcopy(reconstruction)\n",
    "removed_image_ids = []\n",
    "removal_reasons = {\n",
    "    'few_matches': [],\n",
    "    'few_points': [],\n",
    "    'low_depth_conf': [],\n",
    "    'high_reproj_error': [],\n",
    "    'pose_discontinuity': [],\n",
    "    'rotation_discontinuity': [],\n",
    "}\n",
    "\n",
    "num_images = len(reconstruction.images)\n",
    "\n",
    "min_points_3d: int = 100\n",
    "min_matches: int = 200\n",
    "min_avg_depth_conf: float = 0.3\n",
    "reprojection_error_percentile: float = 95  # Filter top 5% worst\n",
    "pose_distance_std_factor: float = 3.0 # Outlier if >3 std from mean\n",
    "rotation_angle_threshold: float = 45.0  # Degrees change between neighbors\n",
    "\n",
    "# ========================================================================\n",
    "# METRIC 5: Pose Discontinuity Detection (NEW - MOST IMPORTANT)\n",
    "# Detects cameras with positions far from their temporal neighbors\n",
    "# ========================================================================\n",
    "if extrinsic is not None:\n",
    "    camera_positions = extrinsic[:, :3, 3]  # Extract translation vectors\n",
    "    \n",
    "    # Compute distances to temporal neighbors\n",
    "    position_distances = []\n",
    "    for i in range(1, len(camera_positions) - 1):\n",
    "        img_id = i + 1  # COLMAP uses 1-indexed\n",
    "        \n",
    "        if img_id in removed_image_ids:\n",
    "            continue\n",
    "        \n",
    "        # Distance to previous and next frame\n",
    "        dist_prev = np.linalg.norm(camera_positions[i] - camera_positions[i-1])\n",
    "        dist_next = np.linalg.norm(camera_positions[i] - camera_positions[i+1])\n",
    "        avg_dist = (dist_prev + dist_next) / 2\n",
    "        \n",
    "        position_distances.append(avg_dist)\n",
    "    \n",
    "    if position_distances:\n",
    "        mean_dist = np.mean(position_distances)\n",
    "        std_dist = np.std(position_distances)\n",
    "        threshold_dist = mean_dist + pose_distance_std_factor * std_dist\n",
    "        \n",
    "        for i in range(1, len(camera_positions) - 1):\n",
    "            img_id = i + 1\n",
    "            \n",
    "            if img_id in removed_image_ids:\n",
    "                continue\n",
    "            \n",
    "            dist_prev = np.linalg.norm(camera_positions[i] - camera_positions[i-1])\n",
    "            dist_next = np.linalg.norm(camera_positions[i] - camera_positions[i+1])\n",
    "            avg_dist = (dist_prev + dist_next) / 2\n",
    "            \n",
    "            if avg_dist > threshold_dist:\n",
    "                removed_image_ids.append(img_id)\n",
    "                removal_reasons['pose_discontinuity'].append(img_id)\n",
    "                # if verbose:\n",
    "                print(f\"[yellow]Image {img_id}: pose jump {avg_dist:.3f} > {threshold_dist:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3263673d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">544</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">163</span><span style=\"color: #808000; text-decoration-color: #808000\"> 3D points &lt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m544\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m163\u001b[0m\u001b[33m 3D points < \u001b[0m\u001b[1;33m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">543</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">184</span><span style=\"color: #808000; text-decoration-color: #808000\"> 3D points &lt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m543\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m184\u001b[0m\u001b[33m 3D points < \u001b[0m\u001b[1;33m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">373</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">163</span><span style=\"color: #808000; text-decoration-color: #808000\"> 3D points &lt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m373\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m163\u001b[0m\u001b[33m 3D points < \u001b[0m\u001b[1;33m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">374</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">79</span><span style=\"color: #808000; text-decoration-color: #808000\"> 3D points &lt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m374\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m79\u001b[0m\u001b[33m 3D points < \u001b[0m\u001b[1;33m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">375</span><span style=\"color: #808000; text-decoration-color: #808000\">: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">183</span><span style=\"color: #808000; text-decoration-color: #808000\"> 3D points &lt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">200</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m375\u001b[0m\u001b[33m: \u001b[0m\u001b[1;33m183\u001b[0m\u001b[33m 3D points < \u001b[0m\u001b[1;33m200\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">7</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.384</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m7\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.384\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">363</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.366</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m363\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.366\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">364</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.449</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m364\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.449\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">365</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.434</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m365\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.434\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">366</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.613</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m366\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.613\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">367</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.585</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m367\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.585\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">368</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.410</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m368\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.410\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">369</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.427</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m369\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.427\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">370</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.424</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m370\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.424\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">371</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.414</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m371\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.414\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">372</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.426</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m372\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.426\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">376</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.578</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m376\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.578\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">377</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.505</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m377\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.505\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">378</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.389</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m378\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.389\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">379</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.299</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m379\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.299\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">384</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.294</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m384\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.294\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">385</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.313</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m385\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.313\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">386</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.305</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m386\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.305\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">417</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.299</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m417\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.299\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">418</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.312</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m418\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.312\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Image </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">419</span><span style=\"color: #808000; text-decoration-color: #808000\">: pose MAD </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.336</span><span style=\"color: #808000; text-decoration-color: #808000\"> &gt; </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.270</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mImage \u001b[0m\u001b[1;33m419\u001b[0m\u001b[33m: pose MAD \u001b[0m\u001b[1;33m0.336\u001b[0m\u001b[33m > \u001b[0m\u001b[1;33m0.270\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Outlier Detection Summary:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mOutlier Detection Summary:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total images: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">597</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Total images: \u001b[1;36m597\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Removed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Removed: \u001b[1;36m26\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Remaining: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Remaining: \u001b[1;36m571\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - few_points: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> images\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - few_points: \u001b[1;36m5\u001b[0m images\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - pose_discontinuity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> images\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - pose_discontinuity: \u001b[1;36m21\u001b[0m images\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Removed 3D points: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Removed 3D points: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruction_filtered, removed_image_ids, removal_reasons = _filter_outlier_cameras_enhanced(\n",
    "    reconstruction=reconstruction,\n",
    "    match_outputs=matches,\n",
    "    depth_conf=depth_conf,\n",
    "    extrinsic=extrinsic_refined,\n",
    "    images=images,\n",
    "    min_points_3d=200,\n",
    "    min_matches=2000,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7eaa603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 518, 294, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81dcf3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from nerfstudio.utils.rich_utils import CONSOLE\n",
    "\n",
    "def _filter_outlier_cameras_enhanced(\n",
    "    reconstruction: Any,\n",
    "    match_outputs: Optional[Dict[str, Any]] = None,\n",
    "    depth_conf: Optional[np.ndarray] = None,\n",
    "    extrinsic: Optional[np.ndarray] = None,\n",
    "    images: Optional[torch.Tensor] = None,\n",
    "    min_points_3d: int = 100,\n",
    "    min_matches: int = 200,\n",
    "    min_avg_depth_conf: float = 0.3,\n",
    "    reprojection_error_percentile: float = 95,\n",
    "    pose_distance_std_factor: float = 2.0,\n",
    "    rotation_angle_threshold: float = 30.0,\n",
    "    verbose: bool = False,\n",
    ") -> Tuple[Any, List[int], Dict[str, List[int]]]:\n",
    "    \"\"\"\n",
    "    Multi-metric outlier detection for camera poses.\n",
    "    Returns:\n",
    "        filtered reconstruction, removed image IDs, removal reasons\n",
    "    \"\"\"\n",
    "    filtered_reconstruction = copy.deepcopy(reconstruction)\n",
    "    removed_image_ids = []\n",
    "    removal_reasons = {\n",
    "        'few_matches': [],\n",
    "        'few_points': [],\n",
    "        'low_depth_conf': [],\n",
    "        'high_reproj_error': [],\n",
    "        'pose_discontinuity': [],\n",
    "        'rotation_discontinuity': [],\n",
    "    }\n",
    "    \n",
    "    num_images = len(reconstruction.images)\n",
    "\n",
    "    # # ----------------------------\n",
    "    # # METRIC 1: Feature Match Count\n",
    "    # # ----------------------------\n",
    "    # if match_outputs is not None:\n",
    "    #     indexes_i = match_outputs[\"indexes_i_expanded\"]\n",
    "    #     indexes_j = match_outputs[\"indexes_j_expanded\"]\n",
    "\n",
    "    #     for img_id in reconstruction.images:\n",
    "    #         mask = (indexes_i == img_id - 1) | (indexes_j == img_id - 1)\n",
    "    #         match_count = mask.sum()\n",
    "    #         print (match_count)\n",
    "    #         if match_count < min_matches:\n",
    "    #             removed_image_ids.append(img_id)\n",
    "    #             removal_reasons['few_matches'].append(img_id)\n",
    "    #             if verbose:\n",
    "    #                 CONSOLE.print(f\"[yellow]Image {img_id}: {match_count} matches < {min_matches}\")\n",
    "    # sys.exit(0)\n",
    "    # ----------------------------\n",
    "    # METRIC 2: Number of 3D Points\n",
    "    # ----------------------------\n",
    "    for img_id in reconstruction.images:\n",
    "        if img_id in removed_image_ids:\n",
    "            continue\n",
    "        point_count = sum(1 for p in reconstruction.images[img_id].points2D if p.point3D_id != -1)\n",
    "        if point_count < min_points_3d:\n",
    "            removed_image_ids.append(img_id)\n",
    "            removal_reasons['few_points'].append(img_id)\n",
    "            if verbose:\n",
    "                CONSOLE.print(f\"[yellow]Image {img_id}: {point_count} 3D points < {min_points_3d}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # METRIC 3: Average Depth Confidence\n",
    "    # ----------------------------\n",
    "    if depth_conf is not None:\n",
    "        for img_id in reconstruction.images:\n",
    "            if img_id in removed_image_ids:\n",
    "                continue\n",
    "            avg_conf = depth_conf[img_id - 1].mean()\n",
    "            if avg_conf < min_avg_depth_conf:\n",
    "                removed_image_ids.append(img_id)\n",
    "                removal_reasons['low_depth_conf'].append(img_id)\n",
    "                if verbose:\n",
    "                    CONSOLE.print(f\"[yellow]Image {img_id}: depth conf {avg_conf:.3f} < {min_avg_depth_conf}\")\n",
    "\n",
    "    # # ----------------------------\n",
    "    # # METRIC 4: Reprojection Error\n",
    "    # # ----------------------------\n",
    "    # reprojection_errors = {}\n",
    "    # for img_id, pyimage in reconstruction.images.items():\n",
    "    #     if img_id in removed_image_ids:\n",
    "    #         continue\n",
    "    #     pycamera = reconstruction.cameras[pyimage.camera_id]\n",
    "\n",
    "    #     errors = []\n",
    "    #     # Obtain world->camera transformation\n",
    "    #     if extrinsic is not None:\n",
    "    #         W2C = extrinsic[img_id - 1]\n",
    "    #     else:\n",
    "    #         # fallback: pyimage.pose() returns world->camera matrix\n",
    "    #         W2C = pyimage.pose()\n",
    "\n",
    "    #     for point2D in pyimage.points2D:\n",
    "    #         if (point3D_id := point2D.point3D_id) != -1:\n",
    "    #             point3D = reconstruction.points3D[point3D_id]\n",
    "    #             point_world_h = np.append(point3D.xyz, 1)\n",
    "    #             point_cam = W2C @ point_world_h\n",
    "    #             projected = pycamera.project(point_cam[:3])\n",
    "    #             error = np.linalg.norm(projected - point2D.xy)\n",
    "    #             errors.append(error)\n",
    "    #     if errors:\n",
    "    #         reprojection_errors[img_id] = np.mean(errors)\n",
    "\n",
    "    # if reprojection_errors:\n",
    "    #     threshold = np.percentile(list(reprojection_errors.values()), reprojection_error_percentile)\n",
    "    #     for img_id, error in reprojection_errors.items():\n",
    "    #         if error > threshold and img_id not in removed_image_ids:\n",
    "    #             removed_image_ids.append(img_id)\n",
    "    #             removal_reasons['high_reproj_error'].append(img_id)\n",
    "    #             if verbose:\n",
    "    #                 CONSOLE.print(f\"[yellow]Image {img_id}: reproj error {error:.2f} > {threshold:.2f}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # METRIC 5: Pose Discontinuity (MAD from neighbors)\n",
    "    # ----------------------------\n",
    "    if extrinsic is not None:\n",
    "        camera_positions = extrinsic[:, :3, 3]\n",
    "        n_neighbors = 3  # number of neighbors on each side\n",
    "        num_cameras = len(camera_positions)\n",
    "\n",
    "        for i in range(num_cameras):\n",
    "            img_id = i + 1\n",
    "            if img_id in removed_image_ids:\n",
    "                continue\n",
    "\n",
    "            # Select neighbor indices\n",
    "            neighbor_indices = [j for j in range(max(0, i - n_neighbors), min(num_cameras, i + n_neighbors + 1))\n",
    "                                if j != i]\n",
    "\n",
    "            # Compute mean absolute deviation from neighbors\n",
    "            neighbor_positions = camera_positions[neighbor_indices]\n",
    "            mad = np.mean(np.linalg.norm(neighbor_positions - camera_positions[i], axis=1))\n",
    "\n",
    "            # Compute global MAD threshold\n",
    "            all_mads = []\n",
    "            for k in range(num_cameras):\n",
    "                neighbor_idx_k = [j for j in range(max(0, k - n_neighbors), min(num_cameras, k + n_neighbors + 1))\n",
    "                                if j != k]\n",
    "                neighbor_pos_k = camera_positions[neighbor_idx_k]\n",
    "                all_mads.append(np.mean(np.linalg.norm(neighbor_pos_k - camera_positions[k], axis=1)))\n",
    "            threshold_mad = np.mean(all_mads) + pose_distance_std_factor * np.std(all_mads)\n",
    "\n",
    "            if mad > threshold_mad:\n",
    "                removed_image_ids.append(img_id)\n",
    "                removal_reasons['pose_discontinuity'].append(img_id)\n",
    "                if verbose:\n",
    "                    CONSOLE.print(f\"[yellow]Image {img_id}: pose MAD {mad:.3f} > {threshold_mad:.3f}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # METRIC 6: Rotation Discontinuity\n",
    "    # ----------------------------\n",
    "    if extrinsic is not None:\n",
    "        for i in range(1, len(extrinsic) - 1):\n",
    "            img_id = i + 1\n",
    "            if img_id in removed_image_ids:\n",
    "                continue\n",
    "            R_curr = extrinsic[i, :3, :3]\n",
    "            R_prev = extrinsic[i-1, :3, :3]\n",
    "            R_next = extrinsic[i+1, :3, :3]\n",
    "\n",
    "            # Relative rotations\n",
    "            R_rel_prev = R_prev.T @ R_curr\n",
    "            R_rel_next = R_curr.T @ R_next\n",
    "\n",
    "            # Rotation angle (degrees)\n",
    "            angle_prev = np.degrees(np.arccos(np.clip((np.trace(R_rel_prev) - 1)/2, -1, 1)))\n",
    "            angle_next = np.degrees(np.arccos(np.clip((np.trace(R_rel_next) - 1)/2, -1, 1)))\n",
    "\n",
    "            if angle_prev > rotation_angle_threshold or angle_next > rotation_angle_threshold:\n",
    "                removed_image_ids.append(img_id)\n",
    "                removal_reasons['rotation_discontinuity'].append(img_id)\n",
    "                if verbose:\n",
    "                    max_angle = max(angle_prev, angle_next)\n",
    "                    CONSOLE.print(f\"[yellow]Image {img_id}: rotation jump {max_angle:.1f}° > {rotation_angle_threshold}°\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Final cleanup: remove images and orphaned points\n",
    "    # ----------------------------\n",
    "    removed_image_ids = list(set(removed_image_ids))\n",
    "    for img_id in removed_image_ids:\n",
    "        filtered_reconstruction.deregister_image(img_id)\n",
    "        if img_id in filtered_reconstruction.images:\n",
    "            del filtered_reconstruction.images[img_id]\n",
    "\n",
    "    points_to_remove = []\n",
    "    for point3D_id, point3D in filtered_reconstruction.points3D.items():\n",
    "        track = point3D.track\n",
    "        track.elements = [e for e in track.elements if e.image_id not in removed_image_ids]\n",
    "        if not track.elements:\n",
    "            points_to_remove.append(point3D_id)\n",
    "\n",
    "    for point3D_id in points_to_remove:\n",
    "        del filtered_reconstruction.points3D[point3D_id]\n",
    "\n",
    "    # ----------------------------\n",
    "    # Verbose summary\n",
    "    # ----------------------------\n",
    "    if verbose:\n",
    "        CONSOLE.print(f\"\\n[bold cyan]Outlier Detection Summary:\")\n",
    "        CONSOLE.print(f\"  Total images: {num_images}\")\n",
    "        CONSOLE.print(f\"  Removed: {len(removed_image_ids)}\")\n",
    "        CONSOLE.print(f\"  Remaining: {len(filtered_reconstruction.images)}\")\n",
    "        for reason, ids in removal_reasons.items():\n",
    "            if ids:\n",
    "                CONSOLE.print(f\"  - {reason}: {len(ids)} images\")\n",
    "        CONSOLE.print(f\"  Removed 3D points: {len(points_to_remove)}\")\n",
    "\n",
    "    return filtered_reconstruction, removed_image_ids, removal_reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "974d9a0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_dist \u001b[38;5;241m+\u001b[39m \u001b[43mpose_distance_std_factor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd_dist\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "mean_dist + pose_distance_std_factor * std_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Visualize the Sparse Point Cloud\n",
    "import pyvista as pv\n",
    "from collab_splats.utils.visualization import (\n",
    "    CAMERA_KWARGS,\n",
    "    MESH_KWARGS,\n",
    "    VIZ_KWARGS,\n",
    "    visualize_splat,\n",
    ")\n",
    "\n",
    "# Load the sparse point cloud\n",
    "# pcd_fn = splatter.config[\"preproc_data_path\"] / \"sparse_pc.ply\"\n",
    "splat = pv.PolyData(points3d)\n",
    "splat.point_data[\"RGB\"] = points_rgb\n",
    "\n",
    "pcd_kwargs = MESH_KWARGS.copy()\n",
    "pcd_kwargs.update(\n",
    "    {\n",
    "        \"point_size\": 2,\n",
    "        \"render_points_as_spheres\": True,\n",
    "        \"ambient\": 0.3,\n",
    "        \"diffuse\": 0.8,\n",
    "        \"specular\": 0.1,\n",
    "    }\n",
    ")\n",
    "\n",
    "camera_kwargs = CAMERA_KWARGS.copy()\n",
    "camera_kwargs.update(\n",
    "    {\n",
    "        \"n_poses\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "plotter = visualize_splat(\n",
    "    mesh=splat,\n",
    "    mesh_kwargs=pcd_kwargs,\n",
    "    camera_kwargs=camera_kwargs,\n",
    "    viz_kwargs=VIZ_KWARGS,\n",
    "    aligned_cameras=extrinsic_refined,\n",
    ")\n",
    "\n",
    "plotter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
