{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Taichi] version 1.7.4, llvm 15.0.4, commit b4b956fd, linux, python 3.10.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 09/20/25 16:53:11.619 86955] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory bank loaded from /workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/grouping/memory_bank.pkl with 548 masks\n"
     ]
    }
   ],
   "source": [
    "from collab_splats.utils.grouping import GroupingClassifier, GroupingConfig\n",
    "\n",
    "# Path to the config for a trained model\n",
    "load_config = '/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-25_074037/config.yml'\n",
    "load_config = Path(load_config)\n",
    "\n",
    "grouping_config = GroupingConfig(segmentation_backend='mobilesamv2', segmentation_strategy='object', front_percentage=0.2, iou_threshold=0.1, num_patches=32)\n",
    "grouping_classifier = GroupingClassifier(load_config=load_config, config=grouping_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NeRF pipeline and model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:53:17] </span>Auto image downscale factor of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                 <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nerfstudio_dataparser.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:53:17]\u001b[0m\u001b[2;36m \u001b[0mAuto image downscale factor of \u001b[1;36m2\u001b[0m                                                 \u001b]8;id=738226;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=677277;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\\u001b[2m484\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:54:20] </span>use color only optimization with sigmoid activation                                         <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">splatfacto.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:54:20]\u001b[0m\u001b[2;36m \u001b[0muse color only optimization with sigmoid activation                                         \u001b]8;id=857079;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\u001b\\\u001b[2msplatfacto.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=748346;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-25_074037/nerfstudio_models/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">step-00002</span>\n",
       "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">9999.ckpt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "\u001b[35m/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-25_074037/nerfstudio_models/\u001b[0m\u001b[95mstep-00002\u001b[0m\n",
       "\u001b[95m9999.ckpt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segmentation module...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /workspace/models/hub/RogerQi_MobileSAMV2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_load_scucess\n",
      "Loading train ordered data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating masks [train]: 100%|██████████| 441/441 [00:00<00:00, 3497.89it/s]\n"
     ]
    }
   ],
   "source": [
    "grouping_classifier.create_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train ordered data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  49%|████▉     | 217/441 [00:03<00:04, 52.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No objects found in frame_00232.png\n",
      "No objects found in frame_00235.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 441/441 [00:08<00:00, 52.52it/s]\n"
     ]
    }
   ],
   "source": [
    "grouping_classifier.associate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera, batch = grouping_classifier.pipeline.datamanager.next_train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_classifier.setup() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = grouping_classifier.model.get_outputs(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.55 GiB. GPU 0 has a total capacty of 23.55 GiB of which 2.67 GiB is free. Process 1089783 has 20.87 GiB memory in use. Of the allocated memory 20.44 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrouping_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_identities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/collab-splats/collab_splats/utils/grouping.py:675\u001b[0m, in \u001b[0;36mGroupingClassifier._render_identities\u001b[0;34m(self, camera)\u001b[0m\n\u001b[1;32m    666\u001b[0m fused_features \u001b[38;5;241m=\u001b[39m create_fused_features(\n\u001b[1;32m    667\u001b[0m     means\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmeans,\n\u001b[1;32m    668\u001b[0m     colors\u001b[38;5;241m=\u001b[39mcolors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    671\u001b[0m     sh_degree_to_use\u001b[38;5;241m=\u001b[39msh_degree_to_use,\n\u001b[1;32m    672\u001b[0m )\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# Rasterize the image using the fused features\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m render, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscales\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfused_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43msh_degree_to_use\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msh_degree_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m preds \u001b[38;5;241m=\u001b[39m render[:, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39midentity_dim]\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\n",
      "File \u001b[0;32m/workspace/collab-splats/collab_splats/models/rade_gs_model.py:403\u001b[0m, in \u001b[0;36mRadegsModel._render\u001b[0;34m(self, means, quats, scales, opacities, colors, render_mode, sh_degree_to_use, camera_params, visible_mask)\u001b[0m\n\u001b[1;32m    393\u001b[0m     colors \u001b[38;5;241m=\u001b[39m colors\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# Items are:\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# - render_colors: [N, 3]\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# - render_alphas: [N, 1]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# - expected_normals: [N, 1]\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# - info: dict\u001b[39;00m\n\u001b[1;32m    402\u001b[0m render, alpha, expected_depths, median_depths, expected_normals, meta \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 403\u001b[0m     \u001b[43mrasterization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N, 3]\u001b[39;49;00m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N, 4]\u001b[39;49;00m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscales\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N, 3]\u001b[39;49;00m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N,]\u001b[39;49;00m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mviewmats\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, 4, 4]\u001b[39;49;00m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, 3, 3]\u001b[39;49;00m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_width\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_height\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43msh_degree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msh_degree_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsgrad\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDefaultStrategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrasterize_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterize_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# # set some threshold to disregard small gaussians for faster rendering.\u001b[39;49;00m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# radius_clip=3.0,\u001b[39;49;00m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Output depth and normal maps\u001b[39;49;00m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_depth_normal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m render, alpha, expected_depths, median_depths, expected_normals, meta\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/rendering.py:505\u001b[0m, in \u001b[0;36mrasterization\u001b[0;34m(means, quats, scales, opacities, colors, viewmats, Ks, width, height, near_plane, far_plane, radius_clip, eps2d, sh_degree, packed, tile_size, backgrounds, render_mode, sparse_grad, absgrad, rasterize_mode, channel_chunk, distributed, camera_model, covars, return_depth_normal)\u001b[0m\n\u001b[1;32m    503\u001b[0m tile_width \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(width \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(tile_size))\n\u001b[1;32m    504\u001b[0m tile_height \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(height \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(tile_size))\n\u001b[0;32m--> 505\u001b[0m tiles_per_gauss, isect_ids, flatten_ids \u001b[38;5;241m=\u001b[39m \u001b[43misect_tiles\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_cameras\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgaussian_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgaussian_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# print(\"rank\", world_rank, \"Before isect_offset_encode\")\u001b[39;00m\n\u001b[1;32m    518\u001b[0m isect_offsets \u001b[38;5;241m=\u001b[39m isect_offset_encode(isect_ids, C, tile_width, tile_height)\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/cuda/_wrapper.py:414\u001b[0m, in \u001b[0;36misect_tiles\u001b[0;34m(means2d, radii, depths, tile_size, tile_width, tile_height, sort, packed, n_cameras, camera_ids, gaussian_ids)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m radii\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (C, N, \u001b[38;5;241m2\u001b[39m), radii\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m depths\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (C, N), depths\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 414\u001b[0m tiles_per_gauss, isect_ids, flatten_ids \u001b[38;5;241m=\u001b[39m \u001b[43m_make_lazy_cuda_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintersect_tile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradii\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgaussian_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tiles_per_gauss, isect_ids, flatten_ids\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/cuda/_wrapper.py:14\u001b[0m, in \u001b[0;36m_make_lazy_cuda_func.<locals>.call_cuda\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_cuda\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.55 GiB. GPU 0 has a total capacty of 23.55 GiB of which 2.67 GiB is free. Process 1089783 has 20.87 GiB memory in use. Of the allocated memory 20.44 GiB is allocated by PyTorch, and 40.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "grouping_classifier._render_identities(camera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
