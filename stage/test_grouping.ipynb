{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Taichi] version 1.7.4, llvm 15.0.4, commit b4b956fd, linux, python 3.10.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 09/22/25 21:30:03.398 51632] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory bank loaded from /workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/grouping/memory_bank.pkl with 729 masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-22:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-3:\n",
      "Traceback (most recent call last):\n",
      "Process ForkProcess-30:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-25:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkProcess-15:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkProcess-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/nerfstudio/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from collab_splats.utils.grouping import GroupingClassifier, GroupingConfig\n",
    "\n",
    "# Path to the config for a trained model\n",
    "load_config = '/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-25_074037/config.yml'\n",
    "load_config = Path(load_config)\n",
    "\n",
    "grouping_config = GroupingConfig(segmentation_backend='mobilesamv2', segmentation_strategy='object', front_percentage=0.2, iou_threshold=0.1, num_patches=32)\n",
    "grouping_classifier = GroupingClassifier(load_config=load_config, config=grouping_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train ordered data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating masks [train]: 100%|██████████| 441/441 [00:02<00:00, 165.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No object detected.\n",
      "No objects found in frame_00232.png, creating empty mask\n",
      "No object detected.\n",
      "No objects found in frame_00235.png, creating empty mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grouping_classifier.create_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train ordered data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  52%|█████▏    | 228/441 [00:02<00:01, 124.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No objects found in frame_00232.png\n",
      "No objects found in frame_00235.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 441/441 [00:04<00:00, 93.13it/s] \n"
     ]
    }
   ],
   "source": [
    "grouping_classifier.associate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try pytorch lightning datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collab_splats.utils.grouping import GroupingDataModule \n",
    "\n",
    "datamodule = GroupingDataModule(\n",
    "    datamanager=grouping_classifier.pipeline.datamanager,\n",
    "    mask_dir=grouping_classifier.associated_mask_dir,\n",
    "    device=\"cuda\",\n",
    "    train_num_workers=0,\n",
    "    val_num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup classifier for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_classifier.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train identity embeddings to lift objects from 2d to 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | pipeline   | VanillaPipeline     | 465 M  | eval \n",
      "1 | model      | RadegsFeaturesModel | 465 M  | eval \n",
      "2 | params     | ParameterDict       | 16.8 M | train\n",
      "3 | classifier | Conv2d              | 10.2 K | train\n",
      "4 | loss_fn    | CrossEntropyLoss    | 0      | train\n",
      "-----------------------------------------------------------\n",
      "16.8 M    Trainable params\n",
      "465 M     Non-trainable params\n",
      "482 M     Total params\n",
      "1,929.245 Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "389       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01ad728379f46a3a54311d0470ada3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10000` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GroupingClassifier(\n",
       "   (pipeline): VanillaPipeline(\n",
       "     (_model): RadegsFeaturesModel(\n",
       "       (gauss_params): ParameterDict(\n",
       "           (features_dc): Parameter containing: [torch.FloatTensor of size 1295257x3]\n",
       "           (features_rest): Parameter containing: [torch.FloatTensor of size 1295257x0x3]\n",
       "           (means): Parameter containing: [torch.FloatTensor of size 1295257x3]\n",
       "           (opacities): Parameter containing: [torch.FloatTensor of size 1295257x1]\n",
       "           (quats): Parameter containing: [torch.FloatTensor of size 1295257x4]\n",
       "           (scales): Parameter containing: [torch.FloatTensor of size 1295257x3]\n",
       "           (distill_features): Parameter containing: [torch.FloatTensor of size 1295257x13]\n",
       "       )\n",
       "       (camera_optimizer): CameraOptimizer()\n",
       "       (psnr): PeakSignalNoiseRatio()\n",
       "       (ssim): SSIM()\n",
       "       (lpips): LearnedPerceptualImagePatchSimilarity(\n",
       "         (net): _NoTrainLpips(\n",
       "           (scaling_layer): ScalingLayer()\n",
       "           (net): Alexnet(\n",
       "             (slice1): Sequential(\n",
       "               (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "               (1): ReLU(inplace=True)\n",
       "             )\n",
       "             (slice2): Sequential(\n",
       "               (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "               (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "               (4): ReLU(inplace=True)\n",
       "             )\n",
       "             (slice3): Sequential(\n",
       "               (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "               (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "               (7): ReLU(inplace=True)\n",
       "             )\n",
       "             (slice4): Sequential(\n",
       "               (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "               (9): ReLU(inplace=True)\n",
       "             )\n",
       "             (slice5): Sequential(\n",
       "               (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "               (11): ReLU(inplace=True)\n",
       "             )\n",
       "           )\n",
       "           (lin0): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (lin1): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (lin2): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (lin3): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (lin4): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (lins): ModuleList(\n",
       "             (0): NetLinLayer(\n",
       "               (model): Sequential(\n",
       "                 (0): Dropout(p=0.5, inplace=False)\n",
       "                 (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "               )\n",
       "             )\n",
       "             (1): NetLinLayer(\n",
       "               (model): Sequential(\n",
       "                 (0): Dropout(p=0.5, inplace=False)\n",
       "                 (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "               )\n",
       "             )\n",
       "             (2): NetLinLayer(\n",
       "               (model): Sequential(\n",
       "                 (0): Dropout(p=0.5, inplace=False)\n",
       "                 (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "               )\n",
       "             )\n",
       "             (3-4): 2 x NetLinLayer(\n",
       "               (model): Sequential(\n",
       "                 (0): Dropout(p=0.5, inplace=False)\n",
       "                 (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (decoder): TwoLayerMLP(\n",
       "         (hidden_conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (feature_branch_dict): ModuleDict(\n",
       "           (dinov2): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "           (samclip): Conv2d(64, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (text_encoder): MaskCLIPExtractor(\n",
       "         (model): CLIP(\n",
       "           (visual): VisionTransformer(\n",
       "             (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "             (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (transformer): Transformer(\n",
       "               (resblocks): Sequential(\n",
       "                 (0): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (1): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (2): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (3): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (4): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (5): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (6): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (7): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (8): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (9): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (10): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (11): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (12): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (13): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (14): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (15): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (16): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (17): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (18): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (19): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (20): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (21): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (22): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "                 (23): ResidualAttentionBlock(\n",
       "                   (attn): MultiheadAttention(\n",
       "                     (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                   (mlp): Sequential(\n",
       "                     (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                     (gelu): QuickGELU()\n",
       "                     (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                   )\n",
       "                   (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (transformer): Transformer(\n",
       "             (resblocks): Sequential(\n",
       "               (0): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (1): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (2): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (3): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (4): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (5): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (6): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (7): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (8): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (9): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (10): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (11): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (token_embedding): Embedding(49408, 768)\n",
       "           (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (model): RadegsFeaturesModel(\n",
       "     (gauss_params): ParameterDict(\n",
       "         (features_dc): Parameter containing: [torch.FloatTensor of size 1295257x3]\n",
       "         (features_rest): Parameter containing: [torch.FloatTensor of size 1295257x0x3]\n",
       "         (means): Parameter containing: [torch.FloatTensor of size 1295257x3]\n",
       "         (opacities): Parameter containing: [torch.FloatTensor of size 1295257x1]\n",
       "         (quats): Parameter containing: [torch.FloatTensor of size 1295257x4]\n",
       "         (scales): Parameter containing: [torch.FloatTensor of size 1295257x3]\n",
       "         (distill_features): Parameter containing: [torch.FloatTensor of size 1295257x13]\n",
       "     )\n",
       "     (camera_optimizer): CameraOptimizer()\n",
       "     (psnr): PeakSignalNoiseRatio()\n",
       "     (ssim): SSIM()\n",
       "     (lpips): LearnedPerceptualImagePatchSimilarity(\n",
       "       (net): _NoTrainLpips(\n",
       "         (scaling_layer): ScalingLayer()\n",
       "         (net): Alexnet(\n",
       "           (slice1): Sequential(\n",
       "             (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "             (1): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice2): Sequential(\n",
       "             (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "             (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "             (4): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice3): Sequential(\n",
       "             (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "             (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (7): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice4): Sequential(\n",
       "             (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (9): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice5): Sequential(\n",
       "             (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (11): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (lin0): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin1): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin2): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin3): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin4): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lins): ModuleList(\n",
       "           (0): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (1): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (2): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (3-4): 2 x NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (decoder): TwoLayerMLP(\n",
       "       (hidden_conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (feature_branch_dict): ModuleDict(\n",
       "         (dinov2): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (samclip): Conv2d(64, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "       )\n",
       "     )\n",
       "     (text_encoder): MaskCLIPExtractor(\n",
       "       (model): CLIP(\n",
       "         (visual): VisionTransformer(\n",
       "           (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "           (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (transformer): Transformer(\n",
       "             (resblocks): Sequential(\n",
       "               (0): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (1): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (2): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (3): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (4): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (5): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (6): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (7): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (8): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (9): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (10): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (11): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (12): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (13): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (14): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (15): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (16): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (17): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (18): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (19): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (20): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (21): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (22): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (23): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "         (transformer): Transformer(\n",
       "           (resblocks): Sequential(\n",
       "             (0): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (1): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (2): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (3): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (4): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (5): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (6): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (7): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (8): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (9): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (10): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (11): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (token_embedding): Embedding(49408, 768)\n",
       "         (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (params): ParameterDict(  (identities): Parameter containing: [torch.FloatTensor of size 1295257x13])\n",
       "   (classifier): Conv2d(13, 729, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (loss_fn): CrossEntropyLoss()\n",
       " ),\n",
       " '/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/grouping/checkpoints/grouping-classifier-v1.ckpt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouping_classifier.lift_segmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to map onto the mesh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import open3d as o3d\n",
    "from collab_splats.utils.mesh import features2vertex\n",
    "\n",
    "\n",
    "mesh_dir = grouping_classifier.output_dir.parent / 'mesh'\n",
    "\n",
    "mesh_path = mesh_dir / 'mesh.ply'\n",
    "transforms_path = mesh_dir / 'transforms.pkl'\n",
    "\n",
    "with open(transforms_path, 'rb') as f:\n",
    "    transforms = pickle.load(f)\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(mesh_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriangleMesh with 592404 points and 1171436 triangles."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grouping_classifier.model.means.clone()\n",
    "\n",
    "means = means @ transforms[\"mesh_transform\"][:3, :3].T + transforms[\"mesh_transform\"][:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = grouping_classifier.per_gaussian_forward(grouping_classifier.identities)\n",
    "classes = classes.argmax(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping categorical features: 100%|██████████| 5/5 [00:17<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "features = features2vertex(\n",
    "    mesh_vertices=mesh.vertices,\n",
    "    points=means,\n",
    "    features=classes,\n",
    "    categorical=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1216, 0.4667, 0.7059],\n",
       "        [0.1216, 0.4667, 0.7059],\n",
       "        [0.1216, 0.4667, 0.7059],\n",
       "        ...,\n",
       "        [0.5804, 0.4039, 0.7412],\n",
       "        [0.5804, 0.4039, 0.7412],\n",
       "        [0.1216, 0.4667, 0.7059]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RGB colors for each unique class\n",
    "unique_classes = torch.unique(features)\n",
    "n_classes = len(unique_classes)\n",
    "\n",
    "# Generate distinct colors using HSV colorspace for better visual separation\n",
    "import matplotlib.pyplot as plt\n",
    "cmap = plt.get_cmap('tab10')  # or 'viridis', 'plasma', etc.\n",
    "\n",
    "# Create color mapping\n",
    "class_to_rgb = {}\n",
    "for i, class_id in enumerate(unique_classes):\n",
    "    color = cmap(i / max(1, n_classes - 1))  # Normalize to [0,1]\n",
    "    class_to_rgb[class_id.item()] = torch.tensor(color[:3], dtype=torch.float32)  # RGB only\n",
    "\n",
    "# Map classes to RGB colors\n",
    "rgb_colors = torch.zeros(features.shape[0], 3, dtype=torch.float32)\n",
    "for i, class_id in enumerate(features.squeeze()):\n",
    "    rgb_colors[i] = class_to_rgb[class_id.item()]\n",
    "\n",
    "rgb_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592404\n",
      "1171436\n",
      "BoundsTuple(x_min=-1.149007797241211, x_max=0.964453399181366, y_min=-0.3168279230594635, y_max=1.4859158992767334, z_min=-0.9972854256629944, z_max=-0.17026546597480774)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4bb54bac7b4276930b0d33959e00a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:42685/index.html?ui=P_0x7e04d03150f0_12&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "mesh = pv.read(mesh_path.as_posix())\n",
    "\n",
    "print(mesh.n_points)\n",
    "print(mesh.n_cells)\n",
    "print(mesh.bounds)\n",
    "\n",
    "mesh.plot(\n",
    "    scalars=rgb_colors, \n",
    "    rgb=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to cast Python instance of type <class 'numpy.int64'> to C++ type '?' (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mesh\u001b[38;5;241m.\u001b[39mvertex_colors \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutility\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVector3dVector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to cast Python instance of type <class 'numpy.int64'> to C++ type '?' (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
     ]
    }
   ],
   "source": [
    "mesh.vertex_colors = o3d.utility.Vector3dVector(features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t == DeviceType::CUDA INTERNAL ASSERT FAILED at \"/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/include/c10/cuda/impl/CUDAGuardImpl.h\":25, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m datamodule\u001b[38;5;241m.\u001b[39mtrain_dataloader():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mgrouping_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/collab-splats/collab_splats/utils/grouping.py:737\u001b[0m, in \u001b[0;36mGroupingClassifier.forward\u001b[0;34m(self, camera)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, camera: Cameras) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    732\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m    Forward pass of the classifier --> renders the camera\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m    viewpoint and creates identity embeddings. Then classifies\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m    the rasterized identities.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m     identities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_identities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     identities \u001b[38;5;241m=\u001b[39m identities\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [H, W, C] -> [C, H, W]\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(identities)\n",
      "File \u001b[0;32m/workspace/collab-splats/collab_splats/utils/grouping.py:640\u001b[0m, in \u001b[0;36mGroupingClassifier._render_identities\u001b[0;34m(self, camera)\u001b[0m\n\u001b[1;32m    631\u001b[0m fused_features \u001b[38;5;241m=\u001b[39m create_fused_features(\n\u001b[1;32m    632\u001b[0m     means\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmeans,\n\u001b[1;32m    633\u001b[0m     colors\u001b[38;5;241m=\u001b[39mcolors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m     sh_degree_to_use\u001b[38;5;241m=\u001b[39msh_degree_to_use,\n\u001b[1;32m    637\u001b[0m )\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# Rasterize the image using the fused features\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m render, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfused_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43msh_degree_to_use\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msh_degree_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m preds \u001b[38;5;241m=\u001b[39m render[:, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39midentity_dim]\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/workspace/collab-splats/collab_splats/models/rade_gs_model.py:403\u001b[0m, in \u001b[0;36mRadegsModel._render\u001b[0;34m(self, means, quats, scales, opacities, colors, render_mode, sh_degree_to_use, camera_params, visible_mask)\u001b[0m\n\u001b[1;32m    393\u001b[0m     colors \u001b[38;5;241m=\u001b[39m colors\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# Items are:\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# - render_colors: [N, 3]\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# - render_alphas: [N, 1]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# - expected_normals: [N, 1]\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# - info: dict\u001b[39;00m\n\u001b[1;32m    402\u001b[0m render, alpha, expected_depths, median_depths, expected_normals, meta \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 403\u001b[0m     \u001b[43mrasterization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N, 3]\u001b[39;49;00m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N, 4]\u001b[39;49;00m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscales\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N, 3]\u001b[39;49;00m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [N,]\u001b[39;49;00m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mviewmats\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, 4, 4]\u001b[39;49;00m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [1, 3, 3]\u001b[39;49;00m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_width\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcamera_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_height\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43msh_degree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msh_degree_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsgrad\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDefaultStrategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrasterize_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterize_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# # set some threshold to disregard small gaussians for faster rendering.\u001b[39;49;00m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# radius_clip=3.0,\u001b[39;49;00m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Output depth and normal maps\u001b[39;49;00m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_depth_normal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m render, alpha, expected_depths, median_depths, expected_normals, meta\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/rendering.py:301\u001b[0m, in \u001b[0;36mrasterization\u001b[0;34m(means, quats, scales, opacities, colors, viewmats, Ks, width, height, near_plane, far_plane, radius_clip, eps2d, sh_degree, packed, tile_size, backgrounds, render_mode, sparse_grad, absgrad, rasterize_mode, channel_chunk, distributed, camera_model, covars, return_depth_normal)\u001b[0m\n\u001b[1;32m    298\u001b[0m     C \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(viewmats)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Project Gaussians to 2D. Directly pass in {quats, scales} is faster than precomputing covars.\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m proj_results \u001b[38;5;241m=\u001b[39m \u001b[43mfully_fused_projection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mKs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalc_compensations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrasterize_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mantialiased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopacities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use opacities to compute a tigher bound for radii.\u001b[39;49;00m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packed:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# The results are packed into shape [nnz, ...]. All elements are valid.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     (\n\u001b[1;32m    324\u001b[0m         camera_ids,\n\u001b[1;32m    325\u001b[0m         gaussian_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m         normals\n\u001b[1;32m    334\u001b[0m     ) \u001b[38;5;241m=\u001b[39m proj_results\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/cuda/_wrapper.py:337\u001b[0m, in \u001b[0;36mfully_fused_projection\u001b[0;34m(means, covars, quats, scales, viewmats, Ks, width, height, eps2d, near_plane, far_plane, radius_clip, packed, sparse_grad, calc_compensations, camera_model, opacities)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _FullyFusedProjectionPacked\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    319\u001b[0m         means,\n\u001b[1;32m    320\u001b[0m         covars,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m         opacities,\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FullyFusedProjection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalc_compensations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcamera_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/cuda/_wrapper.py:791\u001b[0m, in \u001b[0;36m_FullyFusedProjection.forward\u001b[0;34m(ctx, means, covars, quats, scales, viewmats, Ks, width, height, eps2d, near_plane, far_plane, radius_clip, calc_compensations, camera_model, opacities)\u001b[0m\n\u001b[1;32m    786\u001b[0m camera_model_type \u001b[38;5;241m=\u001b[39m _make_lazy_cuda_obj(\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCameraModelType.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcamera_model\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m )\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# \"covars\" and {\"quats\", \"scales\"} are mutually exclusive\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m radii, means2d, depths, conics, compensations, ray_ts, ray_planes, normals \u001b[38;5;241m=\u001b[39m \u001b[43m_make_lazy_cuda_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojection_ewa_3dgs_fused_fwd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopacities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mviewmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mKs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalc_compensations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_model_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m calc_compensations:\n\u001b[1;32m    811\u001b[0m     compensations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/gsplat/cuda/_wrapper.py:14\u001b[0m, in \u001b[0;36m_make_lazy_cuda_func.<locals>.call_cuda\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_cuda\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t == DeviceType::CUDA INTERNAL ASSERT FAILED at \"/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/include/c10/cuda/impl/CUDAGuardImpl.h\":25, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "for x in datamodule.train_dataloader():\n",
    "    break\n",
    "\n",
    "outs = grouping_classifier(x[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
