{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Dictionary Segmentation\n",
    "\n",
    "This notebook tests semantic segmentation using a dictionary of terms with positive queries. Each term's queries are contrasted against negative queries from other dictionary items to segment the environment into semantic compartments.\n",
    "\n",
    "For example:\n",
    "- 'tree': ['green', 'leaves', 'bark', 'trunk', 'branches']\n",
    "- 'ground': ['dirt', 'rocks', 'floor', 'soil', 'path']\n",
    "- 'sky': ['blue', 'clouds', 'air', 'above']\n",
    "- 'feeder': ['bird feeder', 'feeding station', 'container']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Taichi] version 1.7.4, llvm 15.0.4, commit b4b956fd, linux, python 3.10.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 12/10/25 18:52:39.459 41554] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "from collab_splats.wrapper import Splatter\n",
    "from collab_splats.utils.mesh import mesh_clustering\n",
    "\n",
    "# pv.start_xvfb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the splatter from configuration\n",
    "\n",
    "Load the dataset configuration from YAML and ensure preprocessing/training steps are complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforms.json already exists at /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/transforms.json\n",
      "To rerun preprocessing, set overwrite=True\n",
      "Output already exists for rade-features\n",
      "To rerun feature extraction, set overwrite=True\n",
      "\n",
      "Available runs:\n",
      "[0] 2025-07-25_040743\n"
     ]
    }
   ],
   "source": [
    "# Load splatter from YAML config\n",
    "splatter = Splatter.from_config_file(\n",
    "    dataset='birds_date-02062024_video-C0043',\n",
    "    config_dir='/workspace/collab-splats/docs/splats/configs'\n",
    ")\n",
    "\n",
    "# Ensure preprocessing and training are done\n",
    "# (if already completed, these will skip automatically)\n",
    "splatter.preprocess()\n",
    "splatter.extract_features()\n",
    "splatter.mesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/rade-features/2025-07-25_040743/config.yml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Train dataset has over </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> images, overriding cache_images to cpu. If you still get OOM errors or segfault, please </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">consider seting cache_images to </span><span style=\"color: #008000; text-decoration-color: #008000\">'disk'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mTrain dataset has over \u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m images, overriding cache_images to cpu. If you still get OOM errors or segfault, please \u001b[0m\n",
       "\u001b[1;33mconsider seting cache_images to \u001b[0m\u001b[32m'disk'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Found cached features at \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">feature-splatting_samclip-features.pt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Found cached features at \n",
       "\u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc/\u001b[0m\u001b[95mfeature-splatting_samclip-features.pt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Loading features from cache</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Loading features from cache\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:50:21] </span>use color only optimization with sigmoid activation                                         <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">splatfacto.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:50:21]\u001b[0m\u001b[2;36m \u001b[0muse color only optimization with sigmoid activation                                         \u001b]8;id=12964;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\u001b\\\u001b[2msplatfacto.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=562028;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/rade-features/2025-07-25_040743/nerfstudio_models/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">step-0000</span>\n",
       "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">29999.ckpt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "\u001b[35m/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/rade-features/2025-07-25_040743/nerfstudio_models/\u001b[0m\u001b[95mstep-0000\u001b[0m\n",
       "\u001b[95m29999.ckpt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded: RadegsFeaturesModel (step 29999)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(_TrainerConfig(_target=<class 'nerfstudio.engine.trainer.Trainer'>, output_dir=PosixPath('/workspace/fieldwork-data/birds/2024-02-06/environment/C0043'), method_name='rade-features', experiment_name='', project_name='nerfstudio-project', timestamp='2025-07-25_040743', machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'), logging=LoggingConfig(relative_log_dir=PosixPath('.'), steps_per_log=10, max_buffer_size=20, local_writer=LocalWriterConfig(_target=<class 'nerfstudio.utils.writer.LocalWriter'>, enable=True, stats_to_track=(<EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>, <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>, <EventName.CURR_TEST_PSNR: 'Test PSNR'>, <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>, <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>, <EventName.ETA: 'ETA (time)'>), max_log_size=10), profiler='basic'), viewer=ViewerConfig(relative_log_filename='viewer_log_filename.txt', websocket_port=None, websocket_port_default=7007, websocket_host='0.0.0.0', num_rays_per_chunk=32768, max_num_display_images=512, quit_on_train_completion=True, image_format='jpeg', jpeg_quality=75, make_share_url=False, camera_frustum_scale=0.1, default_composite_depth=True), pipeline=VanillaPipelineConfig(_target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>, datamanager=FeatureSplattingDataManagerConfig(_target=<class 'collab_splats.datamanagers.features_datamanager.FeatureSplattingDataManager'>, data=PosixPath('/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc'), masks_on_gpu=False, images_on_gpu=False, dataparser=NerfstudioDataParserConfig(_target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>, data=PosixPath('/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc'), scale_factor=1.0, downscale_factor=None, scene_scale=1.0, orientation_method='up', center_method='poses', auto_scale_poses=True, eval_mode='fraction', train_split_fraction=0.9, eval_interval=8, depth_unit_scale_factor=0.001, mask_color=None, load_3D_points=True), camera_res_scale_factor=1.0, eval_num_images_to_sample_from=-1, eval_num_times_to_repeat_images=-1, cache_images='cpu', cache_images_type='uint8', max_thread_workers=None, train_cameras_sampling_strategy='random', train_cameras_sampling_seed=42, fps_reset_every=100, dataloader_num_workers=4, prefetch_factor=4, cache_compressed_images=False, main_features='samclip', regularization_features='dinov2', enable_cache=True, segmentation_backend='mobilesamv2', segmentation_strategy='object', sam_resolution=1024, obj_resolution=100, final_resolution=64), model=RadegsFeaturesModelConfig(_target=<class 'collab_splats.models.rade_features_model.RadegsFeaturesModel'>, enable_collider=True, collider_params={'far_plane': 6.0, 'near_plane': 2.0}, loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0}, eval_num_rays_per_chunk=4096, prompt=None, warmup_length=500, refine_every=100, resolution_schedule=3000, background_color='random', num_downscales=2, cull_alpha_thresh=0.1, cull_scale_thresh=0.5, reset_alpha_every=30, densify_grad_thresh=0.0008, use_absgrad=True, densify_size_thresh=0.01, n_split_samples=2, sh_degree_interval=1000, cull_screen_size=0.15, split_screen_size=0.05, stop_screen_size_at=4000, random_init=False, num_random=50000, random_scale=10.0, ssim_lambda=0.2, stop_split_at=15000, sh_degree=0, use_scale_regularization=True, max_gauss_ratio=10.0, output_depth_during_training=True, rasterize_mode='antialiased', camera_optimizer=CameraOptimizerConfig(_target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>, mode='off', trans_l2_penalty=0.01, rot_l2_penalty=0.001, optimizer=None, scheduler=None), use_bilateral_grid=False, grid_shape=(16, 16, 8), color_corrected_metrics=False, strategy='default', max_gs_num=1000000, noise_lr=500000.0, mcmc_opacity_reg=0.01, mcmc_scale_reg=0.01, regularization_from_iter=15000, use_depth_normal_loss=True, depth_normal_lambda=0.05, depth_ratio=0.6, render_mode='RGB', prefilter_voxel=False, features_loss_lambda=0.001, features_regularization_lambda=0.1, features_latent_dim=13, mlp_hidden_dim=64, positive_queries=[''], negative_queries=['object'], similarity_method='pairwise')), optimizers={'bilateral_grid': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.002, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': ExponentialDecaySchedulerConfig(_target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>, lr_pre_warmup=0, lr_final=0.0001, warmup_steps=1000, max_steps=30000, ramp='cosine')}, 'camera_opt': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.0001, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': ExponentialDecaySchedulerConfig(_target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>, lr_pre_warmup=0, lr_final=5e-07, warmup_steps=1000, max_steps=30000, ramp='cosine')}, 'decoder': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.001, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': None}, 'distill_features': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.0025, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': ExponentialDecaySchedulerConfig(_target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>, lr_pre_warmup=1e-08, lr_final=0.0005, warmup_steps=0, max_steps=10000, ramp='cosine')}, 'features_dc': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.0025, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': None}, 'features_rest': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.000125, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': None}, 'means': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.00016, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': ExponentialDecaySchedulerConfig(_target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>, lr_pre_warmup=1e-08, lr_final=1.6e-06, warmup_steps=0, max_steps=30000, ramp='cosine')}, 'opacities': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.05, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': None}, 'quats': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.001, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': None}, 'scales': {'optimizer': AdamOptimizerConfig(_target=<class 'torch.optim.adam.Adam'>, lr=0.005, eps=1e-15, max_norm=None, weight_decay=0), 'scheduler': None}}, vis='viewer', data=PosixPath('/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/preproc'), prompt=None, relative_model_dir=PosixPath('nerfstudio_models'), load_scheduler=True, steps_per_save=2000, steps_per_eval_batch=0, steps_per_eval_image=100, steps_per_eval_all_images=1000, max_num_iterations=30000, mixed_precision=False, use_grad_scaler=False, save_only_latest_checkpoint=True, load_dir=PosixPath('/workspace/fieldwork-data/birds/2024-02-06/environment/C0043/rade-features/2025-07-25_040743/nerfstudio_models'), load_step=None, load_config=None, load_checkpoint=None, log_gradients=False, gradient_accumulation_steps={}, start_paused=False),\n",
       " VanillaPipeline(\n",
       "   (_model): RadegsFeaturesModel(\n",
       "     (gauss_params): ParameterDict(\n",
       "         (features_dc): Parameter containing: [torch.cuda.FloatTensor of size 1872950x3 (cuda:0)]\n",
       "         (features_rest): Parameter containing: [torch.cuda.FloatTensor of size 1872950x0x3 (cuda:0)]\n",
       "         (means): Parameter containing: [torch.cuda.FloatTensor of size 1872950x3 (cuda:0)]\n",
       "         (opacities): Parameter containing: [torch.cuda.FloatTensor of size 1872950x1 (cuda:0)]\n",
       "         (quats): Parameter containing: [torch.cuda.FloatTensor of size 1872950x4 (cuda:0)]\n",
       "         (scales): Parameter containing: [torch.cuda.FloatTensor of size 1872950x3 (cuda:0)]\n",
       "         (distill_features): Parameter containing: [torch.cuda.FloatTensor of size 1872950x13 (cuda:0)]\n",
       "     )\n",
       "     (camera_optimizer): CameraOptimizer()\n",
       "     (psnr): PeakSignalNoiseRatio()\n",
       "     (ssim): SSIM()\n",
       "     (lpips): LearnedPerceptualImagePatchSimilarity(\n",
       "       (net): _NoTrainLpips(\n",
       "         (scaling_layer): ScalingLayer()\n",
       "         (net): Alexnet(\n",
       "           (slice1): Sequential(\n",
       "             (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "             (1): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice2): Sequential(\n",
       "             (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "             (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "             (4): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice3): Sequential(\n",
       "             (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "             (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (7): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice4): Sequential(\n",
       "             (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (9): ReLU(inplace=True)\n",
       "           )\n",
       "           (slice5): Sequential(\n",
       "             (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (11): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "         (lin0): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin1): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin2): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin3): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lin4): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (lins): ModuleList(\n",
       "           (0): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (1): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (2): NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "           (3-4): 2 x NetLinLayer(\n",
       "             (model): Sequential(\n",
       "               (0): Dropout(p=0.5, inplace=False)\n",
       "               (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (decoder): TwoLayerMLP(\n",
       "       (hidden_conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (feature_branch_dict): ModuleDict(\n",
       "         (dinov2): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "         (samclip): Conv2d(64, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "       )\n",
       "     )\n",
       "     (text_encoder): MaskCLIPExtractor(\n",
       "       (model): CLIP(\n",
       "         (visual): VisionTransformer(\n",
       "           (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "           (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (transformer): Transformer(\n",
       "             (resblocks): Sequential(\n",
       "               (0): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (1): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (2): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (3): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (4): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (5): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (6): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (7): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (8): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (9): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (10): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (11): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (12): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (13): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (14): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (15): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (16): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (17): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (18): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (19): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (20): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (21): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (22): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "               (23): ResidualAttentionBlock(\n",
       "                 (attn): MultiheadAttention(\n",
       "                   (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                 (mlp): Sequential(\n",
       "                   (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                   (gelu): QuickGELU()\n",
       "                   (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 )\n",
       "                 (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "         (transformer): Transformer(\n",
       "           (resblocks): Sequential(\n",
       "             (0): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (1): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (2): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (3): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (4): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (5): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (6): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (7): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (8): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (9): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (10): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (11): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (token_embedding): Embedding(49408, 768)\n",
       "         (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " RadegsFeaturesModel(\n",
       "   (gauss_params): ParameterDict(\n",
       "       (features_dc): Parameter containing: [torch.cuda.FloatTensor of size 1872950x3 (cuda:0)]\n",
       "       (features_rest): Parameter containing: [torch.cuda.FloatTensor of size 1872950x0x3 (cuda:0)]\n",
       "       (means): Parameter containing: [torch.cuda.FloatTensor of size 1872950x3 (cuda:0)]\n",
       "       (opacities): Parameter containing: [torch.cuda.FloatTensor of size 1872950x1 (cuda:0)]\n",
       "       (quats): Parameter containing: [torch.cuda.FloatTensor of size 1872950x4 (cuda:0)]\n",
       "       (scales): Parameter containing: [torch.cuda.FloatTensor of size 1872950x3 (cuda:0)]\n",
       "       (distill_features): Parameter containing: [torch.cuda.FloatTensor of size 1872950x13 (cuda:0)]\n",
       "   )\n",
       "   (camera_optimizer): CameraOptimizer()\n",
       "   (psnr): PeakSignalNoiseRatio()\n",
       "   (ssim): SSIM()\n",
       "   (lpips): LearnedPerceptualImagePatchSimilarity(\n",
       "     (net): _NoTrainLpips(\n",
       "       (scaling_layer): ScalingLayer()\n",
       "       (net): Alexnet(\n",
       "         (slice1): Sequential(\n",
       "           (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "           (1): ReLU(inplace=True)\n",
       "         )\n",
       "         (slice2): Sequential(\n",
       "           (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "           (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "           (4): ReLU(inplace=True)\n",
       "         )\n",
       "         (slice3): Sequential(\n",
       "           (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "           (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (7): ReLU(inplace=True)\n",
       "         )\n",
       "         (slice4): Sequential(\n",
       "           (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (9): ReLU(inplace=True)\n",
       "         )\n",
       "         (slice5): Sequential(\n",
       "           (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "           (11): ReLU(inplace=True)\n",
       "         )\n",
       "       )\n",
       "       (lin0): NetLinLayer(\n",
       "         (model): Sequential(\n",
       "           (0): Dropout(p=0.5, inplace=False)\n",
       "           (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         )\n",
       "       )\n",
       "       (lin1): NetLinLayer(\n",
       "         (model): Sequential(\n",
       "           (0): Dropout(p=0.5, inplace=False)\n",
       "           (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         )\n",
       "       )\n",
       "       (lin2): NetLinLayer(\n",
       "         (model): Sequential(\n",
       "           (0): Dropout(p=0.5, inplace=False)\n",
       "           (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         )\n",
       "       )\n",
       "       (lin3): NetLinLayer(\n",
       "         (model): Sequential(\n",
       "           (0): Dropout(p=0.5, inplace=False)\n",
       "           (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         )\n",
       "       )\n",
       "       (lin4): NetLinLayer(\n",
       "         (model): Sequential(\n",
       "           (0): Dropout(p=0.5, inplace=False)\n",
       "           (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         )\n",
       "       )\n",
       "       (lins): ModuleList(\n",
       "         (0): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (1): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (2): NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "         (3-4): 2 x NetLinLayer(\n",
       "           (model): Sequential(\n",
       "             (0): Dropout(p=0.5, inplace=False)\n",
       "             (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (decoder): TwoLayerMLP(\n",
       "     (hidden_conv): Conv2d(13, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (feature_branch_dict): ModuleDict(\n",
       "       (dinov2): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (samclip): Conv2d(64, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "     )\n",
       "   )\n",
       "   (text_encoder): MaskCLIPExtractor(\n",
       "     (model): CLIP(\n",
       "       (visual): VisionTransformer(\n",
       "         (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "         (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         (transformer): Transformer(\n",
       "           (resblocks): Sequential(\n",
       "             (0): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (1): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (2): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (3): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (4): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (5): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (6): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (7): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (8): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (9): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (10): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (11): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (12): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (13): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (14): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (15): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (16): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (17): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (18): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (19): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (20): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (21): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (22): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "             (23): ResidualAttentionBlock(\n",
       "               (attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (mlp): Sequential(\n",
       "                 (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (gelu): QuickGELU()\n",
       "                 (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "               (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "       (transformer): Transformer(\n",
       "         (resblocks): Sequential(\n",
       "           (0): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (1): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (2): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (3): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (4): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (5): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (6): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (7): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (8): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (9): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (10): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "           (11): ResidualAttentionBlock(\n",
       "             (attn): MultiheadAttention(\n",
       "               (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (mlp): Sequential(\n",
       "               (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (gelu): QuickGELU()\n",
       "               (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             )\n",
       "             (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (token_embedding): Embedding(49408, 768)\n",
       "       (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splatter.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Semantic Dictionary\n",
    "\n",
    "Create a dictionary mapping semantic categories to positive query terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Semantic dictionary: maps categories to positive query terms\n",
    "semantic_dictionary = {\n",
    "    'tree': ['green', 'leaves', 'bark', 'trunk'],\n",
    "    # 'ground': ['rocks'],\n",
    "    'feeder': ['bird feeder', 'container', 'food'],\n",
    "    'brush': ['leaves', 'plants', 'thicket', 'bramble'],\n",
    "    'gravel': ['gravel', 'rock', 'concrete'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'brush'\n",
    "positive_queries = semantic_dictionary[category]\n",
    "negative_queries = [other_category for other_category in semantic_dictionary.keys() if other_category != category]\n",
    "\n",
    "\n",
    "similarity = splatter.query_mesh(\n",
    "    positive_queries=positive_queries,\n",
    "    negative_queries=negative_queries,\n",
    "    output_fn=f\"query-{category}.ply\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 351349\n",
      "Number of cells: 661879\n",
      "Bounds: BoundsTuple(x_min=-1.093526840209961, x_max=0.6880093812942505, y_min=-0.27054786682128906, y_max=1.2863465547561646, z_min=-0.42523476481437683, z_max=0.5941177606582642)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62884c1a0e464e3b8c057e4d3ada20a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34769/index.html?ui=P_0x7fb7308a2ad0_25&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load query mesh\n",
    "mesh_dir = splatter.config[\"mesh_info\"][\"mesh\"].parent\n",
    "query_mesh_path = mesh_dir / f\"query-{category}.ply\"\n",
    "\n",
    "splatter.plot_mesh(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Mesh for Each Semantic Category\n",
    "\n",
    "For each semantic term, use its positive queries and contrast them against negative queries (all terms from other categories in the dictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying 'tree'...\n",
      "  Positive: ['green', 'leaves', 'bark', 'trunk', 'tree']\n",
      "  Negative: 3 terms from other categories\n",
      "  Done! Saved to query-tree.ply\n",
      "\n",
      "Querying 'feeder'...\n",
      "  Positive: ['bird feeder', 'container', 'food', 'feeder']\n",
      "  Negative: 3 terms from other categories\n",
      "  Done! Saved to query-feeder.ply\n",
      "\n",
      "Querying 'brush'...\n",
      "  Positive: ['leaves', 'plants', 'thicket', 'bramble', 'brush']\n",
      "  Negative: 3 terms from other categories\n",
      "  Done! Saved to query-brush.ply\n",
      "\n",
      "Querying 'gravel'...\n",
      "  Positive: ['gravel', 'rock', 'concrete', 'gravel']\n",
      "  Negative: 3 terms from other categories\n",
      "  Done! Saved to query-gravel.ply\n"
     ]
    }
   ],
   "source": [
    "# Store results for each category\n",
    "semantic_results = {}\n",
    "\n",
    "# Query mesh for each semantic category\n",
    "for category, positive_queries in semantic_dictionary.items():\n",
    "    # Gather negative queries from all other categories\n",
    "    negative_queries = []\n",
    "    positive_queries += [category] # Add category to positive queries\n",
    "\n",
    "    for other_category, other_queries in semantic_dictionary.items():\n",
    "        if other_category != category:\n",
    "            negative_queries.extend([other_category])\n",
    "            # negative_queries.extend(other_queries)\n",
    "    \n",
    "    # Query the mesh with positive vs negative queries\n",
    "    print(f\"\\nQuerying '{category}'...\")\n",
    "    print(f\"  Positive: {positive_queries}\")\n",
    "    print(f\"  Negative: {len(negative_queries)} terms from other categories\")\n",
    "    \n",
    "    similarity = splatter.query_mesh(\n",
    "        positive_queries=positive_queries,\n",
    "        negative_queries=negative_queries,\n",
    "        output_fn=f\"query-{category}.ply\"\n",
    "    )\n",
    "    \n",
    "    semantic_results[category] = similarity\n",
    "    print(f\"  Done! Saved to query-{category}.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate All Clusters into Categorical Mesh\n",
    "\n",
    "Cluster all semantic categories and combine them into a single categorical mesh with unique labels for each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 'tree'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building adjacency matrix: 75777it [00:07, 9928.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 134 clusters\n",
      "    Cluster 0: 12445 vertices\n",
      "    Cluster 1: 7667 vertices\n",
      "    Cluster 2: 23324 vertices\n",
      "    Cluster 3: 2405 vertices\n",
      "    Cluster 4: 1110 vertices\n",
      "    Cluster 5: 141 vertices\n",
      "    Cluster 6: 66 vertices\n",
      "    Cluster 7: 122 vertices\n",
      "    Cluster 8: 144 vertices\n",
      "    Cluster 9: 65 vertices\n",
      "    Cluster 10: 358 vertices\n",
      "    Cluster 11: 86 vertices\n",
      "    Cluster 12: 319 vertices\n",
      "    Cluster 13: 66 vertices\n",
      "    Cluster 14: 40 vertices\n",
      "    Cluster 15: 47 vertices\n",
      "    Cluster 16: 1254 vertices\n",
      "    Cluster 17: 17 vertices\n",
      "    Cluster 18: 498 vertices\n",
      "    Cluster 19: 4160 vertices\n",
      "    Cluster 20: 42 vertices\n",
      "    Cluster 21: 20 vertices\n",
      "    Cluster 22: 527 vertices\n",
      "    Cluster 23: 23 vertices\n",
      "    Cluster 24: 21 vertices\n",
      "    Cluster 25: 296 vertices\n",
      "    Cluster 26: 17 vertices\n",
      "    Cluster 27: 30 vertices\n",
      "    Cluster 28: 28 vertices\n",
      "    Cluster 29: 41 vertices\n",
      "    Cluster 30: 77 vertices\n",
      "    Cluster 31: 22 vertices\n",
      "    Cluster 32: 36 vertices\n",
      "    Cluster 33: 59 vertices\n",
      "    Cluster 34: 51 vertices\n",
      "    Cluster 35: 93 vertices\n",
      "    Cluster 36: 51 vertices\n",
      "    Cluster 37: 14 vertices\n",
      "    Cluster 38: 11 vertices\n",
      "    Cluster 39: 59 vertices\n",
      "    Cluster 40: 22 vertices\n",
      "    Cluster 41: 17 vertices\n",
      "    Cluster 42: 48 vertices\n",
      "    Cluster 43: 29 vertices\n",
      "    Cluster 44: 14 vertices\n",
      "    Cluster 45: 24 vertices\n",
      "    Cluster 46: 22 vertices\n",
      "    Cluster 47: 11 vertices\n",
      "    Cluster 48: 63 vertices\n",
      "    Cluster 49: 17 vertices\n",
      "    Cluster 50: 48 vertices\n",
      "    Cluster 51: 17 vertices\n",
      "    Cluster 52: 25 vertices\n",
      "    Cluster 53: 138 vertices\n",
      "    Cluster 54: 46 vertices\n",
      "    Cluster 55: 239 vertices\n",
      "    Cluster 56: 412 vertices\n",
      "    Cluster 57: 189 vertices\n",
      "    Cluster 58: 51 vertices\n",
      "    Cluster 59: 45 vertices\n",
      "    Cluster 60: 266 vertices\n",
      "    Cluster 61: 11 vertices\n",
      "    Cluster 62: 51 vertices\n",
      "    Cluster 63: 87 vertices\n",
      "    Cluster 64: 93 vertices\n",
      "    Cluster 65: 64 vertices\n",
      "    Cluster 66: 12 vertices\n",
      "    Cluster 67: 16 vertices\n",
      "    Cluster 68: 11 vertices\n",
      "    Cluster 69: 336 vertices\n",
      "    Cluster 70: 301 vertices\n",
      "    Cluster 71: 975 vertices\n",
      "    Cluster 72: 56 vertices\n",
      "    Cluster 73: 33 vertices\n",
      "    Cluster 74: 45 vertices\n",
      "    Cluster 75: 90 vertices\n",
      "    Cluster 76: 21 vertices\n",
      "    Cluster 77: 282 vertices\n",
      "    Cluster 78: 12 vertices\n",
      "    Cluster 79: 67 vertices\n",
      "    Cluster 80: 108 vertices\n",
      "    Cluster 81: 68 vertices\n",
      "    Cluster 82: 138 vertices\n",
      "    Cluster 83: 18 vertices\n",
      "    Cluster 84: 129 vertices\n",
      "    Cluster 85: 1036 vertices\n",
      "    Cluster 86: 11 vertices\n",
      "    Cluster 87: 132 vertices\n",
      "    Cluster 88: 38 vertices\n",
      "    Cluster 89: 324 vertices\n",
      "    Cluster 90: 787 vertices\n",
      "    Cluster 91: 400 vertices\n",
      "    Cluster 92: 139 vertices\n",
      "    Cluster 93: 23 vertices\n",
      "    Cluster 94: 38 vertices\n",
      "    Cluster 95: 35 vertices\n",
      "    Cluster 96: 49 vertices\n",
      "    Cluster 97: 69 vertices\n",
      "    Cluster 98: 127 vertices\n",
      "    Cluster 99: 569 vertices\n",
      "    Cluster 100: 1000 vertices\n",
      "    Cluster 101: 15 vertices\n",
      "    Cluster 102: 3238 vertices\n",
      "    Cluster 103: 696 vertices\n",
      "    Cluster 104: 32 vertices\n",
      "    Cluster 105: 19 vertices\n",
      "    Cluster 106: 62 vertices\n",
      "    Cluster 107: 21 vertices\n",
      "    Cluster 108: 1416 vertices\n",
      "    Cluster 109: 64 vertices\n",
      "    Cluster 110: 101 vertices\n",
      "    Cluster 111: 58 vertices\n",
      "    Cluster 112: 41 vertices\n",
      "    Cluster 113: 22 vertices\n",
      "    Cluster 114: 12 vertices\n",
      "    Cluster 115: 26 vertices\n",
      "    Cluster 116: 16 vertices\n",
      "    Cluster 117: 97 vertices\n",
      "    Cluster 118: 13 vertices\n",
      "    Cluster 119: 16 vertices\n",
      "    Cluster 120: 15 vertices\n",
      "    Cluster 121: 21 vertices\n",
      "    Cluster 122: 21 vertices\n",
      "    Cluster 123: 37 vertices\n",
      "    Cluster 124: 96 vertices\n",
      "    Cluster 125: 82 vertices\n",
      "    Cluster 126: 274 vertices\n",
      "    Cluster 127: 20 vertices\n",
      "    Cluster 128: 2510 vertices\n",
      "    Cluster 129: 18 vertices\n",
      "    Cluster 130: 795 vertices\n",
      "    Cluster 131: 22 vertices\n",
      "    Cluster 132: 11 vertices\n",
      "    Cluster 133: 13 vertices\n",
      "\n",
      "Processing 'feeder'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building adjacency matrix: 6440it [00:00, 12110.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 79 clusters\n",
      "    Cluster 134: 16 vertices\n",
      "    Cluster 135: 38 vertices\n",
      "    Cluster 136: 25 vertices\n",
      "    Cluster 137: 11 vertices\n",
      "    Cluster 138: 28 vertices\n",
      "    Cluster 139: 24 vertices\n",
      "    Cluster 140: 103 vertices\n",
      "    Cluster 141: 105 vertices\n",
      "    Cluster 142: 63 vertices\n",
      "    Cluster 143: 26 vertices\n",
      "    Cluster 144: 1602 vertices\n",
      "    Cluster 145: 90 vertices\n",
      "    Cluster 146: 28 vertices\n",
      "    Cluster 147: 48 vertices\n",
      "    Cluster 148: 13 vertices\n",
      "    Cluster 149: 82 vertices\n",
      "    Cluster 150: 12 vertices\n",
      "    Cluster 151: 26 vertices\n",
      "    Cluster 152: 117 vertices\n",
      "    Cluster 153: 20 vertices\n",
      "    Cluster 154: 64 vertices\n",
      "    Cluster 155: 185 vertices\n",
      "    Cluster 156: 53 vertices\n",
      "    Cluster 157: 12 vertices\n",
      "    Cluster 158: 22 vertices\n",
      "    Cluster 159: 54 vertices\n",
      "    Cluster 160: 42 vertices\n",
      "    Cluster 161: 29 vertices\n",
      "    Cluster 162: 90 vertices\n",
      "    Cluster 163: 50 vertices\n",
      "    Cluster 164: 13 vertices\n",
      "    Cluster 165: 34 vertices\n",
      "    Cluster 166: 54 vertices\n",
      "    Cluster 167: 67 vertices\n",
      "    Cluster 168: 45 vertices\n",
      "    Cluster 169: 99 vertices\n",
      "    Cluster 170: 14 vertices\n",
      "    Cluster 171: 159 vertices\n",
      "    Cluster 172: 27 vertices\n",
      "    Cluster 173: 28 vertices\n",
      "    Cluster 174: 385 vertices\n",
      "    Cluster 175: 13 vertices\n",
      "    Cluster 176: 89 vertices\n",
      "    Cluster 177: 28 vertices\n",
      "    Cluster 178: 57 vertices\n",
      "    Cluster 179: 13 vertices\n",
      "    Cluster 180: 48 vertices\n",
      "    Cluster 181: 27 vertices\n",
      "    Cluster 182: 18 vertices\n",
      "    Cluster 183: 128 vertices\n",
      "    Cluster 184: 395 vertices\n",
      "    Cluster 185: 14 vertices\n",
      "    Cluster 186: 70 vertices\n",
      "    Cluster 187: 66 vertices\n",
      "    Cluster 188: 59 vertices\n",
      "    Cluster 189: 15 vertices\n",
      "    Cluster 190: 16 vertices\n",
      "    Cluster 191: 69 vertices\n",
      "    Cluster 192: 72 vertices\n",
      "    Cluster 193: 82 vertices\n",
      "    Cluster 194: 13 vertices\n",
      "    Cluster 195: 23 vertices\n",
      "    Cluster 196: 76 vertices\n",
      "    Cluster 197: 16 vertices\n",
      "    Cluster 198: 13 vertices\n",
      "    Cluster 199: 19 vertices\n",
      "    Cluster 200: 95 vertices\n",
      "    Cluster 201: 47 vertices\n",
      "    Cluster 202: 14 vertices\n",
      "    Cluster 203: 94 vertices\n",
      "    Cluster 204: 86 vertices\n",
      "    Cluster 205: 65 vertices\n",
      "    Cluster 206: 21 vertices\n",
      "    Cluster 207: 12 vertices\n",
      "    Cluster 208: 18 vertices\n",
      "    Cluster 209: 17 vertices\n",
      "    Cluster 210: 14 vertices\n",
      "    Cluster 211: 20 vertices\n",
      "    Cluster 212: 14 vertices\n",
      "\n",
      "Processing 'brush'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building adjacency matrix: 9800it [00:00, 10073.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 82 clusters\n",
      "    Cluster 213: 64 vertices\n",
      "    Cluster 214: 15 vertices\n",
      "    Cluster 215: 55 vertices\n",
      "    Cluster 216: 22 vertices\n",
      "    Cluster 217: 76 vertices\n",
      "    Cluster 218: 85 vertices\n",
      "    Cluster 219: 44 vertices\n",
      "    Cluster 220: 37 vertices\n",
      "    Cluster 221: 28 vertices\n",
      "    Cluster 222: 1805 vertices\n",
      "    Cluster 223: 53 vertices\n",
      "    Cluster 224: 64 vertices\n",
      "    Cluster 225: 153 vertices\n",
      "    Cluster 226: 73 vertices\n",
      "    Cluster 227: 11 vertices\n",
      "    Cluster 228: 62 vertices\n",
      "    Cluster 229: 403 vertices\n",
      "    Cluster 230: 134 vertices\n",
      "    Cluster 231: 20 vertices\n",
      "    Cluster 232: 83 vertices\n",
      "    Cluster 233: 55 vertices\n",
      "    Cluster 234: 28 vertices\n",
      "    Cluster 235: 58 vertices\n",
      "    Cluster 236: 377 vertices\n",
      "    Cluster 237: 820 vertices\n",
      "    Cluster 238: 15 vertices\n",
      "    Cluster 239: 54 vertices\n",
      "    Cluster 240: 13 vertices\n",
      "    Cluster 241: 23 vertices\n",
      "    Cluster 242: 324 vertices\n",
      "    Cluster 243: 143 vertices\n",
      "    Cluster 244: 31 vertices\n",
      "    Cluster 245: 22 vertices\n",
      "    Cluster 246: 44 vertices\n",
      "    Cluster 247: 176 vertices\n",
      "    Cluster 248: 24 vertices\n",
      "    Cluster 249: 27 vertices\n",
      "    Cluster 250: 60 vertices\n",
      "    Cluster 251: 30 vertices\n",
      "    Cluster 252: 46 vertices\n",
      "    Cluster 253: 27 vertices\n",
      "    Cluster 254: 21 vertices\n",
      "    Cluster 255: 66 vertices\n",
      "    Cluster 256: 23 vertices\n",
      "    Cluster 257: 103 vertices\n",
      "    Cluster 258: 44 vertices\n",
      "    Cluster 259: 42 vertices\n",
      "    Cluster 260: 25 vertices\n",
      "    Cluster 261: 26 vertices\n",
      "    Cluster 262: 51 vertices\n",
      "    Cluster 263: 42 vertices\n",
      "    Cluster 264: 106 vertices\n",
      "    Cluster 265: 11 vertices\n",
      "    Cluster 266: 52 vertices\n",
      "    Cluster 267: 1788 vertices\n",
      "    Cluster 268: 12 vertices\n",
      "    Cluster 269: 54 vertices\n",
      "    Cluster 270: 291 vertices\n",
      "    Cluster 271: 115 vertices\n",
      "    Cluster 272: 160 vertices\n",
      "    Cluster 273: 37 vertices\n",
      "    Cluster 274: 59 vertices\n",
      "    Cluster 275: 18 vertices\n",
      "    Cluster 276: 19 vertices\n",
      "    Cluster 277: 11 vertices\n",
      "    Cluster 278: 75 vertices\n",
      "    Cluster 279: 22 vertices\n",
      "    Cluster 280: 14 vertices\n",
      "    Cluster 281: 25 vertices\n",
      "    Cluster 282: 11 vertices\n",
      "    Cluster 283: 27 vertices\n",
      "    Cluster 284: 12 vertices\n",
      "    Cluster 285: 24 vertices\n",
      "    Cluster 286: 32 vertices\n",
      "    Cluster 287: 43 vertices\n",
      "    Cluster 288: 118 vertices\n",
      "    Cluster 289: 23 vertices\n",
      "    Cluster 290: 36 vertices\n",
      "    Cluster 291: 40 vertices\n",
      "    Cluster 292: 18 vertices\n",
      "    Cluster 293: 14 vertices\n",
      "    Cluster 294: 13 vertices\n",
      "\n",
      "Processing 'gravel'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building adjacency matrix: 14056it [00:01, 9912.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 31 clusters\n",
      "    Cluster 295: 62 vertices\n",
      "    Cluster 296: 45 vertices\n",
      "    Cluster 297: 228 vertices\n",
      "    Cluster 298: 506 vertices\n",
      "    Cluster 299: 6395 vertices\n",
      "    Cluster 300: 4053 vertices\n",
      "    Cluster 301: 379 vertices\n",
      "    Cluster 302: 50 vertices\n",
      "    Cluster 303: 13 vertices\n",
      "    Cluster 304: 1308 vertices\n",
      "    Cluster 305: 14 vertices\n",
      "    Cluster 306: 13 vertices\n",
      "    Cluster 307: 97 vertices\n",
      "    Cluster 308: 93 vertices\n",
      "    Cluster 309: 16 vertices\n",
      "    Cluster 310: 127 vertices\n",
      "    Cluster 311: 84 vertices\n",
      "    Cluster 312: 32 vertices\n",
      "    Cluster 313: 62 vertices\n",
      "    Cluster 314: 11 vertices\n",
      "    Cluster 315: 28 vertices\n",
      "    Cluster 316: 19 vertices\n",
      "    Cluster 317: 16 vertices\n",
      "    Cluster 318: 15 vertices\n",
      "    Cluster 319: 79 vertices\n",
      "    Cluster 320: 14 vertices\n",
      "    Cluster 321: 19 vertices\n",
      "    Cluster 322: 31 vertices\n",
      "    Cluster 323: 33 vertices\n",
      "    Cluster 324: 20 vertices\n",
      "    Cluster 325: 14 vertices\n",
      "\n",
      "\n",
      "Total clusters across all categories: 326\n"
     ]
    }
   ],
   "source": [
    "# Process all categories and aggregate clusters\n",
    "all_clusters = {}  # Store {category: [(cluster_idx, vertex_indices), ...]}\n",
    "cluster_counter = 0\n",
    "\n",
    "mesh_dir = splatter.config[\"mesh_info\"][\"mesh\"].parent\n",
    "\n",
    "for category in semantic_dictionary.keys():\n",
    "    print(f\"\\nProcessing '{category}'...\")\n",
    "    \n",
    "    # Load query mesh\n",
    "    query_mesh_path = mesh_dir / f\"query-{category}.ply\"\n",
    "    mesh_cat = o3d.io.read_triangle_mesh(str(query_mesh_path))\n",
    "    similarity = np.asarray(mesh_cat.vertex_colors)[:, 0]\n",
    "    \n",
    "    # Cluster\n",
    "    clusters = mesh_clustering(\n",
    "        mesh=mesh_cat,\n",
    "        similarity_values=similarity,\n",
    "        similarity_threshold=0.95,\n",
    "        spatial_radius=0.02,\n",
    "    )\n",
    "    \n",
    "    print(f\"  Found {len(clusters)} clusters\")\n",
    "    \n",
    "    # Store clusters with global cluster IDs\n",
    "    all_clusters[category] = []\n",
    "    for cluster_vertices in clusters:\n",
    "        all_clusters[category].append((cluster_counter, np.array(cluster_vertices)))\n",
    "        cluster_counter += 1\n",
    "        print(f\"    Cluster {cluster_counter-1}: {len(cluster_vertices)} vertices\")\n",
    "\n",
    "print(f\"\\n\\nTotal clusters across all categories: {cluster_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Categorical Mesh with Cluster Labels\n",
    "\n",
    "Create a single mesh with cluster labels for each vertex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned 103504/351349 vertices to clusters\n",
      "Cluster labels range: -1 to 3\n",
      "\n",
      "Saved cluster labels to /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/rade-features/2025-07-25_040743/mesh/cluster_labels.npy\n"
     ]
    }
   ],
   "source": [
    "# Load the base mesh (we'll use the first category's mesh as the base)\n",
    "base_category = list(semantic_dictionary.keys())[0]\n",
    "base_mesh_path = mesh_dir / f\"query-{base_category}.ply\"\n",
    "categorical_mesh = o3d.io.read_triangle_mesh(str(base_mesh_path))\n",
    "\n",
    "# Create cluster label array (-1 means no cluster assigned)\n",
    "num_vertices = len(categorical_mesh.vertices)\n",
    "cluster_labels = -np.ones(num_vertices, dtype=np.int32)\n",
    "\n",
    "# Assign cluster labels\n",
    "for category_id, (category, category_clusters) in enumerate(all_clusters.items()):\n",
    "    for cluster_id, vertex_indices in category_clusters:\n",
    "        cluster_labels[vertex_indices] = category_id\n",
    "\n",
    "# Count how many vertices are in clusters\n",
    "num_clustered = (cluster_labels >= 0).sum()\n",
    "print(f\"Assigned {num_clustered}/{num_vertices} vertices to clusters\")\n",
    "print(f\"Cluster labels range: {cluster_labels.min()} to {cluster_labels.max()}\")\n",
    "\n",
    "# Save cluster labels as a scalar field in the mesh\n",
    "# Store as colors for now (we'll create proper visualization later)\n",
    "# Normalize cluster IDs to 0-1 range for color mapping\n",
    "cluster_labels_normalized = cluster_labels.copy().astype(float)\n",
    "cluster_labels_normalized[cluster_labels >= 0] = cluster_labels[cluster_labels >= 0] / cluster_counter\n",
    "\n",
    "# Save categorical mesh with cluster labels\n",
    "categorical_mesh_path = mesh_dir / \"categorical_mesh.ply\"\n",
    "# We'll store the actual cluster labels separately\n",
    "np.save(mesh_dir / \"cluster_labels.npy\", cluster_labels)\n",
    "print(f\"\\nSaved cluster labels to {mesh_dir / 'cluster_labels.npy'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize All Clusters\n",
    "\n",
    "Create a comprehensive visualization showing:\n",
    "1. All clusters together with unique colors\n",
    "2. Individual cluster views (each cluster highlighted, rest black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 distinct colors for 4 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41554/2426260350.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = plt.cm.get_cmap('tab10')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Generate unique colors for each cluster\n",
    "def generate_distinct_colors(n):\n",
    "    \"\"\"Generate n visually distinct colors\"\"\"\n",
    "    if n <= 10:\n",
    "        # Use tab10 for small number of clusters\n",
    "        cmap = plt.cm.get_cmap('tab10')\n",
    "        return [cmap(i) for i in range(n)]\n",
    "    elif n <= 20:\n",
    "        # Use tab20 for medium number\n",
    "        cmap = plt.cm.get_cmap('tab20')\n",
    "        return [cmap(i) for i in range(n)]\n",
    "    else:\n",
    "        # Use hsv for many clusters\n",
    "        cmap = plt.cm.get_cmap('hsv')\n",
    "        return [cmap(i / n) for i in range(n)]\n",
    "\n",
    "# Generate colors for all clusters\n",
    "n_clusters = len(all_clusters.items())\n",
    "cluster_colors = generate_distinct_colors(n_clusters)\n",
    "print(f\"Generated {len(cluster_colors)} distinct colors for {n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View All Clusters Together\n",
    "\n",
    "Show all clusters in a single view with unique colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all-clusters mesh to /workspace/fieldwork-data/birds/2024-02-06/environment/C0043/rade-features/2025-07-25_040743/mesh/all_clusters.ply\n",
      "\n",
      "Visualizing all clusters together:\n",
      "Number of points: 351349\n",
      "Number of cells: 661879\n",
      "Bounds: BoundsTuple(x_min=-1.093526840209961, x_max=0.6880093812942505, y_min=-0.27054786682128906, y_max=1.2863465547561646, z_min=-0.42523476481437683, z_max=0.5941177606582642)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9780e98b05464a99b2042712e546c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:34769/index.html?ui=P_0x7fb71c68ae00_36&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "# Create mesh with all clusters colored\n",
    "all_clusters_mesh = copy.deepcopy(categorical_mesh)\n",
    "colors_all = np.zeros((num_vertices, 3))\n",
    "\n",
    "# Color each vertex by its cluster\n",
    "for vertex_idx in range(num_vertices):\n",
    "    cluster_id = cluster_labels[vertex_idx]\n",
    "    if cluster_id >= 0:\n",
    "        # Use cluster color (take RGB from the color tuple)\n",
    "        colors_all[vertex_idx] = cluster_colors[cluster_id][:3]\n",
    "    else:\n",
    "        # Non-clustered vertices are black\n",
    "        colors_all[vertex_idx] = [0,0,0]\n",
    "\n",
    "all_clusters_mesh.vertex_colors = o3d.utility.Vector3dVector(colors_all)\n",
    "\n",
    "# Save the all-clusters mesh\n",
    "all_clusters_path = mesh_dir / \"all_clusters.ply\"\n",
    "o3d.io.write_triangle_mesh(str(all_clusters_path), all_clusters_mesh)\n",
    "print(f\"Saved all-clusters mesh to {all_clusters_path}\")\n",
    "\n",
    "# Visualize\n",
    "print(\"\\nVisualizing all clusters together:\")\n",
    "splatter.plot_mesh(colors_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Grid Visualization of Individual Clusters\n",
    "\n",
    "Generate a grid showing each cluster individually (highlighted with unique color, rest black):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate grid dimensions for subplots\n",
    "import math\n",
    "\n",
    "n_clusters = cluster_counter\n",
    "n_cols = min(4, n_clusters)  # Max 4 columns\n",
    "n_rows = math.ceil(n_clusters / n_cols)\n",
    "\n",
    "print(f\"Creating grid visualization: {n_rows} rows x {n_cols} columns for {n_clusters} clusters\")\n",
    "\n",
    "# Create plotter with subplots\n",
    "plotter = pv.Plotter(shape=(n_rows, n_cols), window_size=[1600, 400 * n_rows])\n",
    "\n",
    "# Convert Open3D mesh to PyVista mesh\n",
    "vertices = np.asarray(categorical_mesh.vertices)\n",
    "faces = np.asarray(categorical_mesh.triangles)\n",
    "# PyVista format: [n_points, p0, p1, p2, n_points, p0, p1, p2, ...]\n",
    "faces_pv = np.hstack([np.full((len(faces), 1), 3), faces]).flatten()\n",
    "pv_mesh = pv.PolyData(vertices, faces_pv)\n",
    "\n",
    "# Flatten all_clusters into a list for easier iteration\n",
    "all_clusters_flat = []\n",
    "for category, category_clusters in all_clusters.items():\n",
    "    for cluster_id, vertex_indices in category_clusters:\n",
    "        all_clusters_flat.append({\n",
    "            'category': category,\n",
    "            'cluster_id': cluster_id,\n",
    "            'vertices': vertex_indices\n",
    "        })\n",
    "\n",
    "# Add each cluster to a subplot\n",
    "for idx, cluster_info in enumerate(all_clusters_flat):\n",
    "    row = idx // n_cols\n",
    "    col = idx % n_cols\n",
    "    \n",
    "    plotter.subplot(row, col)\n",
    "    \n",
    "    # Create color array: black background, cluster in its unique color\n",
    "    colors_single = np.zeros((num_vertices, 3))\n",
    "    cluster_id = cluster_info['cluster_id']\n",
    "    vertex_indices = cluster_info['vertices']\n",
    "    \n",
    "    # Color the cluster vertices\n",
    "    colors_single[vertex_indices] = cluster_colors[cluster_id][:3]\n",
    "    \n",
    "    # Add colors to mesh\n",
    "    pv_mesh_copy = pv_mesh.copy()\n",
    "    pv_mesh_copy['colors'] = colors_single\n",
    "    \n",
    "    # Add to plot\n",
    "    plotter.add_mesh(pv_mesh_copy, rgb=True, scalars='colors')\n",
    "    plotter.add_text(f\"{cluster_info['category']} - Cluster {cluster_id}\", \n",
    "                     font_size=10, position='upper_edge')\n",
    "    plotter.camera_position = 'iso'\n",
    "\n",
    "print(\"Rendering grid visualization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the grid visualization\n",
    "plotter.show()\n",
    "\n",
    "# Optional: Save as image\n",
    "# output_image_path = mesh_dir / \"clusters_grid.png\"\n",
    "# plotter.screenshot(output_image_path)\n",
    "# print(f\"Saved grid visualization to {output_image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Summary\n",
    "\n",
    "Display a summary of all clusters organized by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print cluster summary\n",
    "print(\"=\" * 60)\n",
    "print(\"CLUSTER SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, category_clusters in all_clusters.items():\n",
    "    print(f\"\\n{category.upper()}: {len(category_clusters)} cluster(s)\")\n",
    "    for cluster_id, vertex_indices in category_clusters:\n",
    "        color_rgb = [int(c * 255) for c in cluster_colors[cluster_id][:3]]\n",
    "        print(f\"  Cluster {cluster_id}: {len(vertex_indices)} vertices | Color: RGB{tuple(color_rgb)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Total: {cluster_counter} clusters across {len(all_clusters)} categories\")\n",
    "print(f\"Total clustered vertices: {num_clustered}/{num_vertices} ({100*num_clustered/num_vertices:.1f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Save Grid as Static Image\n",
    "\n",
    "Optionally save the grid visualization as a static PNG image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create offline plotter to render to image\n",
    "plotter_offline = pv.Plotter(shape=(n_rows, n_cols), \n",
    "                              window_size=[1600, 400 * n_rows],\n",
    "                              off_screen=True)\n",
    "\n",
    "# Recreate the grid\n",
    "for idx, cluster_info in enumerate(all_clusters_flat):\n",
    "    row = idx // n_cols\n",
    "    col = idx % n_cols\n",
    "    \n",
    "    plotter_offline.subplot(row, col)\n",
    "    \n",
    "    # Create color array\n",
    "    colors_single = np.zeros((num_vertices, 3))\n",
    "    cluster_id = cluster_info['cluster_id']\n",
    "    vertex_indices = cluster_info['vertices']\n",
    "    colors_single[vertex_indices] = cluster_colors[cluster_id][:3]\n",
    "    \n",
    "    # Add to plot\n",
    "    pv_mesh_copy = pv_mesh.copy()\n",
    "    pv_mesh_copy['colors'] = colors_single\n",
    "    plotter_offline.add_mesh(pv_mesh_copy, rgb=True, scalars='colors')\n",
    "    plotter_offline.add_text(f\"{cluster_info['category']} - Cluster {cluster_id}\", \n",
    "                            font_size=10, position='upper_edge')\n",
    "    plotter_offline.camera_position = 'iso'\n",
    "\n",
    "# Save as image\n",
    "output_image_path = mesh_dir / \"clusters_grid.png\"\n",
    "plotter_offline.screenshot(output_image_path)\n",
    "plotter_offline.close()\n",
    "\n",
    "print(f\"Saved grid visualization to {output_image_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
