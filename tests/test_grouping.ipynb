{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.3, llvm 15.0.4, commit 5ec301be, linux, python 3.10.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 07/16/25 16:07:30.587 23133] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "# from ns_extension.utils.grouping import GroupingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:07:34] </span>Auto image downscale factor of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                 <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nerfstudio_dataparser.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:07:34]\u001b[0m\u001b[2;36m \u001b[0mAuto image downscale factor of \u001b[1;36m2\u001b[0m                                                 \u001b]8;id=968234;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=557974;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\\u001b[2m484\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:08:11] </span>use color only optimization with sigmoid activation                                         <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">splatfacto.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#266\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:08:11]\u001b[0m\u001b[2;36m \u001b[0muse color only optimization with sigmoid activation                                         \u001b]8;id=122381;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\u001b\\\u001b[2msplatfacto.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=253357;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#266\u001b\\\u001b[2m266\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-11_171420/nerfstudio_models/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">step-00002</span>\n",
       "<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">9999.ckpt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "\u001b[35m/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-11_171420/nerfstudio_models/\u001b[0m\u001b[95mstep-00002\u001b[0m\n",
       "\u001b[95m9999.ckpt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the config for a trained model\n",
    "load_config = '/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/rade-features/2025-07-11_171420/config.yml'\n",
    "load_config = Path(load_config)\n",
    "\n",
    "config, pipeline, checkpoint_path, step = eval_setup(load_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question is whether to build grouping on top of the existing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:08:29] </span>Caching <span style=\"color: #800080; text-decoration-color: #800080\">/</span> undistorting train images                                            <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/datamanagers/full_images_datamanager.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">full_images_datamanager.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/datamanagers/full_images_datamanager.py#230\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:08:29]\u001b[0m\u001b[2;36m \u001b[0mCaching \u001b[35m/\u001b[0m undistorting train images                                            \u001b]8;id=491392;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/datamanagers/full_images_datamanager.py\u001b\\\u001b[2mfull_images_datamanager.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826539;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/data/datamanagers/full_images_datamanager.py#230\u001b\\\u001b[2m230\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b831917e4747c89a25e3f30dd41ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera, batch = pipeline.datamanager.next_train(0)\n",
    "\n",
    "fn = pipeline.datamanager.train_dataset.image_filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /workspace/models/hub/RogerQi_MobileSAMV2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_load_scucess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nerfstudio/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from ns_extension.utils.features import resize_image\n",
    "from ns_extension.utils.segmentation import Segmentation\n",
    "\n",
    "segmentation = Segmentation(\n",
    "    backend='mobilesamv2',\n",
    "    strategy='object',\n",
    "    device='cuda',\n",
    ")\n",
    "segmentation.strategy = 'auto'\n",
    "\n",
    "image = Image.open(fn)\n",
    "H, W = image.height, image.width\n",
    "\n",
    "# # Prepare image for segmentation\n",
    "# image = resize_image(image, longest_edge=1024) # Resize image to SAM resolution\n",
    "\n",
    "# Apply segmentation masks over features\n",
    "image = np.asarray(image) # Convert to numpy array\n",
    "masks, results = segmentation.segment(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start making our functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gaga --> gaussian grouping via multiview association + memory bank\n",
    "\n",
    "Steps:\n",
    "1. Create masks --> for each view within the dataset, create masks\n",
    "    - Original implementation saves them out as images, but we could just save them out as tensors\n",
    "\n",
    "2. Associate masks --> creates the memory bank?\n",
    "    - Front percentage (0.2)\n",
    "    - Overlap threshold (0.1)\n",
    "    - For each camera --> \n",
    "        - If no masks, initialize a memory bank for the first view's masks\n",
    "        - Get gaussian idxs and zcoords (for depth grouping) for the current view\n",
    "        - Find front gaussians:\n",
    "            - Create Spatial patch mask --> divides image into patch grid\n",
    "            - Object masks --> goes through each mask in the image\n",
    "            - Combines the two masks (i.e., find overlap between patch and object mask)\n",
    "            - Find frontmost gaussians within each patch for each object\n",
    "        - Based on this:\n",
    "            - Stores the indices of the front gaussians\n",
    "            - Mask ID = tensor of ALL indices of that mask (i.e., all gaussians in that mask)\n",
    "            - Num masks == number of masks in the memory bank\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from ns_extension.utils.utils import project_gaussians\n",
    "\n",
    "class GroupingClassifier(nn.Module):\n",
    "    def __init__(self, num_masks: int, num_gaussians: int):\n",
    "        super(GroupingClassifier, self).__init__()\n",
    "\n",
    "        # eval_setup(load_config)\n",
    "        self.num_masks = num_masks\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.classifier = nn.Conv2d(in_channels=num_masks, out_channels=num_gaussians, kernel_size=1)\n",
    "\n",
    "    #########################################################\n",
    "    ############## Mask initialization ######################\n",
    "    #########################################################\n",
    "\n",
    "    def set_patch_mask(self, image, num_patches: int = 32):\n",
    "        \"\"\"\n",
    "        Provided an image of given dimensions, create an array of patches.\n",
    "        \"\"\"\n",
    "        # Get image dimensions\n",
    "        H, W = image.shape[:2]\n",
    "\n",
    "        # Get patch dimensions\n",
    "        patch_width = math.ceil(W / num_patches)\n",
    "        patch_height = math.ceil(H / num_patches)\n",
    "        \n",
    "        # Create flattened coordinates\n",
    "        total_pixels = H * W\n",
    "        y_coords = torch.arange(H).unsqueeze(1).expand(-1, W).flatten()\n",
    "        x_coords = torch.arange(W).unsqueeze(0).expand(H, -1).flatten()\n",
    "        \n",
    "        # Calculate patch indices for all pixels at once\n",
    "        patch_y_indices = torch.clamp(y_coords // patch_height, 0, num_patches - 1)\n",
    "        patch_x_indices = torch.clamp(x_coords // patch_width, 0, num_patches - 1)\n",
    "        \n",
    "        # Create sparse representation\n",
    "        flatten_patch_mask = torch.zeros((num_patches, num_patches, total_pixels), \n",
    "                                    dtype=torch.bool)\n",
    "        \n",
    "        # Use indexing to set values\n",
    "        pixel_indices = torch.arange(total_pixels)\n",
    "        flatten_patch_mask[patch_y_indices, patch_x_indices, pixel_indices] = True\n",
    "        \n",
    "        return flatten_patch_mask\n",
    "    \n",
    "    def create_composite_mask(self, results, confidence_threshold=0.85):\n",
    "        \"\"\"\n",
    "        Creates a composite mask from the results of the segmentation model.\n",
    "        \n",
    "        Inputs:\n",
    "            results: list of dicts, each containing a mask and a confidence score\n",
    "            confidence_threshold: float, the minimum confidence score for a mask to be included in the composite mask\n",
    "\n",
    "        Outputs:\n",
    "            composite_mask: numpy array, the composite mask\n",
    "        \"\"\"\n",
    "\n",
    "        selected_masks = []\n",
    "        for mask in results:\n",
    "            if mask['predicted_iou'] < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            selected_masks.append(\n",
    "                (mask['segmentation'], mask['predicted_iou'])\n",
    "            )\n",
    "        \n",
    "        # Store the masks and confidences\n",
    "        masks, confs = zip(*selected_masks)\n",
    "\n",
    "        # Create empty image to store mask ids\n",
    "        H, W = masks[0].shape[:2]\n",
    "        mask_id = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "        sorted_idxs = np.argsort(confs)\n",
    "        for i, idx in enumerate(sorted_idxs, start=1):\n",
    "            current_mask = masks[idx - 1]\n",
    "            mask_id[current_mask == 1] = i\n",
    "\n",
    "        # Find mask indices after having calculated overlap based on ranked confidence\n",
    "        mask_indices = np.unique(mask_id)\n",
    "        mask_indices = np.setdiff1d(mask_indices, [0]) # remove 0 item\n",
    "\n",
    "        composite_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "        for i, idx in enumerate(mask_indices, start=1):\n",
    "            mask = (mask_id == idx)\n",
    "            if mask.sum() > 0 and (mask.sum() / masks[idx-1].sum()) > 0.1:\n",
    "                composite_mask[mask] = i\n",
    "\n",
    "        return composite_mask\n",
    "\n",
    "    def mask_id_to_binary_mask(self, composite_mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert an image with integer mask IDs to a binary mask array.\n",
    "\n",
    "        Args:\n",
    "            mask_id (np.ndarray): An (H, W) array where each unique positive integer \n",
    "                                represents a separate object mask.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: A (N, H, W) boolean array where N is the number of masks and each \n",
    "                        slice contains a binary mask.\n",
    "        \"\"\"\n",
    "        unique_ids = np.unique(composite_mask)\n",
    "        unique_ids = unique_ids[unique_ids > 0]  # Ignore background (assumed to be 0)\n",
    "\n",
    "        binary_masks = (composite_mask[None, ...] == unique_ids[:, None, None])\n",
    "        return binary_masks\n",
    "\n",
    "    #########################################################\n",
    "    ############## Gaussian selection #######################\n",
    "    #########################################################\n",
    "\n",
    "    def select_front_gaussians(self, model, camera, composite_mask, front_percentage: float = 0.5):\n",
    "        \"\"\"\n",
    "        JIT-compiled version using torch.compile (PyTorch 2.0+).\n",
    "        Maintains original structure and comments while adding compilation optimization.\n",
    "        Now with separated helper functions for better code organization.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Project gaussians onto 2d image\n",
    "        proj_results = project_gaussians(model, camera)\n",
    "        \n",
    "        # Prepare masks = Decimate the composite mask into individual masks\n",
    "        binary_masks = self.mask_id_to_binary_mask(composite_mask)\n",
    "        flattened_masks = torch.tensor(binary_masks).flatten(start_dim=1)  # (N, H*W)\n",
    "\n",
    "        # Pre-extract proj_results for compiled function\n",
    "        proj_flattened = proj_results['proj_flattened']\n",
    "        proj_depths = proj_results['proj_depths']\n",
    "\n",
    "        # Compute the gaussian lookup table\n",
    "        max_gaussian_id = proj_results['gaussian_ids'].max() if len(proj_results['gaussian_ids']) > 0 else 0\n",
    "        valid_gaussian_mask = torch.zeros(max_gaussian_id + 1, dtype=torch.bool, device=proj_results['gaussian_ids'].device)\n",
    "        valid_gaussian_mask[proj_results['gaussian_ids']] = True\n",
    "\n",
    "        front_gaussians = []\n",
    "\n",
    "        for mask in tqdm(flattened_masks, total=len(flattened_masks), desc=\"Processing masks\"):\n",
    "            # Use compiled function for main processing\n",
    "            result = self.process_mask_gaussians(\n",
    "                mask, \n",
    "                proj_results, \n",
    "                valid_gaussian_mask, \n",
    "                front_percentage=front_percentage\n",
    "            )\n",
    "            \n",
    "            front_gaussians.append(result)\n",
    "\n",
    "        return front_gaussians\n",
    "\n",
    "    @torch.compile(mode=\"max-autotune\")\n",
    "    def process_mask_gaussians(self, mask, proj_results: Dict[str, torch.Tensor], valid_gaussian_mask: torch.Tensor, front_percentage: float = 0.5):\n",
    "        \"\"\"\n",
    "        JIT-compiled function for processing a single mask.\n",
    "        Optimized for performance with torch.compile.\n",
    "        \"\"\"\n",
    "        # Find intersection between object mask and patch masks\n",
    "        patch_intersections = mask.unsqueeze(0).unsqueeze(0) & self.patch_mask\n",
    "\n",
    "        # Find non-empty patches\n",
    "        patch_sums = patch_intersections.sum(dim=2)\n",
    "        non_empty_patches = (patch_sums > 0).nonzero(as_tuple=False)\n",
    "\n",
    "        if len(non_empty_patches) == 0:\n",
    "            return torch.tensor([], dtype=torch.long, device=mask.device)\n",
    "        \n",
    "        # Extract all patches at once\n",
    "        mask_gaussians = []\n",
    "        patches_data = patch_intersections[non_empty_patches[:, 0], non_empty_patches[:, 1]]\n",
    "\n",
    "        # Go through each non-empty patch and get the front gaussians\n",
    "        for patch_idx, current_patch in enumerate(patches_data):\n",
    "            # Projected flattened are the pixel coordinates of each gaussian --> current patch is the pixels of the mask\n",
    "            # Grab gaussians in the current patch\n",
    "            patch_gaussians = current_patch[proj_results['proj_flattened']].nonzero().squeeze(-1)\n",
    "            \n",
    "            if len(patch_gaussians) == 0:\n",
    "                continue\n",
    "\n",
    "            # Filter valid gaussians using pre-computed mask\n",
    "            overlap_mask = valid_gaussian_mask[patch_gaussians]\n",
    "\n",
    "            if not overlap_mask.all():\n",
    "                invalid_count = (~overlap_mask).sum()\n",
    "                print(f\"Found {invalid_count} gaussians not in the IDs\")\n",
    "                print(\"Gaussians not in the IDs: \", patch_gaussians[~overlap_mask])\n",
    "\n",
    "            # Note: Error checking moved outside compiled function for better performance\n",
    "            patch_gaussians = patch_gaussians[overlap_mask]\n",
    "\n",
    "            if len(patch_gaussians) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Grab the depths of the gaussians in the patch\n",
    "            num_front_gaussians = max(int(front_percentage * len(patch_gaussians)), 1)\n",
    "            \n",
    "            if num_front_gaussians < len(patch_gaussians):\n",
    "                # Use partial sorting for better performance\n",
    "                patch_depths = proj_results['proj_depths'][patch_gaussians]\n",
    "                _, front_indices = torch.topk(patch_depths, num_front_gaussians, largest=False)\n",
    "                selected_gaussians = patch_gaussians[front_indices]\n",
    "            else:\n",
    "                selected_gaussians = patch_gaussians\n",
    "            \n",
    "            mask_gaussians.append(selected_gaussians)\n",
    "\n",
    "        if len(mask_gaussians) > 0:\n",
    "            mask_gaussians = torch.cat(mask_gaussians)\n",
    "            return mask_gaussians\n",
    "        else:\n",
    "            return torch.tensor([], dtype=torch.long, device=mask.device)\n",
    "\n",
    "    def associate_masks(self):\n",
    "        pass\n",
    "\n",
    "# def get_n_different_colors(n: int) -> np.ndarray:\n",
    "#     np.random.seed(0)\n",
    "#     return np.random.randint(1, 256, (n, 3), dtype=np.uint8)\n",
    "\n",
    "# def visualize_mask(mask: np.ndarray) -> np.ndarray:\n",
    "#     color_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "#     num_masks = np.max(mask)\n",
    "#     random_colors = get_n_different_colors(num_masks)\n",
    "#     for i in range(num_masks):\n",
    "#         color_mask[mask == i+1] = random_colors[i]\n",
    "#     return color_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the grouping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ns-extension/ns_extension/utils/camera_utils.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(get_world2view_transform(R, T, trans, scale)).transpose(0, 1).cuda()\n",
      "/tmp/ns-extension/ns_extension/utils/camera_utils.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(get_world2view_transform(R, T, trans, scale)).transpose(0, 1).cuda()\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.model\n",
    "proj_results = project_gaussians(model, camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 540)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['segmentation'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ns-extension/ns_extension/utils/camera_utils.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(get_world2view_transform(R, T, trans, scale)).transpose(0, 1).cuda()\n",
      "Processing masks:   0%|          | 0/65 [00:00<?, ?it/s]skipping cudagraphs for unknown reason\n",
      "Processing masks:   8%|▊         | 5/65 [00:02<00:24,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1195031])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  11%|█         | 7/65 [00:02<00:22,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1317422])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  37%|███▋      | 24/65 [00:08<00:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([730857])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([169239])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([281163])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([424230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  60%|██████    | 39/65 [00:14<00:09,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1103701, 1178042])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  68%|██████▊   | 44/65 [00:16<00:08,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([897836])\n",
      "Found 2 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1089400, 1096504])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  78%|███████▊  | 51/65 [00:18<00:04,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1236157])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([369113])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  91%|█████████ | 59/65 [00:20<00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([ 333050,  718835, 1230981])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  94%|█████████▍| 61/65 [00:21<00:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1264189, 1296009])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1309851])\n",
      "Found 4 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([466000, 526218, 720453, 992983])\n",
      "Found 2 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([392888, 787331])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([895690])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1048921])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  97%|█████████▋| 63/65 [00:22<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1303073])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([719282])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([813548])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1103224])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1231555])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1118953])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1089382])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1254684])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([115346])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1191680])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([150277])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([36077])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([194914])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1231573])\n",
      "Found 2 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([285126, 904047])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([384937])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1254771])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([652547])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([35])\n",
      "Found 3 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([  85541, 1121214, 1165543])\n",
      "Found 5 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([118247, 401735, 439226, 599613, 952390])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1231637])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([992976])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1121497])\n",
      "Found 2 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([ 644910, 1232854])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([913792])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([546112])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([925])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([228335])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([823473])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([477592])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1279455])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1232611])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1258072])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1266847])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1255004])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1302337])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([534900])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1231101])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([861653])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks:  98%|█████████▊| 64/65 [00:25<00:01,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([482238])\n",
      "Found 1 gaussians not in the IDs\n",
      "Gaussians not in the IDs:  tensor([1133756])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing masks: 100%|██████████| 65/65 [00:26<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "composite_mask = create_composite_mask(results)\n",
    "patch_mask = create_patch_mask(image, num_patches=32)\n",
    "front_gaussians = select_front_gaussians(model, camera, composite_mask, patch_mask, front_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the intersection between a given object mask and the patch masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the current mask, but we loop over these in the final product\n",
    "current_mask = flattened_masks[0]\n",
    "patch_intersections = current_mask.unsqueeze(0).unsqueeze(0) & patch_mask\n",
    "\n",
    "# Find non-empty patches\n",
    "patch_sums = patch_intersections.sum(dim=2)\n",
    "non_empty_patches = (patch_sums > 0).nonzero(as_tuple=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the gaussians into pixel space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ns-extension/ns_extension/utils/camera_utils.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(get_world2view_transform(R, T, trans, scale)).transpose(0, 1).cuda()\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.model\n",
    "proj_results = project_gaussians(model, camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab a non-empty patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = non_empty_patches[4]\n",
    "current_patch = patch_intersections[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the current patch, find its associated gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projected flattened are the pixel coordinates of each gaussian --> current patch is the pixels of the mask\n",
    "projected_flattened = proj_results['proj_flattened'] # (M,)\n",
    "patch_gaussians = current_patch[projected_flattened.cpu()].nonzero().squeeze(-1)\n",
    "\n",
    "# This should pass --> need to check all found patch gaussians are in the valid gaussians\n",
    "assert torch.isin(patch_gaussians.detach().cpu(), proj_results['gaussian_ids'].detach().cpu()).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the depths of the gaussians in the patch\n",
    "patch_gaussian_depths = proj_results['proj_depths'][patch_gaussians]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_percentage = 0.2\n",
    "num_patch_gaussians = len(patch_gaussians)\n",
    "num_front_gaussians = max(int(front_percentage * num_patch_gaussians), 1)\n",
    "\n",
    "# Sort the gaussians by depth\n",
    "sorted_gaussian_ids = torch.argsort(patch_gaussian_depths)\n",
    "\n",
    "# gaussians sorted by their depths and select the front based on percentage\n",
    "sorted_gaussians = patch_gaussians[sorted_gaussian_ids]\n",
    "selected_gaussians = sorted_gaussians[:num_front_gaussians]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_gaussians(model, image, camera, composite_mask, n_patches: int = 32, front_percentage: float = 0.5):\n",
    "\n",
    "    # Project the gaussians to 2d\n",
    "    proj_results = project_gaussians(model, camera)\n",
    "\n",
    "    # Decimate the composite mask into individual masks\n",
    "    binary_masks = mask_id_to_binary_mask(composite_mask)\n",
    "    flattened_masks = torch.tensor(binary_masks).flatten(start_dim=1)\n",
    "\n",
    "    # Create a patch mask --> find the intersection between the composite mask and the patch mask\n",
    "    patch_mask = create_patch_mask(image, n_patches)\n",
    "\n",
    "    gaussians = []\n",
    "\n",
    "    for mask in flattened_masks:\n",
    "\n",
    "        # Find the intersection between the mask and the patch mask\n",
    "        patch_intersections = mask.unsqueeze(0).unsqueeze(0) & patch_mask\n",
    "\n",
    "        # Find the non-empty patches\n",
    "        patch_sums = patch_intersections.sum(dim=2)  # Sum pixels per patch\n",
    "        non_empty_patches = (patch_sums > 0).nonzero(as_tuple=False)\n",
    "\n",
    "        # If there are no non-empty patches, add an empty tensor to the gaussians list\n",
    "        if len(non_empty_patches) == 0:\n",
    "            gaussians.append(torch.tensor([], dtype=torch.long))\n",
    "            continue\n",
    "        \n",
    "        # Find the gaussian ids that are inside the non-empty patches\n",
    "        mask_gaussians = []\n",
    "\n",
    "        for patch_idx in non_empty_patches:\n",
    "            i, j = patch_idx\n",
    "            current_patch = patch_intersections[i, j]\n",
    "\n",
    "            # current_patch\n",
    "\n",
    "            # Find the gaussian ids that are inside the current patch\n",
    "            patch_gaussians = torch.where(current_patch)[0]\n",
    "\n",
    "            # Find the gaussian ids that are inside the current patch\n",
    "            patch_gaussians = torch.where(current_patch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ns-extension/ns_extension/utils/camera_utils.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(get_world2view_transform(R, T, trans, scale)).transpose(0, 1).cuda()\n"
     ]
    }
   ],
   "source": [
    "proj_results = project_gaussians(model, camera)\n",
    "\n",
    "i, j = non_empty_patches[4]\n",
    "current_patch = patch_intersections[i, j]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
