{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.3, llvm 15.0.4, commit 5ec301be, linux, python 3.10.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 07/02/25 18:15:34.958 6296] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# from rade_gs.models import RadegsModel, RadegsModelConfig\n",
    "from nerfstudio.models.splatfacto import SplatfactoModel, SplatfactoModelConfig\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from nerfstudio.data.scene_box import OrientedBox, SceneBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find config for our current model\n",
    "load_config = Path('/workspace/fieldwork-data/rats/2024-07-11/environment/C0119/feature-splatting/2025-06-18_174658/config.yml')\n",
    "\n",
    "config = yaml.load(load_config.read_text(), Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:35:09] </span>use color only optimization with sigmoid activation                                         <a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">splatfacto.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#266\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:35:09]\u001b[0m\u001b[2;36m \u001b[0muse color only optimization with sigmoid activation                                         \u001b]8;id=132383;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py\u001b\\\u001b[2msplatfacto.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=732632;file:///opt/conda/envs/nerfstudio/lib/python3.10/site-packages/nerfstudio/models/splatfacto.py#266\u001b\\\u001b[2m266\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CLIP model from https://openaipublic.azureedge.net/clip/models/3035c92b350959924f9f00213499208652fc7ea050643e8b385c2dac08641f02/ViT-L-14-336px.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 891M/891M [02:51<00:00, 5.45MiB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline = config.pipeline.setup(device='cuda', test_mode='inference')\n",
    "\n",
    "aabb_scale = pipeline.datamanager.dataparser.config.scene_scale\n",
    "\n",
    "scene_box = SceneBox(\n",
    "    aabb=torch.tensor(\n",
    "        [[-aabb_scale, -aabb_scale, -aabb_scale], [aabb_scale, aabb_scale, aabb_scale]], dtype=torch.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "train_samples = len(pipeline.datamanager.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RadegsModelConfig(output_depth_during_training=True)\n",
    "radegs_model = RadegsModel(config, scene_box=scene_box, num_train_data=train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "camera = pipeline.datamanager.train_dataset.cameras[idx:idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu118\n",
      "CUDA available: True\n",
      "CUDA version PyTorch was compiled with: 11.8\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version PyTorch was compiled with: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera device: cpu\n",
      "Parameter device_indicator_param is on cpu\n"
     ]
    }
   ],
   "source": [
    "# Before calling radegs_model.get_outputs(camera)\n",
    "print(f\"Camera device: {camera.device if hasattr(camera, 'device') else 'No device attr'}\")\n",
    "\n",
    "# Check model parameters\n",
    "for name, param in radegs_model.named_parameters():\n",
    "    if param.device.type != 'cuda':\n",
    "        print(f\"Parameter {name} is on {param.device}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the entire model to CUDA\n",
    "radegs_model = radegs_model.cuda()\n",
    "\n",
    "# Or if you want to be explicit about the device\n",
    "device = torch.device('cuda:0')\n",
    "radegs_model = radegs_model.to(device)\n",
    "\n",
    "camera = camera.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 67, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radegs_model._downscale_if_required()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = radegs_model.get_outputs(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_outputs = pipeline.model.get_outputs(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['camera_ids', 'gaussian_ids', 'radii', 'means2d', 'depths', 'conics', 'opacities', 'tile_width', 'tile_height', 'tiles_per_gauss', 'isect_ids', 'flatten_ids', 'isect_offsets', 'width', 'height', 'tile_size', 'n_cameras'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['info'].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
